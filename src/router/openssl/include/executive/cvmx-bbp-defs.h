/***********************license start***************
 * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
 * reserved.
 *
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are
 * met:
 *
 *   * Redistributions of source code must retain the above copyright
 *     notice, this list of conditions and the following disclaimer.
 *
 *   * Redistributions in binary form must reproduce the above
 *     copyright notice, this list of conditions and the following
 *     disclaimer in the documentation and/or other materials provided
 *     with the distribution.

 *   * Neither the name of Cavium Inc. nor the names of
 *     its contributors may be used to endorse or promote products
 *     derived from this software without specific prior written
 *     permission.

 * This Software, including technical data, may be subject to U.S. export  control
 * laws, including the U.S. Export Administration Act and its  associated
 * regulations, and may be subject to export or import  regulations in other
 * countries.

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
 * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
 * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
 * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
 * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
 * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
 * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
 * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
 * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
 ***********************license end**************************************/


/**
 * cvmx-bbp-defs.h
 *
 * Configuration and status register (CSR) type definitions for
 * Octeon bbp.
 *
 * This file is auto generated. Do not edit.
 *
 * <hr>$Revision$<hr>
 *
 */
#ifndef __CVMX_BBP_DEFS_H__
#define __CVMX_BBP_DEFS_H__

#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_AUTO_CLK_GATE CVMX_BBP_ADMA_AUTO_CLK_GATE_FUNC()
static inline uint64_t CVMX_BBP_ADMA_AUTO_CLK_GATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_AUTO_CLK_GATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844004ull);
}
#else
#define CVMX_BBP_ADMA_AUTO_CLK_GATE (CVMX_ADD_IO_SEG(0x00010F0000844004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_AXIERR_INTR CVMX_BBP_ADMA_AXIERR_INTR_FUNC()
static inline uint64_t CVMX_BBP_ADMA_AXIERR_INTR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_AXIERR_INTR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844044ull);
}
#else
#define CVMX_BBP_ADMA_AXIERR_INTR (CVMX_ADD_IO_SEG(0x00010F0000844044ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_AXI_RSPCODE CVMX_BBP_ADMA_AXI_RSPCODE_FUNC()
static inline uint64_t CVMX_BBP_ADMA_AXI_RSPCODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_AXI_RSPCODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844050ull);
}
#else
#define CVMX_BBP_ADMA_AXI_RSPCODE (CVMX_ADD_IO_SEG(0x00010F0000844050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_AXI_SIGNAL CVMX_BBP_ADMA_AXI_SIGNAL_FUNC()
static inline uint64_t CVMX_BBP_ADMA_AXI_SIGNAL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_AXI_SIGNAL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844084ull);
}
#else
#define CVMX_BBP_ADMA_AXI_SIGNAL (CVMX_ADD_IO_SEG(0x00010F0000844084ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_DMADONE_INTR CVMX_BBP_ADMA_DMADONE_INTR_FUNC()
static inline uint64_t CVMX_BBP_ADMA_DMADONE_INTR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_DMADONE_INTR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844040ull);
}
#else
#define CVMX_BBP_ADMA_DMADONE_INTR (CVMX_ADD_IO_SEG(0x00010F0000844040ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_ADMA_DMAX_ADDR_HI(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 7)))))
		cvmx_warn("CVMX_BBP_ADMA_DMAX_ADDR_HI(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000084410Cull) + ((offset) & 7) * 16;
}
#else
#define CVMX_BBP_ADMA_DMAX_ADDR_HI(offset) (CVMX_ADD_IO_SEG(0x00010F000084410Cull) + ((offset) & 7) * 16)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_ADMA_DMAX_ADDR_LO(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 7)))))
		cvmx_warn("CVMX_BBP_ADMA_DMAX_ADDR_LO(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000844108ull) + ((offset) & 7) * 16;
}
#else
#define CVMX_BBP_ADMA_DMAX_ADDR_LO(offset) (CVMX_ADD_IO_SEG(0x00010F0000844108ull) + ((offset) & 7) * 16)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_ADMA_DMAX_CFG(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 7)))))
		cvmx_warn("CVMX_BBP_ADMA_DMAX_CFG(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000844100ull) + ((offset) & 7) * 16;
}
#else
#define CVMX_BBP_ADMA_DMAX_CFG(offset) (CVMX_ADD_IO_SEG(0x00010F0000844100ull) + ((offset) & 7) * 16)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_ADMA_DMAX_SIZE(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 7)))))
		cvmx_warn("CVMX_BBP_ADMA_DMAX_SIZE(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000844104ull) + ((offset) & 7) * 16;
}
#else
#define CVMX_BBP_ADMA_DMAX_SIZE(offset) (CVMX_ADD_IO_SEG(0x00010F0000844104ull) + ((offset) & 7) * 16)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_DMA_PRIORITY CVMX_BBP_ADMA_DMA_PRIORITY_FUNC()
static inline uint64_t CVMX_BBP_ADMA_DMA_PRIORITY_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_DMA_PRIORITY not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844080ull);
}
#else
#define CVMX_BBP_ADMA_DMA_PRIORITY (CVMX_ADD_IO_SEG(0x00010F0000844080ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_DMA_RESET CVMX_BBP_ADMA_DMA_RESET_FUNC()
static inline uint64_t CVMX_BBP_ADMA_DMA_RESET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_DMA_RESET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844008ull);
}
#else
#define CVMX_BBP_ADMA_DMA_RESET (CVMX_ADD_IO_SEG(0x00010F0000844008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_INTR_DIS CVMX_BBP_ADMA_INTR_DIS_FUNC()
static inline uint64_t CVMX_BBP_ADMA_INTR_DIS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_INTR_DIS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084404Cull);
}
#else
#define CVMX_BBP_ADMA_INTR_DIS (CVMX_ADD_IO_SEG(0x00010F000084404Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_INTR_ENB CVMX_BBP_ADMA_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_ADMA_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844048ull);
}
#else
#define CVMX_BBP_ADMA_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000844048ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ADMA_MODULE_STATUS CVMX_BBP_ADMA_MODULE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_ADMA_MODULE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ADMA_MODULE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844000ull);
}
#else
#define CVMX_BBP_ADMA_MODULE_STATUS (CVMX_ADD_IO_SEG(0x00010F0000844000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_BYPASS_MODE CVMX_BBP_DFTDMP_BYPASS_MODE_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_BYPASS_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_BYPASS_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829214ull);
}
#else
#define CVMX_BBP_DFTDMP_BYPASS_MODE (CVMX_ADD_IO_SEG(0x00010F0000829214ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_CLK_CTRL CVMX_BBP_DFTDMP_CLK_CTRL_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_CLK_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_CLK_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082900Cull);
}
#else
#define CVMX_BBP_DFTDMP_CLK_CTRL (CVMX_ADD_IO_SEG(0x00010F000082900Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_CONTROL CVMX_BBP_DFTDMP_CONTROL_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_CONTROL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_CONTROL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829004ull);
}
#else
#define CVMX_BBP_DFTDMP_CONTROL (CVMX_ADD_IO_SEG(0x00010F0000829004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_DEMAPLLR_RD_TOUT CVMX_BBP_DFTDMP_DEMAPLLR_RD_TOUT_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_DEMAPLLR_RD_TOUT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_DEMAPLLR_RD_TOUT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829248ull);
}
#else
#define CVMX_BBP_DFTDMP_DEMAPLLR_RD_TOUT (CVMX_ADD_IO_SEG(0x00010F0000829248ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_DFT_MODE CVMX_BBP_DFTDMP_DFT_MODE_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_DFT_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_DFT_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829210ull);
}
#else
#define CVMX_BBP_DFTDMP_DFT_MODE (CVMX_ADD_IO_SEG(0x00010F0000829210ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_DMARD_GAP_CNT CVMX_BBP_DFTDMP_DMARD_GAP_CNT_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_DMARD_GAP_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_DMARD_GAP_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829240ull);
}
#else
#define CVMX_BBP_DFTDMP_DMARD_GAP_CNT (CVMX_ADD_IO_SEG(0x00010F0000829240ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_ENG_VER CVMX_BBP_DFTDMP_ENG_VER_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_ENG_VER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_ENG_VER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829308ull);
}
#else
#define CVMX_BBP_DFTDMP_ENG_VER (CVMX_ADD_IO_SEG(0x00010F0000829308ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_ESTSYM_WR_CNT CVMX_BBP_DFTDMP_ESTSYM_WR_CNT_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_ESTSYM_WR_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_ESTSYM_WR_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829244ull);
}
#else
#define CVMX_BBP_DFTDMP_ESTSYM_WR_CNT (CVMX_ADD_IO_SEG(0x00010F0000829244ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_HW_CORE_STATUS CVMX_BBP_DFTDMP_HW_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_HW_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_HW_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829008ull);
}
#else
#define CVMX_BBP_DFTDMP_HW_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F0000829008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_HW_TEST_MODE CVMX_BBP_DFTDMP_HW_TEST_MODE_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_HW_TEST_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_HW_TEST_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829250ull);
}
#else
#define CVMX_BBP_DFTDMP_HW_TEST_MODE (CVMX_ADD_IO_SEG(0x00010F0000829250ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_INT_MASK CVMX_BBP_DFTDMP_INT_MASK_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_INT_MASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_INT_MASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082910Cull);
}
#else
#define CVMX_BBP_DFTDMP_INT_MASK (CVMX_ADD_IO_SEG(0x00010F000082910Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_INT_SRC CVMX_BBP_DFTDMP_INT_SRC_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_INT_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_INT_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829100ull);
}
#else
#define CVMX_BBP_DFTDMP_INT_SRC (CVMX_ADD_IO_SEG(0x00010F0000829100ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_LAB_VER CVMX_BBP_DFTDMP_LAB_VER_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_LAB_VER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_LAB_VER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829304ull);
}
#else
#define CVMX_BBP_DFTDMP_LAB_VER (CVMX_ADD_IO_SEG(0x00010F0000829304ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_LLR_BIT_WID CVMX_BBP_DFTDMP_LLR_BIT_WID_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_LLR_BIT_WID_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_LLR_BIT_WID not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082922Cull);
}
#else
#define CVMX_BBP_DFTDMP_LLR_BIT_WID (CVMX_ADD_IO_SEG(0x00010F000082922Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_PARAMETER1 CVMX_BBP_DFTDMP_PARAMETER1_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_PARAMETER1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_PARAMETER1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829200ull);
}
#else
#define CVMX_BBP_DFTDMP_PARAMETER1 (CVMX_ADD_IO_SEG(0x00010F0000829200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_PARAMETER2 CVMX_BBP_DFTDMP_PARAMETER2_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_PARAMETER2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_PARAMETER2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829204ull);
}
#else
#define CVMX_BBP_DFTDMP_PARAMETER2 (CVMX_ADD_IO_SEG(0x00010F0000829204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_QAM_DIST1 CVMX_BBP_DFTDMP_QAM_DIST1_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_QAM_DIST1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_QAM_DIST1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829220ull);
}
#else
#define CVMX_BBP_DFTDMP_QAM_DIST1 (CVMX_ADD_IO_SEG(0x00010F0000829220ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_QAM_DIST2 CVMX_BBP_DFTDMP_QAM_DIST2_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_QAM_DIST2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_QAM_DIST2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829224ull);
}
#else
#define CVMX_BBP_DFTDMP_QAM_DIST2 (CVMX_ADD_IO_SEG(0x00010F0000829224ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_SS_CTRL CVMX_BBP_DFTDMP_SS_CTRL_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_SS_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_SS_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829228ull);
}
#else
#define CVMX_BBP_DFTDMP_SS_CTRL (CVMX_ADD_IO_SEG(0x00010F0000829228ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_STATUS CVMX_BBP_DFTDMP_STATUS_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829000ull);
}
#else
#define CVMX_BBP_DFTDMP_STATUS (CVMX_ADD_IO_SEG(0x00010F0000829000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DFTDMP_VER CVMX_BBP_DFTDMP_VER_FUNC()
static inline uint64_t CVMX_BBP_DFTDMP_VER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DFTDMP_VER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000829300ull);
}
#else
#define CVMX_BBP_DFTDMP_VER (CVMX_ADD_IO_SEG(0x00010F0000829300ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_BYPASS_MODE CVMX_BBP_DLE_BYPASS_MODE_FUNC()
static inline uint64_t CVMX_BBP_DLE_BYPASS_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_BYPASS_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E618ull);
}
#else
#define CVMX_BBP_DLE_BYPASS_MODE (CVMX_ADD_IO_SEG(0x00010F000086E618ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_CLK_CTRL CVMX_BBP_DLE_CLK_CTRL_FUNC()
static inline uint64_t CVMX_BBP_DLE_CLK_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_CLK_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E40Cull);
}
#else
#define CVMX_BBP_DLE_CLK_CTRL (CVMX_ADD_IO_SEG(0x00010F000086E40Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_CONTROL CVMX_BBP_DLE_CONTROL_FUNC()
static inline uint64_t CVMX_BBP_DLE_CONTROL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_CONTROL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E404ull);
}
#else
#define CVMX_BBP_DLE_CONTROL (CVMX_ADD_IO_SEG(0x00010F000086E404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_ENCODED_PBCH0 CVMX_BBP_DLE_ENCODED_PBCH0_FUNC()
static inline uint64_t CVMX_BBP_DLE_ENCODED_PBCH0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_ENCODED_PBCH0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E710ull);
}
#else
#define CVMX_BBP_DLE_ENCODED_PBCH0 (CVMX_ADD_IO_SEG(0x00010F000086E710ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_ENCODED_PBCH1 CVMX_BBP_DLE_ENCODED_PBCH1_FUNC()
static inline uint64_t CVMX_BBP_DLE_ENCODED_PBCH1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_ENCODED_PBCH1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E714ull);
}
#else
#define CVMX_BBP_DLE_ENCODED_PBCH1 (CVMX_ADD_IO_SEG(0x00010F000086E714ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_ENCODED_PBCH2 CVMX_BBP_DLE_ENCODED_PBCH2_FUNC()
static inline uint64_t CVMX_BBP_DLE_ENCODED_PBCH2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_ENCODED_PBCH2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E718ull);
}
#else
#define CVMX_BBP_DLE_ENCODED_PBCH2 (CVMX_ADD_IO_SEG(0x00010F000086E718ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_ENCODED_PBCH3 CVMX_BBP_DLE_ENCODED_PBCH3_FUNC()
static inline uint64_t CVMX_BBP_DLE_ENCODED_PBCH3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_ENCODED_PBCH3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E71Cull);
}
#else
#define CVMX_BBP_DLE_ENCODED_PBCH3 (CVMX_ADD_IO_SEG(0x00010F000086E71Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_GRANT_NUM CVMX_BBP_DLE_GRANT_NUM_FUNC()
static inline uint64_t CVMX_BBP_DLE_GRANT_NUM_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_GRANT_NUM not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E610ull);
}
#else
#define CVMX_BBP_DLE_GRANT_NUM (CVMX_ADD_IO_SEG(0x00010F000086E610ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_HAB_VERSION CVMX_BBP_DLE_HAB_VERSION_FUNC()
static inline uint64_t CVMX_BBP_DLE_HAB_VERSION_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_HAB_VERSION not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E700ull);
}
#else
#define CVMX_BBP_DLE_HAB_VERSION (CVMX_ADD_IO_SEG(0x00010F000086E700ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_HMM_RD_TOUT_VAL CVMX_BBP_DLE_HMM_RD_TOUT_VAL_FUNC()
static inline uint64_t CVMX_BBP_DLE_HMM_RD_TOUT_VAL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_HMM_RD_TOUT_VAL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E61Cull);
}
#else
#define CVMX_BBP_DLE_HMM_RD_TOUT_VAL (CVMX_ADD_IO_SEG(0x00010F000086E61Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_HW_CORE_STATUS CVMX_BBP_DLE_HW_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_DLE_HW_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_HW_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E408ull);
}
#else
#define CVMX_BBP_DLE_HW_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F000086E408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_INT_MASK CVMX_BBP_DLE_INT_MASK_FUNC()
static inline uint64_t CVMX_BBP_DLE_INT_MASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_INT_MASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E50Cull);
}
#else
#define CVMX_BBP_DLE_INT_MASK (CVMX_ADD_IO_SEG(0x00010F000086E50Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_INT_SRC CVMX_BBP_DLE_INT_SRC_FUNC()
static inline uint64_t CVMX_BBP_DLE_INT_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_INT_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E500ull);
}
#else
#define CVMX_BBP_DLE_INT_SRC (CVMX_ADD_IO_SEG(0x00010F000086E500ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PBCH_CONF CVMX_BBP_DLE_PBCH_CONF_FUNC()
static inline uint64_t CVMX_BBP_DLE_PBCH_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PBCH_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E600ull);
}
#else
#define CVMX_BBP_DLE_PBCH_CONF (CVMX_ADD_IO_SEG(0x00010F000086E600ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PBCH_DATA CVMX_BBP_DLE_PBCH_DATA_FUNC()
static inline uint64_t CVMX_BBP_DLE_PBCH_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PBCH_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E604ull);
}
#else
#define CVMX_BBP_DLE_PBCH_DATA (CVMX_ADD_IO_SEG(0x00010F000086E604ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDCCH_CONF CVMX_BBP_DLE_PDCCH_CONF_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDCCH_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDCCH_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E624ull);
}
#else
#define CVMX_BBP_DLE_PDCCH_CONF (CVMX_ADD_IO_SEG(0x00010F000086E624ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDCCH_DATA0 CVMX_BBP_DLE_PDCCH_DATA0_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDCCH_DATA0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDCCH_DATA0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E628ull);
}
#else
#define CVMX_BBP_DLE_PDCCH_DATA0 (CVMX_ADD_IO_SEG(0x00010F000086E628ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDCCH_DATA1 CVMX_BBP_DLE_PDCCH_DATA1_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDCCH_DATA1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDCCH_DATA1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E62Cull);
}
#else
#define CVMX_BBP_DLE_PDCCH_DATA1 (CVMX_ADD_IO_SEG(0x00010F000086E62Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDCCH_IDX CVMX_BBP_DLE_PDCCH_IDX_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDCCH_IDX_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDCCH_IDX not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E620ull);
}
#else
#define CVMX_BBP_DLE_PDCCH_IDX (CVMX_ADD_IO_SEG(0x00010F000086E620ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_IDX CVMX_BBP_DLE_PDSCH_IDX_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_IDX_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_IDX not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E640ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_IDX (CVMX_ADD_IO_SEG(0x00010F000086E640ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB0_CONF0 CVMX_BBP_DLE_PDSCH_TB0_CONF0_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB0_CONF0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB0_CONF0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E644ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB0_CONF0 (CVMX_ADD_IO_SEG(0x00010F000086E644ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB0_CONF1 CVMX_BBP_DLE_PDSCH_TB0_CONF1_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB0_CONF1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB0_CONF1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E648ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB0_CONF1 (CVMX_ADD_IO_SEG(0x00010F000086E648ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB0_CONF2 CVMX_BBP_DLE_PDSCH_TB0_CONF2_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB0_CONF2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB0_CONF2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E64Cull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB0_CONF2 (CVMX_ADD_IO_SEG(0x00010F000086E64Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB0_CONF3 CVMX_BBP_DLE_PDSCH_TB0_CONF3_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB0_CONF3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB0_CONF3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E650ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB0_CONF3 (CVMX_ADD_IO_SEG(0x00010F000086E650ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB0_CONF4 CVMX_BBP_DLE_PDSCH_TB0_CONF4_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB0_CONF4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB0_CONF4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E654ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB0_CONF4 (CVMX_ADD_IO_SEG(0x00010F000086E654ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB0_CONF5 CVMX_BBP_DLE_PDSCH_TB0_CONF5_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB0_CONF5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB0_CONF5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E658ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB0_CONF5 (CVMX_ADD_IO_SEG(0x00010F000086E658ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB1_CONF0 CVMX_BBP_DLE_PDSCH_TB1_CONF0_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB1_CONF0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB1_CONF0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E65Cull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB1_CONF0 (CVMX_ADD_IO_SEG(0x00010F000086E65Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB1_CONF1 CVMX_BBP_DLE_PDSCH_TB1_CONF1_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB1_CONF1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB1_CONF1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E660ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB1_CONF1 (CVMX_ADD_IO_SEG(0x00010F000086E660ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB1_CONF2 CVMX_BBP_DLE_PDSCH_TB1_CONF2_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB1_CONF2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB1_CONF2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E664ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB1_CONF2 (CVMX_ADD_IO_SEG(0x00010F000086E664ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB1_CONF3 CVMX_BBP_DLE_PDSCH_TB1_CONF3_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB1_CONF3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB1_CONF3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E668ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB1_CONF3 (CVMX_ADD_IO_SEG(0x00010F000086E668ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB1_CONF4 CVMX_BBP_DLE_PDSCH_TB1_CONF4_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB1_CONF4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB1_CONF4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E66Cull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB1_CONF4 (CVMX_ADD_IO_SEG(0x00010F000086E66Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_TB1_CONF5 CVMX_BBP_DLE_PDSCH_TB1_CONF5_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_TB1_CONF5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_TB1_CONF5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E670ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_TB1_CONF5 (CVMX_ADD_IO_SEG(0x00010F000086E670ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_PDSCH_WR_CNT CVMX_BBP_DLE_PDSCH_WR_CNT_FUNC()
static inline uint64_t CVMX_BBP_DLE_PDSCH_WR_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_PDSCH_WR_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E614ull);
}
#else
#define CVMX_BBP_DLE_PDSCH_WR_CNT (CVMX_ADD_IO_SEG(0x00010F000086E614ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDCCH_CONF CVMX_BBP_DLE_RD_PDCCH_CONF_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDCCH_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDCCH_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E734ull);
}
#else
#define CVMX_BBP_DLE_RD_PDCCH_CONF (CVMX_ADD_IO_SEG(0x00010F000086E734ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDCCH_DATA0 CVMX_BBP_DLE_RD_PDCCH_DATA0_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDCCH_DATA0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDCCH_DATA0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E738ull);
}
#else
#define CVMX_BBP_DLE_RD_PDCCH_DATA0 (CVMX_ADD_IO_SEG(0x00010F000086E738ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDCCH_DATA1 CVMX_BBP_DLE_RD_PDCCH_DATA1_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDCCH_DATA1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDCCH_DATA1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E73Cull);
}
#else
#define CVMX_BBP_DLE_RD_PDCCH_DATA1 (CVMX_ADD_IO_SEG(0x00010F000086E73Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDCCH_IDX CVMX_BBP_DLE_RD_PDCCH_IDX_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDCCH_IDX_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDCCH_IDX not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E730ull);
}
#else
#define CVMX_BBP_DLE_RD_PDCCH_IDX (CVMX_ADD_IO_SEG(0x00010F000086E730ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_IDX CVMX_BBP_DLE_RD_PDSCH_IDX_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_IDX_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_IDX not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E740ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_IDX (CVMX_ADD_IO_SEG(0x00010F000086E740ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF0 CVMX_BBP_DLE_RD_PDSCH_TB0_CONF0_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB0_CONF0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB0_CONF0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E744ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF0 (CVMX_ADD_IO_SEG(0x00010F000086E744ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF1 CVMX_BBP_DLE_RD_PDSCH_TB0_CONF1_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB0_CONF1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB0_CONF1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E748ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF1 (CVMX_ADD_IO_SEG(0x00010F000086E748ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF2 CVMX_BBP_DLE_RD_PDSCH_TB0_CONF2_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB0_CONF2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB0_CONF2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E74Cull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF2 (CVMX_ADD_IO_SEG(0x00010F000086E74Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF3 CVMX_BBP_DLE_RD_PDSCH_TB0_CONF3_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB0_CONF3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB0_CONF3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E750ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF3 (CVMX_ADD_IO_SEG(0x00010F000086E750ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF4 CVMX_BBP_DLE_RD_PDSCH_TB0_CONF4_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB0_CONF4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB0_CONF4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E754ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF4 (CVMX_ADD_IO_SEG(0x00010F000086E754ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF5 CVMX_BBP_DLE_RD_PDSCH_TB0_CONF5_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB0_CONF5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB0_CONF5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E758ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB0_CONF5 (CVMX_ADD_IO_SEG(0x00010F000086E758ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF0 CVMX_BBP_DLE_RD_PDSCH_TB1_CONF0_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB1_CONF0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB1_CONF0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E75Cull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF0 (CVMX_ADD_IO_SEG(0x00010F000086E75Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF1 CVMX_BBP_DLE_RD_PDSCH_TB1_CONF1_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB1_CONF1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB1_CONF1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E760ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF1 (CVMX_ADD_IO_SEG(0x00010F000086E760ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF2 CVMX_BBP_DLE_RD_PDSCH_TB1_CONF2_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB1_CONF2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB1_CONF2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E764ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF2 (CVMX_ADD_IO_SEG(0x00010F000086E764ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF3 CVMX_BBP_DLE_RD_PDSCH_TB1_CONF3_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB1_CONF3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB1_CONF3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E768ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF3 (CVMX_ADD_IO_SEG(0x00010F000086E768ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF4 CVMX_BBP_DLE_RD_PDSCH_TB1_CONF4_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB1_CONF4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB1_CONF4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E76Cull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF4 (CVMX_ADD_IO_SEG(0x00010F000086E76Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF5 CVMX_BBP_DLE_RD_PDSCH_TB1_CONF5_FUNC()
static inline uint64_t CVMX_BBP_DLE_RD_PDSCH_TB1_CONF5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_RD_PDSCH_TB1_CONF5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E770ull);
}
#else
#define CVMX_BBP_DLE_RD_PDSCH_TB1_CONF5 (CVMX_ADD_IO_SEG(0x00010F000086E770ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_DLE_STATUS CVMX_BBP_DLE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_DLE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_DLE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E400ull);
}
#else
#define CVMX_BBP_DLE_STATUS (CVMX_ADD_IO_SEG(0x00010F000086E400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_AUTOGATE CVMX_BBP_ENC3G_AUTOGATE_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_AUTOGATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_AUTOGATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EC04ull);
}
#else
#define CVMX_BBP_ENC3G_AUTOGATE (CVMX_ADD_IO_SEG(0x00010F000086EC04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_CFG1 CVMX_BBP_ENC3G_CFG1_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_CFG1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_CFG1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086ED04ull);
}
#else
#define CVMX_BBP_ENC3G_CFG1 (CVMX_ADD_IO_SEG(0x00010F000086ED04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_CFG2 CVMX_BBP_ENC3G_CFG2_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_CFG2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_CFG2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086ED08ull);
}
#else
#define CVMX_BBP_ENC3G_CFG2 (CVMX_ADD_IO_SEG(0x00010F000086ED08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EINI1 CVMX_BBP_ENC3G_EINI1_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EINI1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EINI1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE00ull);
}
#else
#define CVMX_BBP_ENC3G_EINI1 (CVMX_ADD_IO_SEG(0x00010F000086EE00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EINI2 CVMX_BBP_ENC3G_EINI2_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EINI2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EINI2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE10ull);
}
#else
#define CVMX_BBP_ENC3G_EINI2 (CVMX_ADD_IO_SEG(0x00010F000086EE10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EINI3 CVMX_BBP_ENC3G_EINI3_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EINI3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EINI3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE20ull);
}
#else
#define CVMX_BBP_ENC3G_EINI3 (CVMX_ADD_IO_SEG(0x00010F000086EE20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EINI4 CVMX_BBP_ENC3G_EINI4_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EINI4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EINI4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE30ull);
}
#else
#define CVMX_BBP_ENC3G_EINI4 (CVMX_ADD_IO_SEG(0x00010F000086EE30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EINI5 CVMX_BBP_ENC3G_EINI5_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EINI5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EINI5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE40ull);
}
#else
#define CVMX_BBP_ENC3G_EINI5 (CVMX_ADD_IO_SEG(0x00010F000086EE40ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EINI6 CVMX_BBP_ENC3G_EINI6_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EINI6_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EINI6 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE50ull);
}
#else
#define CVMX_BBP_ENC3G_EINI6 (CVMX_ADD_IO_SEG(0x00010F000086EE50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EMINUS1 CVMX_BBP_ENC3G_EMINUS1_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EMINUS1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EMINUS1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE08ull);
}
#else
#define CVMX_BBP_ENC3G_EMINUS1 (CVMX_ADD_IO_SEG(0x00010F000086EE08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EMINUS2 CVMX_BBP_ENC3G_EMINUS2_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EMINUS2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EMINUS2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE18ull);
}
#else
#define CVMX_BBP_ENC3G_EMINUS2 (CVMX_ADD_IO_SEG(0x00010F000086EE18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EMINUS3 CVMX_BBP_ENC3G_EMINUS3_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EMINUS3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EMINUS3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE28ull);
}
#else
#define CVMX_BBP_ENC3G_EMINUS3 (CVMX_ADD_IO_SEG(0x00010F000086EE28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EMINUS4 CVMX_BBP_ENC3G_EMINUS4_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EMINUS4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EMINUS4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE38ull);
}
#else
#define CVMX_BBP_ENC3G_EMINUS4 (CVMX_ADD_IO_SEG(0x00010F000086EE38ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EMINUS5 CVMX_BBP_ENC3G_EMINUS5_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EMINUS5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EMINUS5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE48ull);
}
#else
#define CVMX_BBP_ENC3G_EMINUS5 (CVMX_ADD_IO_SEG(0x00010F000086EE48ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EMINUS6 CVMX_BBP_ENC3G_EMINUS6_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EMINUS6_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EMINUS6 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE58ull);
}
#else
#define CVMX_BBP_ENC3G_EMINUS6 (CVMX_ADD_IO_SEG(0x00010F000086EE58ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EPLUS1 CVMX_BBP_ENC3G_EPLUS1_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EPLUS1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EPLUS1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE04ull);
}
#else
#define CVMX_BBP_ENC3G_EPLUS1 (CVMX_ADD_IO_SEG(0x00010F000086EE04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EPLUS2 CVMX_BBP_ENC3G_EPLUS2_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EPLUS2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EPLUS2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE14ull);
}
#else
#define CVMX_BBP_ENC3G_EPLUS2 (CVMX_ADD_IO_SEG(0x00010F000086EE14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EPLUS3 CVMX_BBP_ENC3G_EPLUS3_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EPLUS3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EPLUS3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE24ull);
}
#else
#define CVMX_BBP_ENC3G_EPLUS3 (CVMX_ADD_IO_SEG(0x00010F000086EE24ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EPLUS4 CVMX_BBP_ENC3G_EPLUS4_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EPLUS4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EPLUS4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE34ull);
}
#else
#define CVMX_BBP_ENC3G_EPLUS4 (CVMX_ADD_IO_SEG(0x00010F000086EE34ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EPLUS5 CVMX_BBP_ENC3G_EPLUS5_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EPLUS5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EPLUS5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE44ull);
}
#else
#define CVMX_BBP_ENC3G_EPLUS5 (CVMX_ADD_IO_SEG(0x00010F000086EE44ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_EPLUS6 CVMX_BBP_ENC3G_EPLUS6_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_EPLUS6_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_EPLUS6 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EE54ull);
}
#else
#define CVMX_BBP_ENC3G_EPLUS6 (CVMX_ADD_IO_SEG(0x00010F000086EE54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_INT CVMX_BBP_ENC3G_INT_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_INT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_INT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EC40ull);
}
#else
#define CVMX_BBP_ENC3G_INT (CVMX_ADD_IO_SEG(0x00010F000086EC40ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_INT_EN CVMX_BBP_ENC3G_INT_EN_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_INT_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_INT_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EC44ull);
}
#else
#define CVMX_BBP_ENC3G_INT_EN (CVMX_ADD_IO_SEG(0x00010F000086EC44ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_START CVMX_BBP_ENC3G_START_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086ED00ull);
}
#else
#define CVMX_BBP_ENC3G_START (CVMX_ADD_IO_SEG(0x00010F000086ED00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ENC3G_STATUS CVMX_BBP_ENC3G_STATUS_FUNC()
static inline uint64_t CVMX_BBP_ENC3G_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ENC3G_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EC00ull);
}
#else
#define CVMX_BBP_ENC3G_STATUS (CVMX_ADD_IO_SEG(0x00010F000086EC00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_AUTO_CLK_GATE CVMX_BBP_IPM_AUTO_CLK_GATE_FUNC()
static inline uint64_t CVMX_BBP_IPM_AUTO_CLK_GATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_AUTO_CLK_GATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E80Cull);
}
#else
#define CVMX_BBP_IPM_AUTO_CLK_GATE (CVMX_ADD_IO_SEG(0x00010F000086E80Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_CH_GAIN CVMX_BBP_IPM_CH_GAIN_FUNC()
static inline uint64_t CVMX_BBP_IPM_CH_GAIN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_CH_GAIN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA08ull);
}
#else
#define CVMX_BBP_IPM_CH_GAIN (CVMX_ADD_IO_SEG(0x00010F000086EA08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_CORE_STATUS CVMX_BBP_IPM_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_IPM_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E808ull);
}
#else
#define CVMX_BBP_IPM_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F000086E808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_FRM_TIC_SET CVMX_BBP_IPM_FRM_TIC_SET_FUNC()
static inline uint64_t CVMX_BBP_IPM_FRM_TIC_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_FRM_TIC_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA1Cull);
}
#else
#define CVMX_BBP_IPM_FRM_TIC_SET (CVMX_ADD_IO_SEG(0x00010F000086EA1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_INTR_MSK CVMX_BBP_IPM_INTR_MSK_FUNC()
static inline uint64_t CVMX_BBP_IPM_INTR_MSK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_INTR_MSK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E90Cull);
}
#else
#define CVMX_BBP_IPM_INTR_MSK (CVMX_ADD_IO_SEG(0x00010F000086E90Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_INTR_SRC CVMX_BBP_IPM_INTR_SRC_FUNC()
static inline uint64_t CVMX_BBP_IPM_INTR_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_INTR_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E900ull);
}
#else
#define CVMX_BBP_IPM_INTR_SRC (CVMX_ADD_IO_SEG(0x00010F000086E900ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_MODULE_CTRL CVMX_BBP_IPM_MODULE_CTRL_FUNC()
static inline uint64_t CVMX_BBP_IPM_MODULE_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_MODULE_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E804ull);
}
#else
#define CVMX_BBP_IPM_MODULE_CTRL (CVMX_ADD_IO_SEG(0x00010F000086E804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_MODULE_STATUS CVMX_BBP_IPM_MODULE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_IPM_MODULE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_MODULE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E800ull);
}
#else
#define CVMX_BBP_IPM_MODULE_STATUS (CVMX_ADD_IO_SEG(0x00010F000086E800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_PAPR_CLIP_VAL CVMX_BBP_IPM_PAPR_CLIP_VAL_FUNC()
static inline uint64_t CVMX_BBP_IPM_PAPR_CLIP_VAL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_PAPR_CLIP_VAL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA28ull);
}
#else
#define CVMX_BBP_IPM_PAPR_CLIP_VAL (CVMX_ADD_IO_SEG(0x00010F000086EA28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_PAPR_EG_ADDR CVMX_BBP_IPM_PAPR_EG_ADDR_FUNC()
static inline uint64_t CVMX_BBP_IPM_PAPR_EG_ADDR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_PAPR_EG_ADDR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA30ull);
}
#else
#define CVMX_BBP_IPM_PAPR_EG_ADDR (CVMX_ADD_IO_SEG(0x00010F000086EA30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_PAPR_EG_DATA CVMX_BBP_IPM_PAPR_EG_DATA_FUNC()
static inline uint64_t CVMX_BBP_IPM_PAPR_EG_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_PAPR_EG_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA34ull);
}
#else
#define CVMX_BBP_IPM_PAPR_EG_DATA (CVMX_ADD_IO_SEG(0x00010F000086EA34ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_PAPR_EG_RDATA CVMX_BBP_IPM_PAPR_EG_RDATA_FUNC()
static inline uint64_t CVMX_BBP_IPM_PAPR_EG_RDATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_PAPR_EG_RDATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EB08ull);
}
#else
#define CVMX_BBP_IPM_PAPR_EG_RDATA (CVMX_ADD_IO_SEG(0x00010F000086EB08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_PAPR_EVM_CTRL CVMX_BBP_IPM_PAPR_EVM_CTRL_FUNC()
static inline uint64_t CVMX_BBP_IPM_PAPR_EVM_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_PAPR_EVM_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA2Cull);
}
#else
#define CVMX_BBP_IPM_PAPR_EVM_CTRL (CVMX_ADD_IO_SEG(0x00010F000086EA2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_RD_LAST_WAIT CVMX_BBP_IPM_RD_LAST_WAIT_FUNC()
static inline uint64_t CVMX_BBP_IPM_RD_LAST_WAIT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_RD_LAST_WAIT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA14ull);
}
#else
#define CVMX_BBP_IPM_RD_LAST_WAIT (CVMX_ADD_IO_SEG(0x00010F000086EA14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_RF_GAIN_CTRL CVMX_BBP_IPM_RF_GAIN_CTRL_FUNC()
static inline uint64_t CVMX_BBP_IPM_RF_GAIN_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_RF_GAIN_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA0Cull);
}
#else
#define CVMX_BBP_IPM_RF_GAIN_CTRL (CVMX_ADD_IO_SEG(0x00010F000086EA0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_RF_GAIN_SET CVMX_BBP_IPM_RF_GAIN_SET_FUNC()
static inline uint64_t CVMX_BBP_IPM_RF_GAIN_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_RF_GAIN_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA10ull);
}
#else
#define CVMX_BBP_IPM_RF_GAIN_SET (CVMX_ADD_IO_SEG(0x00010F000086EA10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_STATUS CVMX_BBP_IPM_STATUS_FUNC()
static inline uint64_t CVMX_BBP_IPM_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EB0Cull);
}
#else
#define CVMX_BBP_IPM_STATUS (CVMX_ADD_IO_SEG(0x00010F000086EB0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_SYMB_TIC_SET0 CVMX_BBP_IPM_SYMB_TIC_SET0_FUNC()
static inline uint64_t CVMX_BBP_IPM_SYMB_TIC_SET0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_SYMB_TIC_SET0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA38ull);
}
#else
#define CVMX_BBP_IPM_SYMB_TIC_SET0 (CVMX_ADD_IO_SEG(0x00010F000086EA38ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_SYMB_TIC_SET1 CVMX_BBP_IPM_SYMB_TIC_SET1_FUNC()
static inline uint64_t CVMX_BBP_IPM_SYMB_TIC_SET1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_SYMB_TIC_SET1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA40ull);
}
#else
#define CVMX_BBP_IPM_SYMB_TIC_SET1 (CVMX_ADD_IO_SEG(0x00010F000086EA40ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_SYS_CFG0 CVMX_BBP_IPM_SYS_CFG0_FUNC()
static inline uint64_t CVMX_BBP_IPM_SYS_CFG0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_SYS_CFG0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA00ull);
}
#else
#define CVMX_BBP_IPM_SYS_CFG0 (CVMX_ADD_IO_SEG(0x00010F000086EA00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_SYS_CFG1 CVMX_BBP_IPM_SYS_CFG1_FUNC()
static inline uint64_t CVMX_BBP_IPM_SYS_CFG1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_SYS_CFG1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA04ull);
}
#else
#define CVMX_BBP_IPM_SYS_CFG1 (CVMX_ADD_IO_SEG(0x00010F000086EA04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_TX_OUT_CTRL CVMX_BBP_IPM_TX_OUT_CTRL_FUNC()
static inline uint64_t CVMX_BBP_IPM_TX_OUT_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_TX_OUT_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA18ull);
}
#else
#define CVMX_BBP_IPM_TX_OUT_CTRL (CVMX_ADD_IO_SEG(0x00010F000086EA18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_VERSION CVMX_BBP_IPM_VERSION_FUNC()
static inline uint64_t CVMX_BBP_IPM_VERSION_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_VERSION not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EB00ull);
}
#else
#define CVMX_BBP_IPM_VERSION (CVMX_ADD_IO_SEG(0x00010F000086EB00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_WIN_COEF_ADDR CVMX_BBP_IPM_WIN_COEF_ADDR_FUNC()
static inline uint64_t CVMX_BBP_IPM_WIN_COEF_ADDR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_WIN_COEF_ADDR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA20ull);
}
#else
#define CVMX_BBP_IPM_WIN_COEF_ADDR (CVMX_ADD_IO_SEG(0x00010F000086EA20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_WIN_COEF_DATA CVMX_BBP_IPM_WIN_COEF_DATA_FUNC()
static inline uint64_t CVMX_BBP_IPM_WIN_COEF_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_WIN_COEF_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EA24ull);
}
#else
#define CVMX_BBP_IPM_WIN_COEF_DATA (CVMX_ADD_IO_SEG(0x00010F000086EA24ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_IPM_WIN_COEF_RDATA CVMX_BBP_IPM_WIN_COEF_RDATA_FUNC()
static inline uint64_t CVMX_BBP_IPM_WIN_COEF_RDATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_IPM_WIN_COEF_RDATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086EB04ull);
}
#else
#define CVMX_BBP_IPM_WIN_COEF_RDATA (CVMX_ADD_IO_SEG(0x00010F000086EB04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_CLK_CTRL CVMX_BBP_RAFE_CLK_CTRL_FUNC()
static inline uint64_t CVMX_BBP_RAFE_CLK_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_CLK_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828C0Cull);
}
#else
#define CVMX_BBP_RAFE_CLK_CTRL (CVMX_ADD_IO_SEG(0x00010F0000828C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_CONTROL CVMX_BBP_RAFE_CONTROL_FUNC()
static inline uint64_t CVMX_BBP_RAFE_CONTROL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_CONTROL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828C04ull);
}
#else
#define CVMX_BBP_RAFE_CONTROL (CVMX_ADD_IO_SEG(0x00010F0000828C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR1_COEF CVMX_BBP_RAFE_FIR1_COEF_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR1_COEF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR1_COEF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E14ull);
}
#else
#define CVMX_BBP_RAFE_FIR1_COEF (CVMX_ADD_IO_SEG(0x00010F0000828E14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR2_COEF_02 CVMX_BBP_RAFE_FIR2_COEF_02_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR2_COEF_02_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR2_COEF_02 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E18ull);
}
#else
#define CVMX_BBP_RAFE_FIR2_COEF_02 (CVMX_ADD_IO_SEG(0x00010F0000828E18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR2_COEF_4 CVMX_BBP_RAFE_FIR2_COEF_4_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR2_COEF_4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR2_COEF_4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E1Cull);
}
#else
#define CVMX_BBP_RAFE_FIR2_COEF_4 (CVMX_ADD_IO_SEG(0x00010F0000828E1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR3_COEF_01 CVMX_BBP_RAFE_FIR3_COEF_01_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR3_COEF_01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR3_COEF_01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E20ull);
}
#else
#define CVMX_BBP_RAFE_FIR3_COEF_01 (CVMX_ADD_IO_SEG(0x00010F0000828E20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR3_COEF_23 CVMX_BBP_RAFE_FIR3_COEF_23_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR3_COEF_23_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR3_COEF_23 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E24ull);
}
#else
#define CVMX_BBP_RAFE_FIR3_COEF_23 (CVMX_ADD_IO_SEG(0x00010F0000828E24ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR3_COEF_45 CVMX_BBP_RAFE_FIR3_COEF_45_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR3_COEF_45_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR3_COEF_45 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E28ull);
}
#else
#define CVMX_BBP_RAFE_FIR3_COEF_45 (CVMX_ADD_IO_SEG(0x00010F0000828E28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR3_COEF_67 CVMX_BBP_RAFE_FIR3_COEF_67_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR3_COEF_67_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR3_COEF_67 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E2Cull);
}
#else
#define CVMX_BBP_RAFE_FIR3_COEF_67 (CVMX_ADD_IO_SEG(0x00010F0000828E2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_FIR3_COEF_89 CVMX_BBP_RAFE_FIR3_COEF_89_FUNC()
static inline uint64_t CVMX_BBP_RAFE_FIR3_COEF_89_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_FIR3_COEF_89 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E30ull);
}
#else
#define CVMX_BBP_RAFE_FIR3_COEF_89 (CVMX_ADD_IO_SEG(0x00010F0000828E30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_HAB_VERSION CVMX_BBP_RAFE_HAB_VERSION_FUNC()
static inline uint64_t CVMX_BBP_RAFE_HAB_VERSION_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_HAB_VERSION not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828F00ull);
}
#else
#define CVMX_BBP_RAFE_HAB_VERSION (CVMX_ADD_IO_SEG(0x00010F0000828F00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_HW_CORE_STATUS CVMX_BBP_RAFE_HW_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RAFE_HW_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_HW_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828C08ull);
}
#else
#define CVMX_BBP_RAFE_HW_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F0000828C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_INTR_CNT_MAX CVMX_BBP_RAFE_INTR_CNT_MAX_FUNC()
static inline uint64_t CVMX_BBP_RAFE_INTR_CNT_MAX_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_INTR_CNT_MAX not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E34ull);
}
#else
#define CVMX_BBP_RAFE_INTR_CNT_MAX (CVMX_ADD_IO_SEG(0x00010F0000828E34ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_INT_MASK CVMX_BBP_RAFE_INT_MASK_FUNC()
static inline uint64_t CVMX_BBP_RAFE_INT_MASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_INT_MASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828D0Cull);
}
#else
#define CVMX_BBP_RAFE_INT_MASK (CVMX_ADD_IO_SEG(0x00010F0000828D0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_INT_SRC CVMX_BBP_RAFE_INT_SRC_FUNC()
static inline uint64_t CVMX_BBP_RAFE_INT_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_INT_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828D00ull);
}
#else
#define CVMX_BBP_RAFE_INT_SRC (CVMX_ADD_IO_SEG(0x00010F0000828D00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_OUT_END_SAMPLE CVMX_BBP_RAFE_OUT_END_SAMPLE_FUNC()
static inline uint64_t CVMX_BBP_RAFE_OUT_END_SAMPLE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_OUT_END_SAMPLE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E10ull);
}
#else
#define CVMX_BBP_RAFE_OUT_END_SAMPLE (CVMX_ADD_IO_SEG(0x00010F0000828E10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_OUT_START_SAMPLE CVMX_BBP_RAFE_OUT_START_SAMPLE_FUNC()
static inline uint64_t CVMX_BBP_RAFE_OUT_START_SAMPLE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_OUT_START_SAMPLE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E0Cull);
}
#else
#define CVMX_BBP_RAFE_OUT_START_SAMPLE (CVMX_ADD_IO_SEG(0x00010F0000828E0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_PHASE_INC CVMX_BBP_RAFE_PHASE_INC_FUNC()
static inline uint64_t CVMX_BBP_RAFE_PHASE_INC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_PHASE_INC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E04ull);
}
#else
#define CVMX_BBP_RAFE_PHASE_INC (CVMX_ADD_IO_SEG(0x00010F0000828E04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_PROC_START CVMX_BBP_RAFE_PROC_START_FUNC()
static inline uint64_t CVMX_BBP_RAFE_PROC_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_PROC_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E08ull);
}
#else
#define CVMX_BBP_RAFE_PROC_START (CVMX_ADD_IO_SEG(0x00010F0000828E08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_STATUS CVMX_BBP_RAFE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RAFE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828C00ull);
}
#else
#define CVMX_BBP_RAFE_STATUS (CVMX_ADD_IO_SEG(0x00010F0000828C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RAFE_SYS_CONF CVMX_BBP_RAFE_SYS_CONF_FUNC()
static inline uint64_t CVMX_BBP_RAFE_SYS_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RAFE_SYS_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828E00ull);
}
#else
#define CVMX_BBP_RAFE_SYS_CONF (CVMX_ADD_IO_SEG(0x00010F0000828E00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_1PPS_GEN_CFG CVMX_BBP_RFIF_1PPS_GEN_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_1PPS_GEN_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_1PPS_GEN_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680CCull);
}
#else
#define CVMX_BBP_RFIF_1PPS_GEN_CFG (CVMX_ADD_IO_SEG(0x00010F00008680CCull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_1PPS_SAMPLE_CNT_OFFSET CVMX_BBP_RFIF_1PPS_SAMPLE_CNT_OFFSET_FUNC()
static inline uint64_t CVMX_BBP_RFIF_1PPS_SAMPLE_CNT_OFFSET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_1PPS_SAMPLE_CNT_OFFSET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868104ull);
}
#else
#define CVMX_BBP_RFIF_1PPS_SAMPLE_CNT_OFFSET (CVMX_ADD_IO_SEG(0x00010F0000868104ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_1PPS_VERIF_GEN_EN CVMX_BBP_RFIF_1PPS_VERIF_GEN_EN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_1PPS_VERIF_GEN_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_1PPS_VERIF_GEN_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868110ull);
}
#else
#define CVMX_BBP_RFIF_1PPS_VERIF_GEN_EN (CVMX_ADD_IO_SEG(0x00010F0000868110ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_1PPS_VERIF_SCNT CVMX_BBP_RFIF_1PPS_VERIF_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_1PPS_VERIF_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_1PPS_VERIF_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868114ull);
}
#else
#define CVMX_BBP_RFIF_1PPS_VERIF_SCNT (CVMX_ADD_IO_SEG(0x00010F0000868114ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_CONF CVMX_BBP_RFIF_CONF_FUNC()
static inline uint64_t CVMX_BBP_RFIF_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868010ull);
}
#else
#define CVMX_BBP_RFIF_CONF (CVMX_ADD_IO_SEG(0x00010F0000868010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_CONF2 CVMX_BBP_RFIF_CONF2_FUNC()
static inline uint64_t CVMX_BBP_RFIF_CONF2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_CONF2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086801Cull);
}
#else
#define CVMX_BBP_RFIF_CONF2 (CVMX_ADD_IO_SEG(0x00010F000086801Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_DSP_RX_IS CVMX_BBP_RFIF_DSP_RX_IS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_DSP_RX_IS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_DSP_RX_IS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086840Cull);
}
#else
#define CVMX_BBP_RFIF_DSP_RX_IS (CVMX_ADD_IO_SEG(0x00010F000086840Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_DSP_RX_ISM CVMX_BBP_RFIF_DSP_RX_ISM_FUNC()
static inline uint64_t CVMX_BBP_RFIF_DSP_RX_ISM_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_DSP_RX_ISM not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868400ull);
}
#else
#define CVMX_BBP_RFIF_DSP_RX_ISM (CVMX_ADD_IO_SEG(0x00010F0000868400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_DSP_TX_IS CVMX_BBP_RFIF_DSP_TX_IS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_DSP_TX_IS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_DSP_TX_IS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A40Cull);
}
#else
#define CVMX_BBP_RFIF_DSP_TX_IS (CVMX_ADD_IO_SEG(0x00010F000086A40Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_DSP_TX_ISM CVMX_BBP_RFIF_DSP_TX_ISM_FUNC()
static inline uint64_t CVMX_BBP_RFIF_DSP_TX_ISM_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_DSP_TX_ISM not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A400ull);
}
#else
#define CVMX_BBP_RFIF_DSP_TX_ISM (CVMX_ADD_IO_SEG(0x00010F000086A400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_FIRS_ENABLE CVMX_BBP_RFIF_FIRS_ENABLE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_FIRS_ENABLE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_FIRS_ENABLE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008684C4ull);
}
#else
#define CVMX_BBP_RFIF_FIRS_ENABLE (CVMX_ADD_IO_SEG(0x00010F00008684C4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_FRAME_CNT CVMX_BBP_RFIF_FRAME_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_FRAME_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_FRAME_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868030ull);
}
#else
#define CVMX_BBP_RFIF_FRAME_CNT (CVMX_ADD_IO_SEG(0x00010F0000868030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_FRAME_L CVMX_BBP_RFIF_FRAME_L_FUNC()
static inline uint64_t CVMX_BBP_RFIF_FRAME_L_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_FRAME_L not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868014ull);
}
#else
#define CVMX_BBP_RFIF_FRAME_L (CVMX_ADD_IO_SEG(0x00010F0000868014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_GPO CVMX_BBP_RFIF_GPO_FUNC()
static inline uint64_t CVMX_BBP_RFIF_GPO_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_GPO not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008684C0ull);
}
#else
#define CVMX_BBP_RFIF_GPO (CVMX_ADD_IO_SEG(0x00010F00008684C0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_GPO_X(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 3)))))
		cvmx_warn("CVMX_BBP_RFIF_GPO_X(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868418ull) + ((offset) & 3) * 4;
}
#else
#define CVMX_BBP_RFIF_GPO_X(offset) (CVMX_ADD_IO_SEG(0x00010F0000868418ull) + ((offset) & 3) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_INT_CTRL_STATUS CVMX_BBP_RFIF_INT_CTRL_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_INT_CTRL_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_INT_CTRL_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086600Cull);
}
#else
#define CVMX_BBP_RFIF_INT_CTRL_STATUS (CVMX_ADD_IO_SEG(0x00010F000086600Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_INT_CTRL_STATUS_SHADOW CVMX_BBP_RFIF_INT_CTRL_STATUS_SHADOW_FUNC()
static inline uint64_t CVMX_BBP_RFIF_INT_CTRL_STATUS_SHADOW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_INT_CTRL_STATUS_SHADOW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086601Cull);
}
#else
#define CVMX_BBP_RFIF_INT_CTRL_STATUS_SHADOW (CVMX_ADD_IO_SEG(0x00010F000086601Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_MAX_SAMPLE_ADJ CVMX_BBP_RFIF_MAX_SAMPLE_ADJ_FUNC()
static inline uint64_t CVMX_BBP_RFIF_MAX_SAMPLE_ADJ_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_MAX_SAMPLE_ADJ not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680DCull);
}
#else
#define CVMX_BBP_RFIF_MAX_SAMPLE_ADJ (CVMX_ADD_IO_SEG(0x00010F00008680DCull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_MIN_SAMPLE_ADJ CVMX_BBP_RFIF_MIN_SAMPLE_ADJ_FUNC()
static inline uint64_t CVMX_BBP_RFIF_MIN_SAMPLE_ADJ_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_MIN_SAMPLE_ADJ not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680E0ull);
}
#else
#define CVMX_BBP_RFIF_MIN_SAMPLE_ADJ (CVMX_ADD_IO_SEG(0x00010F00008680E0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_NUM_RX_WIN CVMX_BBP_RFIF_NUM_RX_WIN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_NUM_RX_WIN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_NUM_RX_WIN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868018ull);
}
#else
#define CVMX_BBP_RFIF_NUM_RX_WIN (CVMX_ADD_IO_SEG(0x00010F0000868018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_NUM_TX_WIN CVMX_BBP_RFIF_NUM_TX_WIN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_NUM_TX_WIN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_NUM_TX_WIN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A418ull);
}
#else
#define CVMX_BBP_RFIF_NUM_TX_WIN (CVMX_ADD_IO_SEG(0x00010F000086A418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_PWM_ENABLE CVMX_BBP_RFIF_PWM_ENABLE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_PWM_ENABLE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_PWM_ENABLE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868180ull);
}
#else
#define CVMX_BBP_RFIF_PWM_ENABLE (CVMX_ADD_IO_SEG(0x00010F0000868180ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_PWM_HIGH_TIME CVMX_BBP_RFIF_PWM_HIGH_TIME_FUNC()
static inline uint64_t CVMX_BBP_RFIF_PWM_HIGH_TIME_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_PWM_HIGH_TIME not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868184ull);
}
#else
#define CVMX_BBP_RFIF_PWM_HIGH_TIME (CVMX_ADD_IO_SEG(0x00010F0000868184ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_PWM_LOW_TIME CVMX_BBP_RFIF_PWM_LOW_TIME_FUNC()
static inline uint64_t CVMX_BBP_RFIF_PWM_LOW_TIME_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_PWM_LOW_TIME not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868188ull);
}
#else
#define CVMX_BBP_RFIF_PWM_LOW_TIME (CVMX_ADD_IO_SEG(0x00010F0000868188ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RD_TIMER64_LSB CVMX_BBP_RFIF_RD_TIMER64_LSB_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RD_TIMER64_LSB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RD_TIMER64_LSB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008681ACull);
}
#else
#define CVMX_BBP_RFIF_RD_TIMER64_LSB (CVMX_ADD_IO_SEG(0x00010F00008681ACull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RD_TIMER64_MSB CVMX_BBP_RFIF_RD_TIMER64_MSB_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RD_TIMER64_MSB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RD_TIMER64_MSB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008681B0ull);
}
#else
#define CVMX_BBP_RFIF_RD_TIMER64_MSB (CVMX_ADD_IO_SEG(0x00010F00008681B0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_REAL_TIME_TIMER CVMX_BBP_RFIF_REAL_TIME_TIMER_FUNC()
static inline uint64_t CVMX_BBP_RFIF_REAL_TIME_TIMER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_REAL_TIME_TIMER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680C8ull);
}
#else
#define CVMX_BBP_RFIF_REAL_TIME_TIMER (CVMX_ADD_IO_SEG(0x00010F00008680C8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RF_CLK_TIMER CVMX_BBP_RFIF_RF_CLK_TIMER_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RF_CLK_TIMER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RF_CLK_TIMER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868194ull);
}
#else
#define CVMX_BBP_RFIF_RF_CLK_TIMER (CVMX_ADD_IO_SEG(0x00010F0000868194ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RF_CLK_TIMER_EN CVMX_BBP_RFIF_RF_CLK_TIMER_EN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RF_CLK_TIMER_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RF_CLK_TIMER_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868198ull);
}
#else
#define CVMX_BBP_RFIF_RF_CLK_TIMER_EN (CVMX_ADD_IO_SEG(0x00010F0000868198ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_CORRECT_ADJ CVMX_BBP_RFIF_RX_CORRECT_ADJ_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_CORRECT_ADJ_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_CORRECT_ADJ not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680E8ull);
}
#else
#define CVMX_BBP_RFIF_RX_CORRECT_ADJ (CVMX_ADD_IO_SEG(0x00010F00008680E8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_DIV_FIFO_CNT CVMX_BBP_RFIF_RX_DIV_FIFO_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_DIV_FIFO_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_DIV_FIFO_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000869900ull);
}
#else
#define CVMX_BBP_RFIF_RX_DIV_FIFO_CNT (CVMX_ADD_IO_SEG(0x00010F0000869900ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_DIV_GEN_PURP CVMX_BBP_RFIF_RX_DIV_GEN_PURP_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_DIV_GEN_PURP_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_DIV_GEN_PURP not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000869810ull);
}
#else
#define CVMX_BBP_RFIF_RX_DIV_GEN_PURP (CVMX_ADD_IO_SEG(0x00010F0000869810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_DIV_LOAD_CFG CVMX_BBP_RFIF_RX_DIV_LOAD_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_DIV_LOAD_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_DIV_LOAD_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000869908ull);
}
#else
#define CVMX_BBP_RFIF_RX_DIV_LOAD_CFG (CVMX_ADD_IO_SEG(0x00010F0000869908ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_DIV_STATUS CVMX_BBP_RFIF_RX_DIV_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_DIV_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_DIV_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868004ull);
}
#else
#define CVMX_BBP_RFIF_RX_DIV_STATUS (CVMX_ADD_IO_SEG(0x00010F0000868004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_DIV_TRANSFER_SIZE CVMX_BBP_RFIF_RX_DIV_TRANSFER_SIZE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_DIV_TRANSFER_SIZE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_DIV_TRANSFER_SIZE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086990Cull);
}
#else
#define CVMX_BBP_RFIF_RX_DIV_TRANSFER_SIZE (CVMX_ADD_IO_SEG(0x00010F000086990Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_FIFO_CNT CVMX_BBP_RFIF_RX_FIFO_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_FIFO_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_FIFO_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868500ull);
}
#else
#define CVMX_BBP_RFIF_RX_FIFO_CNT (CVMX_ADD_IO_SEG(0x00010F0000868500ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_IF_CFG CVMX_BBP_RFIF_RX_IF_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_IF_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_IF_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868038ull);
}
#else
#define CVMX_BBP_RFIF_RX_IF_CFG (CVMX_ADD_IO_SEG(0x00010F0000868038ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_LEAD_LAG CVMX_BBP_RFIF_RX_LEAD_LAG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_LEAD_LAG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_LEAD_LAG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868020ull);
}
#else
#define CVMX_BBP_RFIF_RX_LEAD_LAG (CVMX_ADD_IO_SEG(0x00010F0000868020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_LOAD_CFG CVMX_BBP_RFIF_RX_LOAD_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_LOAD_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_LOAD_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868508ull);
}
#else
#define CVMX_BBP_RFIF_RX_LOAD_CFG (CVMX_ADD_IO_SEG(0x00010F0000868508ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_OFFSET CVMX_BBP_RFIF_RX_OFFSET_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_OFFSET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_OFFSET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680D4ull);
}
#else
#define CVMX_BBP_RFIF_RX_OFFSET (CVMX_ADD_IO_SEG(0x00010F00008680D4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_OFFSET_ADJ_SCNT CVMX_BBP_RFIF_RX_OFFSET_ADJ_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_OFFSET_ADJ_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_OFFSET_ADJ_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868108ull);
}
#else
#define CVMX_BBP_RFIF_RX_OFFSET_ADJ_SCNT (CVMX_ADD_IO_SEG(0x00010F0000868108ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_STATUS CVMX_BBP_RFIF_RX_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868000ull);
}
#else
#define CVMX_BBP_RFIF_RX_STATUS (CVMX_ADD_IO_SEG(0x00010F0000868000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_SYNC_SCNT CVMX_BBP_RFIF_RX_SYNC_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_SYNC_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_SYNC_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680C4ull);
}
#else
#define CVMX_BBP_RFIF_RX_SYNC_SCNT (CVMX_ADD_IO_SEG(0x00010F00008680C4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_SYNC_VALUE CVMX_BBP_RFIF_RX_SYNC_VALUE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_SYNC_VALUE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_SYNC_VALUE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680C0ull);
}
#else
#define CVMX_BBP_RFIF_RX_SYNC_VALUE (CVMX_ADD_IO_SEG(0x00010F00008680C0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_TH CVMX_BBP_RFIF_RX_TH_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_TH_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_TH not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868410ull);
}
#else
#define CVMX_BBP_RFIF_RX_TH (CVMX_ADD_IO_SEG(0x00010F0000868410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_TRANSFER_SIZE CVMX_BBP_RFIF_RX_TRANSFER_SIZE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_TRANSFER_SIZE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_TRANSFER_SIZE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086850Cull);
}
#else
#define CVMX_BBP_RFIF_RX_TRANSFER_SIZE (CVMX_ADD_IO_SEG(0x00010F000086850Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_WIN_EN CVMX_BBP_RFIF_RX_WIN_EN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_WIN_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_WIN_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868040ull);
}
#else
#define CVMX_BBP_RFIF_RX_WIN_EN (CVMX_ADD_IO_SEG(0x00010F0000868040ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_RX_WIN_UPD_SCNT CVMX_BBP_RFIF_RX_WIN_UPD_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_RX_WIN_UPD_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_RX_WIN_UPD_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086803Cull);
}
#else
#define CVMX_BBP_RFIF_RX_WIN_UPD_SCNT (CVMX_ADD_IO_SEG(0x00010F000086803Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_RX_W_EX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 3)))))
		cvmx_warn("CVMX_BBP_RFIF_RX_W_EX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868084ull) + ((offset) & 3) * 4;
}
#else
#define CVMX_BBP_RFIF_RX_W_EX(offset) (CVMX_ADD_IO_SEG(0x00010F0000868084ull) + ((offset) & 3) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_RX_W_SX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 3)))))
		cvmx_warn("CVMX_BBP_RFIF_RX_W_SX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868044ull) + ((offset) & 3) * 4;
}
#else
#define CVMX_BBP_RFIF_RX_W_SX(offset) (CVMX_ADD_IO_SEG(0x00010F0000868044ull) + ((offset) & 3) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SAMPLE_ADJ_CFG CVMX_BBP_RFIF_SAMPLE_ADJ_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SAMPLE_ADJ_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SAMPLE_ADJ_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680E4ull);
}
#else
#define CVMX_BBP_RFIF_SAMPLE_ADJ_CFG (CVMX_ADD_IO_SEG(0x00010F00008680E4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SAMPLE_ADJ_ERROR CVMX_BBP_RFIF_SAMPLE_ADJ_ERROR_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SAMPLE_ADJ_ERROR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SAMPLE_ADJ_ERROR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868100ull);
}
#else
#define CVMX_BBP_RFIF_SAMPLE_ADJ_ERROR (CVMX_ADD_IO_SEG(0x00010F0000868100ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SAMPLE_CNT CVMX_BBP_RFIF_SAMPLE_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SAMPLE_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SAMPLE_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868028ull);
}
#else
#define CVMX_BBP_RFIF_SAMPLE_CNT (CVMX_ADD_IO_SEG(0x00010F0000868028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SKIP_FRM_CNT_BITS CVMX_BBP_RFIF_SKIP_FRM_CNT_BITS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SKIP_FRM_CNT_BITS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SKIP_FRM_CNT_BITS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868444ull);
}
#else
#define CVMX_BBP_RFIF_SKIP_FRM_CNT_BITS (CVMX_ADD_IO_SEG(0x00010F0000868444ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_SPI_CMDSX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 63)))))
		cvmx_warn("CVMX_BBP_RFIF_SPI_CMDSX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868800ull) + ((offset) & 63) * 4;
}
#else
#define CVMX_BBP_RFIF_SPI_CMDSX(offset) (CVMX_ADD_IO_SEG(0x00010F0000868800ull) + ((offset) & 63) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_SPI_CMD_ATTRX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 63)))))
		cvmx_warn("CVMX_BBP_RFIF_SPI_CMD_ATTRX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868A00ull) + ((offset) & 63) * 4;
}
#else
#define CVMX_BBP_RFIF_SPI_CMD_ATTRX(offset) (CVMX_ADD_IO_SEG(0x00010F0000868A00ull) + ((offset) & 63) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SPI_CONF0 CVMX_BBP_RFIF_SPI_CONF0_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SPI_CONF0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SPI_CONF0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868428ull);
}
#else
#define CVMX_BBP_RFIF_SPI_CONF0 (CVMX_ADD_IO_SEG(0x00010F0000868428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SPI_CONF1 CVMX_BBP_RFIF_SPI_CONF1_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SPI_CONF1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SPI_CONF1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086842Cull);
}
#else
#define CVMX_BBP_RFIF_SPI_CONF1 (CVMX_ADD_IO_SEG(0x00010F000086842Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SPI_CTRL CVMX_BBP_RFIF_SPI_CTRL_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SPI_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SPI_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000866008ull);
}
#else
#define CVMX_BBP_RFIF_SPI_CTRL (CVMX_ADD_IO_SEG(0x00010F0000866008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_SPI_DINX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 63)))))
		cvmx_warn("CVMX_BBP_RFIF_SPI_DINX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868900ull) + ((offset) & 63) * 4;
}
#else
#define CVMX_BBP_RFIF_SPI_DINX(offset) (CVMX_ADD_IO_SEG(0x00010F0000868900ull) + ((offset) & 63) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SPI_RX_DATA CVMX_BBP_RFIF_SPI_RX_DATA_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SPI_RX_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SPI_RX_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000866000ull);
}
#else
#define CVMX_BBP_RFIF_SPI_RX_DATA (CVMX_ADD_IO_SEG(0x00010F0000866000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SPI_STATUS CVMX_BBP_RFIF_SPI_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SPI_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SPI_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000866010ull);
}
#else
#define CVMX_BBP_RFIF_SPI_STATUS (CVMX_ADD_IO_SEG(0x00010F0000866010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_SPI_TX_DATA CVMX_BBP_RFIF_SPI_TX_DATA_FUNC()
static inline uint64_t CVMX_BBP_RFIF_SPI_TX_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_SPI_TX_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000866004ull);
}
#else
#define CVMX_BBP_RFIF_SPI_TX_DATA (CVMX_ADD_IO_SEG(0x00010F0000866004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_SPI_X_LL(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 3)))))
		cvmx_warn("CVMX_BBP_RFIF_SPI_X_LL(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868430ull) + ((offset) & 3) * 4;
}
#else
#define CVMX_BBP_RFIF_SPI_X_LL(offset) (CVMX_ADD_IO_SEG(0x00010F0000868430ull) + ((offset) & 3) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TIMER64_CFG CVMX_BBP_RFIF_TIMER64_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TIMER64_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TIMER64_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008681A0ull);
}
#else
#define CVMX_BBP_RFIF_TIMER64_CFG (CVMX_ADD_IO_SEG(0x00010F00008681A0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TIMER64_EN CVMX_BBP_RFIF_TIMER64_EN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TIMER64_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TIMER64_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086819Cull);
}
#else
#define CVMX_BBP_RFIF_TIMER64_EN (CVMX_ADD_IO_SEG(0x00010F000086819Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_TTI_SCNT_INTX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 7)))))
		cvmx_warn("CVMX_BBP_RFIF_TTI_SCNT_INTX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000868140ull) + ((offset) & 7) * 4;
}
#else
#define CVMX_BBP_RFIF_TTI_SCNT_INTX(offset) (CVMX_ADD_IO_SEG(0x00010F0000868140ull) + ((offset) & 7) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TTI_SCNT_INT_CLR CVMX_BBP_RFIF_TTI_SCNT_INT_CLR_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TTI_SCNT_INT_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TTI_SCNT_INT_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868118ull);
}
#else
#define CVMX_BBP_RFIF_TTI_SCNT_INT_CLR (CVMX_ADD_IO_SEG(0x00010F0000868118ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TTI_SCNT_INT_EN CVMX_BBP_RFIF_TTI_SCNT_INT_EN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TTI_SCNT_INT_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TTI_SCNT_INT_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868124ull);
}
#else
#define CVMX_BBP_RFIF_TTI_SCNT_INT_EN (CVMX_ADD_IO_SEG(0x00010F0000868124ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TTI_SCNT_INT_MAP CVMX_BBP_RFIF_TTI_SCNT_INT_MAP_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TTI_SCNT_INT_MAP_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TTI_SCNT_INT_MAP not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868120ull);
}
#else
#define CVMX_BBP_RFIF_TTI_SCNT_INT_MAP (CVMX_ADD_IO_SEG(0x00010F0000868120ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TTI_SCNT_INT_STAT CVMX_BBP_RFIF_TTI_SCNT_INT_STAT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TTI_SCNT_INT_STAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TTI_SCNT_INT_STAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086811Cull);
}
#else
#define CVMX_BBP_RFIF_TTI_SCNT_INT_STAT (CVMX_ADD_IO_SEG(0x00010F000086811Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_CORRECT_ADJ CVMX_BBP_RFIF_TX_CORRECT_ADJ_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_CORRECT_ADJ_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_CORRECT_ADJ not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680ECull);
}
#else
#define CVMX_BBP_RFIF_TX_CORRECT_ADJ (CVMX_ADD_IO_SEG(0x00010F00008680ECull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_DIV_FIFO_CNT CVMX_BBP_RFIF_TX_DIV_FIFO_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_DIV_FIFO_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_DIV_FIFO_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A900ull);
}
#else
#define CVMX_BBP_RFIF_TX_DIV_FIFO_CNT (CVMX_ADD_IO_SEG(0x00010F000086A900ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_DIV_GEN_PURP CVMX_BBP_RFIF_TX_DIV_GEN_PURP_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_DIV_GEN_PURP_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_DIV_GEN_PURP not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A810ull);
}
#else
#define CVMX_BBP_RFIF_TX_DIV_GEN_PURP (CVMX_ADD_IO_SEG(0x00010F000086A810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_DIV_LOAD_CFG CVMX_BBP_RFIF_TX_DIV_LOAD_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_DIV_LOAD_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_DIV_LOAD_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A908ull);
}
#else
#define CVMX_BBP_RFIF_TX_DIV_LOAD_CFG (CVMX_ADD_IO_SEG(0x00010F000086A908ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_DIV_STATUS CVMX_BBP_RFIF_TX_DIV_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_DIV_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_DIV_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086800Cull);
}
#else
#define CVMX_BBP_RFIF_TX_DIV_STATUS (CVMX_ADD_IO_SEG(0x00010F000086800Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_DIV_TRANSFER_SIZE CVMX_BBP_RFIF_TX_DIV_TRANSFER_SIZE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_DIV_TRANSFER_SIZE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_DIV_TRANSFER_SIZE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A90Cull);
}
#else
#define CVMX_BBP_RFIF_TX_DIV_TRANSFER_SIZE (CVMX_ADD_IO_SEG(0x00010F000086A90Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_FIFO_CNT CVMX_BBP_RFIF_TX_FIFO_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_FIFO_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_FIFO_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A500ull);
}
#else
#define CVMX_BBP_RFIF_TX_FIFO_CNT (CVMX_ADD_IO_SEG(0x00010F000086A500ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_GEN_PURP CVMX_BBP_RFIF_TX_GEN_PURP_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_GEN_PURP_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_GEN_PURP not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A410ull);
}
#else
#define CVMX_BBP_RFIF_TX_GEN_PURP (CVMX_ADD_IO_SEG(0x00010F000086A410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_IF_CFG CVMX_BBP_RFIF_TX_IF_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_IF_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_IF_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868034ull);
}
#else
#define CVMX_BBP_RFIF_TX_IF_CFG (CVMX_ADD_IO_SEG(0x00010F0000868034ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_LEAD_LAG CVMX_BBP_RFIF_TX_LEAD_LAG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_LEAD_LAG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_LEAD_LAG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868024ull);
}
#else
#define CVMX_BBP_RFIF_TX_LEAD_LAG (CVMX_ADD_IO_SEG(0x00010F0000868024ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_LOAD_CFG CVMX_BBP_RFIF_TX_LOAD_CFG_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_LOAD_CFG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_LOAD_CFG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A508ull);
}
#else
#define CVMX_BBP_RFIF_TX_LOAD_CFG (CVMX_ADD_IO_SEG(0x00010F000086A508ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_OFFSET CVMX_BBP_RFIF_TX_OFFSET_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_OFFSET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_OFFSET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008680D8ull);
}
#else
#define CVMX_BBP_RFIF_TX_OFFSET (CVMX_ADD_IO_SEG(0x00010F00008680D8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_OFFSET_ADJ_SCNT CVMX_BBP_RFIF_TX_OFFSET_ADJ_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_OFFSET_ADJ_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_OFFSET_ADJ_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086810Cull);
}
#else
#define CVMX_BBP_RFIF_TX_OFFSET_ADJ_SCNT (CVMX_ADD_IO_SEG(0x00010F000086810Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_SAMPLE_CNT CVMX_BBP_RFIF_TX_SAMPLE_CNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_SAMPLE_CNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_SAMPLE_CNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A428ull);
}
#else
#define CVMX_BBP_RFIF_TX_SAMPLE_CNT (CVMX_ADD_IO_SEG(0x00010F000086A428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_STATUS CVMX_BBP_RFIF_TX_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868008ull);
}
#else
#define CVMX_BBP_RFIF_TX_STATUS (CVMX_ADD_IO_SEG(0x00010F0000868008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_SYNC_SCNT CVMX_BBP_RFIF_TX_SYNC_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_SYNC_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_SYNC_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A4C4ull);
}
#else
#define CVMX_BBP_RFIF_TX_SYNC_SCNT (CVMX_ADD_IO_SEG(0x00010F000086A4C4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_SYNC_VALUE CVMX_BBP_RFIF_TX_SYNC_VALUE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_SYNC_VALUE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_SYNC_VALUE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A4C0ull);
}
#else
#define CVMX_BBP_RFIF_TX_SYNC_VALUE (CVMX_ADD_IO_SEG(0x00010F000086A4C0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_TH CVMX_BBP_RFIF_TX_TH_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_TH_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_TH not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000868414ull);
}
#else
#define CVMX_BBP_RFIF_TX_TH (CVMX_ADD_IO_SEG(0x00010F0000868414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_TRANSFER_SIZE CVMX_BBP_RFIF_TX_TRANSFER_SIZE_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_TRANSFER_SIZE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_TRANSFER_SIZE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A50Cull);
}
#else
#define CVMX_BBP_RFIF_TX_TRANSFER_SIZE (CVMX_ADD_IO_SEG(0x00010F000086A50Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_WIN_EN CVMX_BBP_RFIF_TX_WIN_EN_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_WIN_EN_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_WIN_EN not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A440ull);
}
#else
#define CVMX_BBP_RFIF_TX_WIN_EN (CVMX_ADD_IO_SEG(0x00010F000086A440ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_TX_WIN_UPD_SCNT CVMX_BBP_RFIF_TX_WIN_UPD_SCNT_FUNC()
static inline uint64_t CVMX_BBP_RFIF_TX_WIN_UPD_SCNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_TX_WIN_UPD_SCNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086A43Cull);
}
#else
#define CVMX_BBP_RFIF_TX_WIN_UPD_SCNT (CVMX_ADD_IO_SEG(0x00010F000086A43Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_TX_W_EX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 3)))))
		cvmx_warn("CVMX_BBP_RFIF_TX_W_EX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086A484ull) + ((offset) & 3) * 4;
}
#else
#define CVMX_BBP_RFIF_TX_W_EX(offset) (CVMX_ADD_IO_SEG(0x00010F000086A484ull) + ((offset) & 3) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RFIF_TX_W_SX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 3)))))
		cvmx_warn("CVMX_BBP_RFIF_TX_W_SX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086A444ull) + ((offset) & 3) * 4;
}
#else
#define CVMX_BBP_RFIF_TX_W_SX(offset) (CVMX_ADD_IO_SEG(0x00010F000086A444ull) + ((offset) & 3) * 4)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_WR_TIMER64_LSB CVMX_BBP_RFIF_WR_TIMER64_LSB_FUNC()
static inline uint64_t CVMX_BBP_RFIF_WR_TIMER64_LSB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_WR_TIMER64_LSB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008681A4ull);
}
#else
#define CVMX_BBP_RFIF_WR_TIMER64_LSB (CVMX_ADD_IO_SEG(0x00010F00008681A4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RFIF_WR_TIMER64_MSB CVMX_BBP_RFIF_WR_TIMER64_MSB_FUNC()
static inline uint64_t CVMX_BBP_RFIF_WR_TIMER64_MSB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RFIF_WR_TIMER64_MSB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008681A8ull);
}
#else
#define CVMX_BBP_RFIF_WR_TIMER64_MSB (CVMX_ADD_IO_SEG(0x00010F00008681A8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_CLKENB0_CLR CVMX_BBP_RSTCLK_CLKENB0_CLR_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_CLKENB0_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_CLKENB0_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844428ull);
}
#else
#define CVMX_BBP_RSTCLK_CLKENB0_CLR (CVMX_ADD_IO_SEG(0x00010F0000844428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_CLKENB0_SET CVMX_BBP_RSTCLK_CLKENB0_SET_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_CLKENB0_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_CLKENB0_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844424ull);
}
#else
#define CVMX_BBP_RSTCLK_CLKENB0_SET (CVMX_ADD_IO_SEG(0x00010F0000844424ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_CLKENB0_STATE CVMX_BBP_RSTCLK_CLKENB0_STATE_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_CLKENB0_STATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_CLKENB0_STATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844420ull);
}
#else
#define CVMX_BBP_RSTCLK_CLKENB0_STATE (CVMX_ADD_IO_SEG(0x00010F0000844420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_CLKENB1_CLR CVMX_BBP_RSTCLK_CLKENB1_CLR_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_CLKENB1_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_CLKENB1_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844438ull);
}
#else
#define CVMX_BBP_RSTCLK_CLKENB1_CLR (CVMX_ADD_IO_SEG(0x00010F0000844438ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_CLKENB1_SET CVMX_BBP_RSTCLK_CLKENB1_SET_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_CLKENB1_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_CLKENB1_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844434ull);
}
#else
#define CVMX_BBP_RSTCLK_CLKENB1_SET (CVMX_ADD_IO_SEG(0x00010F0000844434ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_CLKENB1_STATE CVMX_BBP_RSTCLK_CLKENB1_STATE_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_CLKENB1_STATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_CLKENB1_STATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844430ull);
}
#else
#define CVMX_BBP_RSTCLK_CLKENB1_STATE (CVMX_ADD_IO_SEG(0x00010F0000844430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_DSPSTALL_CLR CVMX_BBP_RSTCLK_DSPSTALL_CLR_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_DSPSTALL_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_DSPSTALL_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844448ull);
}
#else
#define CVMX_BBP_RSTCLK_DSPSTALL_CLR (CVMX_ADD_IO_SEG(0x00010F0000844448ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_DSPSTALL_SET CVMX_BBP_RSTCLK_DSPSTALL_SET_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_DSPSTALL_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_DSPSTALL_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844444ull);
}
#else
#define CVMX_BBP_RSTCLK_DSPSTALL_SET (CVMX_ADD_IO_SEG(0x00010F0000844444ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_DSPSTALL_STATE CVMX_BBP_RSTCLK_DSPSTALL_STATE_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_DSPSTALL_STATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_DSPSTALL_STATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844440ull);
}
#else
#define CVMX_BBP_RSTCLK_DSPSTALL_STATE (CVMX_ADD_IO_SEG(0x00010F0000844440ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR0_CLRMASK CVMX_BBP_RSTCLK_INTR0_CLRMASK_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR0_CLRMASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR0_CLRMASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844498ull);
}
#else
#define CVMX_BBP_RSTCLK_INTR0_CLRMASK (CVMX_ADD_IO_SEG(0x00010F0000844498ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR0_MASK CVMX_BBP_RSTCLK_INTR0_MASK_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR0_MASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR0_MASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844490ull);
}
#else
#define CVMX_BBP_RSTCLK_INTR0_MASK (CVMX_ADD_IO_SEG(0x00010F0000844490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR0_SETMASK CVMX_BBP_RSTCLK_INTR0_SETMASK_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR0_SETMASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR0_SETMASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844494ull);
}
#else
#define CVMX_BBP_RSTCLK_INTR0_SETMASK (CVMX_ADD_IO_SEG(0x00010F0000844494ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR0_STATUS CVMX_BBP_RSTCLK_INTR0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084449Cull);
}
#else
#define CVMX_BBP_RSTCLK_INTR0_STATUS (CVMX_ADD_IO_SEG(0x00010F000084449Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR1_CLRMASK CVMX_BBP_RSTCLK_INTR1_CLRMASK_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR1_CLRMASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR1_CLRMASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008444A8ull);
}
#else
#define CVMX_BBP_RSTCLK_INTR1_CLRMASK (CVMX_ADD_IO_SEG(0x00010F00008444A8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR1_MASK CVMX_BBP_RSTCLK_INTR1_MASK_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR1_MASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR1_MASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008444A0ull);
}
#else
#define CVMX_BBP_RSTCLK_INTR1_MASK (CVMX_ADD_IO_SEG(0x00010F00008444A0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR1_SETMASK CVMX_BBP_RSTCLK_INTR1_SETMASK_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR1_SETMASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR1_SETMASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008444A4ull);
}
#else
#define CVMX_BBP_RSTCLK_INTR1_SETMASK (CVMX_ADD_IO_SEG(0x00010F00008444A4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_INTR1_STATUS CVMX_BBP_RSTCLK_INTR1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_INTR1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_INTR1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008444ACull);
}
#else
#define CVMX_BBP_RSTCLK_INTR1_STATUS (CVMX_ADD_IO_SEG(0x00010F00008444ACull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_PHY_CONFIG CVMX_BBP_RSTCLK_PHY_CONFIG_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_PHY_CONFIG_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_PHY_CONFIG not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844450ull);
}
#else
#define CVMX_BBP_RSTCLK_PHY_CONFIG (CVMX_ADD_IO_SEG(0x00010F0000844450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_RESET0_CLR CVMX_BBP_RSTCLK_RESET0_CLR_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_RESET0_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_RESET0_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844408ull);
}
#else
#define CVMX_BBP_RSTCLK_RESET0_CLR (CVMX_ADD_IO_SEG(0x00010F0000844408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_RESET0_SET CVMX_BBP_RSTCLK_RESET0_SET_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_RESET0_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_RESET0_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844404ull);
}
#else
#define CVMX_BBP_RSTCLK_RESET0_SET (CVMX_ADD_IO_SEG(0x00010F0000844404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_RESET0_STATE CVMX_BBP_RSTCLK_RESET0_STATE_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_RESET0_STATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_RESET0_STATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844400ull);
}
#else
#define CVMX_BBP_RSTCLK_RESET0_STATE (CVMX_ADD_IO_SEG(0x00010F0000844400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_RESET1_CLR CVMX_BBP_RSTCLK_RESET1_CLR_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_RESET1_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_RESET1_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844418ull);
}
#else
#define CVMX_BBP_RSTCLK_RESET1_CLR (CVMX_ADD_IO_SEG(0x00010F0000844418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_RESET1_SET CVMX_BBP_RSTCLK_RESET1_SET_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_RESET1_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_RESET1_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844414ull);
}
#else
#define CVMX_BBP_RSTCLK_RESET1_SET (CVMX_ADD_IO_SEG(0x00010F0000844414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_RESET1_STATE CVMX_BBP_RSTCLK_RESET1_STATE_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_RESET1_STATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_RESET1_STATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844410ull);
}
#else
#define CVMX_BBP_RSTCLK_RESET1_STATE (CVMX_ADD_IO_SEG(0x00010F0000844410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_SW_INTR_CLR CVMX_BBP_RSTCLK_SW_INTR_CLR_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_SW_INTR_CLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_SW_INTR_CLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844488ull);
}
#else
#define CVMX_BBP_RSTCLK_SW_INTR_CLR (CVMX_ADD_IO_SEG(0x00010F0000844488ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_SW_INTR_SET CVMX_BBP_RSTCLK_SW_INTR_SET_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_SW_INTR_SET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_SW_INTR_SET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844484ull);
}
#else
#define CVMX_BBP_RSTCLK_SW_INTR_SET (CVMX_ADD_IO_SEG(0x00010F0000844484ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_SW_INTR_STATUS CVMX_BBP_RSTCLK_SW_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_SW_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_SW_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844480ull);
}
#else
#define CVMX_BBP_RSTCLK_SW_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000844480ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_TIMER_CTL CVMX_BBP_RSTCLK_TIMER_CTL_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_TIMER_CTL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_TIMER_CTL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844460ull);
}
#else
#define CVMX_BBP_RSTCLK_TIMER_CTL (CVMX_ADD_IO_SEG(0x00010F0000844460ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_TIMER_MAX CVMX_BBP_RSTCLK_TIMER_MAX_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_TIMER_MAX_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_TIMER_MAX not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844468ull);
}
#else
#define CVMX_BBP_RSTCLK_TIMER_MAX (CVMX_ADD_IO_SEG(0x00010F0000844468ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_TIMER_VALUE CVMX_BBP_RSTCLK_TIMER_VALUE_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_TIMER_VALUE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_TIMER_VALUE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844464ull);
}
#else
#define CVMX_BBP_RSTCLK_TIMER_VALUE (CVMX_ADD_IO_SEG(0x00010F0000844464ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RSTCLK_VERSION CVMX_BBP_RSTCLK_VERSION_FUNC()
static inline uint64_t CVMX_BBP_RSTCLK_VERSION_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RSTCLK_VERSION not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000844470ull);
}
#else
#define CVMX_BBP_RSTCLK_VERSION (CVMX_ADD_IO_SEG(0x00010F0000844470ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_CNTL_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_CNTL_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008201E4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX0INT_CNTL_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008201E4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_CNTL_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_CNTL_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008201E0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX0INT_CNTL_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008201E0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_INDEX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_INDEX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008201A4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX0INT_INDEX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008201A4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_INDEX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_INDEX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008201A0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX0INT_INDEX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008201A0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_MISC_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820134ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_MISC_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820134ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_MISC_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820114ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_MISC_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820114ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_MISC_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820034ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_MISC_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820034ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_MISC_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820014ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_MISC_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820014ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_MISC_RINT CVMX_BBP_RX0INT_MISC_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_MISC_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820194ull);
}
#else
#define CVMX_BBP_RX0INT_MISC_RINT (CVMX_ADD_IO_SEG(0x00010F0000820194ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_MISC_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008200B4ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_MISC_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008200B4ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_MISC_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_MISC_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820094ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_MISC_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820094ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RDQ_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000082012Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RDQ_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F000082012Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RDQ_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000082010Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RDQ_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000082010Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RDQ_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000082002Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RDQ_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F000082002Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RDQ_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000000000Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RDQ_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000000000Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_RDQ_RINT CVMX_BBP_RX0INT_RDQ_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_RDQ_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082018Cull);
}
#else
#define CVMX_BBP_RX0INT_RDQ_RINT (CVMX_ADD_IO_SEG(0x00010F000082018Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RDQ_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008200ACull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RDQ_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008200ACull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RDQ_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RDQ_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000082008Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RDQ_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000082008Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RD_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RD_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820124ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RD_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820124ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RD_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RD_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820104ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RD_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820104ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RD_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RD_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820024ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RD_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820024ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RD_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RD_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820004ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RD_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820004ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_RD_RINT CVMX_BBP_RX0INT_RD_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_RD_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_RD_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820184ull);
}
#else
#define CVMX_BBP_RX0INT_RD_RINT (CVMX_ADD_IO_SEG(0x00010F0000820184ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RD_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RD_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008200A4ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RD_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008200A4ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_RD_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_RD_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820084ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_RD_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820084ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_STAT_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_STAT_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008201C4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX0INT_STAT_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008201C4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_STAT_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_STAT_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008201C0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX0INT_STAT_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008201C0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_SWCLR CVMX_BBP_RX0INT_SWCLR_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_SWCLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_SWCLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820204ull);
}
#else
#define CVMX_BBP_RX0INT_SWCLR (CVMX_ADD_IO_SEG(0x00010F0000820204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_SWSET CVMX_BBP_RX0INT_SWSET_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_SWSET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_SWSET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820200ull);
}
#else
#define CVMX_BBP_RX0INT_SWSET (CVMX_ADD_IO_SEG(0x00010F0000820200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_SW_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_SW_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820130ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_SW_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820130ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_SW_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_SW_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820110ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_SW_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820110ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_SW_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_SW_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820030ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_SW_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820030ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_SW_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_SW_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820010ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_SW_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820010ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_SW_RINT CVMX_BBP_RX0INT_SW_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_SW_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_SW_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820190ull);
}
#else
#define CVMX_BBP_RX0INT_SW_RINT (CVMX_ADD_IO_SEG(0x00010F0000820190ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_SW_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_SW_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008200B0ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_SW_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008200B0ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_SW_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_SW_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820090ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_SW_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820090ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WRQ_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820128ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WRQ_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820128ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WRQ_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820108ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WRQ_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820108ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WRQ_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820028ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WRQ_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820028ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WRQ_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820008ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WRQ_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820008ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_WRQ_RINT CVMX_BBP_RX0INT_WRQ_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_WRQ_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820188ull);
}
#else
#define CVMX_BBP_RX0INT_WRQ_RINT (CVMX_ADD_IO_SEG(0x00010F0000820188ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WRQ_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008200A8ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WRQ_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008200A8ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WRQ_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WRQ_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820088ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WRQ_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820088ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WR_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WR_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820120ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WR_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820120ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WR_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WR_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820100ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WR_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820100ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WR_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WR_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820020ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WR_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820020ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WR_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WR_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820000ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WR_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820000ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0INT_WR_RINT CVMX_BBP_RX0INT_WR_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX0INT_WR_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0INT_WR_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000820180ull);
}
#else
#define CVMX_BBP_RX0INT_WR_RINT (CVMX_ADD_IO_SEG(0x00010F0000820180ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WR_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WR_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008200A0ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WR_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008200A0ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0INT_WR_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX0INT_WR_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000820080ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX0INT_WR_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000820080ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_AUTOGATE CVMX_BBP_RX0SEQ_AUTOGATE_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_AUTOGATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_AUTOGATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082800Cull);
}
#else
#define CVMX_BBP_RX0SEQ_AUTOGATE (CVMX_ADD_IO_SEG(0x00010F000082800Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_GPI_RD00 CVMX_BBP_RX0SEQ_GPI_RD00_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_GPI_RD00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_GPI_RD00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828240ull);
}
#else
#define CVMX_BBP_RX0SEQ_GPI_RD00 (CVMX_ADD_IO_SEG(0x00010F0000828240ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_GPI_RD01 CVMX_BBP_RX0SEQ_GPI_RD01_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_GPI_RD01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_GPI_RD01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828244ull);
}
#else
#define CVMX_BBP_RX0SEQ_GPI_RD01 (CVMX_ADD_IO_SEG(0x00010F0000828244ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_GPO_CLR00 CVMX_BBP_RX0SEQ_GPO_CLR00_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_GPO_CLR00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_GPO_CLR00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828220ull);
}
#else
#define CVMX_BBP_RX0SEQ_GPO_CLR00 (CVMX_ADD_IO_SEG(0x00010F0000828220ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_GPO_CLR01 CVMX_BBP_RX0SEQ_GPO_CLR01_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_GPO_CLR01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_GPO_CLR01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828224ull);
}
#else
#define CVMX_BBP_RX0SEQ_GPO_CLR01 (CVMX_ADD_IO_SEG(0x00010F0000828224ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_GPO_SET00 CVMX_BBP_RX0SEQ_GPO_SET00_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_GPO_SET00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_GPO_SET00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828200ull);
}
#else
#define CVMX_BBP_RX0SEQ_GPO_SET00 (CVMX_ADD_IO_SEG(0x00010F0000828200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_GPO_SET01 CVMX_BBP_RX0SEQ_GPO_SET01_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_GPO_SET01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_GPO_SET01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828204ull);
}
#else
#define CVMX_BBP_RX0SEQ_GPO_SET01 (CVMX_ADD_IO_SEG(0x00010F0000828204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_PARAM0 CVMX_BBP_RX0SEQ_PARAM0_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_PARAM0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_PARAM0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008280C0ull);
}
#else
#define CVMX_BBP_RX0SEQ_PARAM0 (CVMX_ADD_IO_SEG(0x00010F00008280C0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_PARAM1 CVMX_BBP_RX0SEQ_PARAM1_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_PARAM1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_PARAM1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008280C4ull);
}
#else
#define CVMX_BBP_RX0SEQ_PARAM1 (CVMX_ADD_IO_SEG(0x00010F00008280C4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_RAMACC CVMX_BBP_RX0SEQ_RAMACC_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_RAMACC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_RAMACC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828080ull);
}
#else
#define CVMX_BBP_RX0SEQ_RAMACC (CVMX_ADD_IO_SEG(0x00010F0000828080ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_RAMRD_LSW CVMX_BBP_RX0SEQ_RAMRD_LSW_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_RAMRD_LSW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_RAMRD_LSW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828088ull);
}
#else
#define CVMX_BBP_RX0SEQ_RAMRD_LSW (CVMX_ADD_IO_SEG(0x00010F0000828088ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_RAMRD_MSW CVMX_BBP_RX0SEQ_RAMRD_MSW_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_RAMRD_MSW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_RAMRD_MSW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082808Cull);
}
#else
#define CVMX_BBP_RX0SEQ_RAMRD_MSW (CVMX_ADD_IO_SEG(0x00010F000082808Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_STATUS CVMX_BBP_RX0SEQ_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828000ull);
}
#else
#define CVMX_BBP_RX0SEQ_STATUS (CVMX_ADD_IO_SEG(0x00010F0000828000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_THRDSTAT0 CVMX_BBP_RX0SEQ_THRDSTAT0_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_THRDSTAT0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_THRDSTAT0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828010ull);
}
#else
#define CVMX_BBP_RX0SEQ_THRDSTAT0 (CVMX_ADD_IO_SEG(0x00010F0000828010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0SEQ_THRDX_CFG(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 15)))))
		cvmx_warn("CVMX_BBP_RX0SEQ_THRDX_CFG(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000828100ull) + ((offset) & 15) * 8;
}
#else
#define CVMX_BBP_RX0SEQ_THRDX_CFG(offset) (CVMX_ADD_IO_SEG(0x00010F0000828100ull) + ((offset) & 15) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX0SEQ_THRDX_PC(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 15)))))
		cvmx_warn("CVMX_BBP_RX0SEQ_THRDX_PC(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000828104ull) + ((offset) & 15) * 8;
}
#else
#define CVMX_BBP_RX0SEQ_THRDX_PC(offset) (CVMX_ADD_IO_SEG(0x00010F0000828104ull) + ((offset) & 15) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0SEQ_TIMER CVMX_BBP_RX0SEQ_TIMER_FUNC()
static inline uint64_t CVMX_BBP_RX0SEQ_TIMER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0SEQ_TIMER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828040ull);
}
#else
#define CVMX_BBP_RX0SEQ_TIMER (CVMX_ADD_IO_SEG(0x00010F0000828040ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_BIST_STATUS0 CVMX_BBP_RX0_BIST_STATUS0_FUNC()
static inline uint64_t CVMX_BBP_RX0_BIST_STATUS0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_BIST_STATUS0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833860ull);
}
#else
#define CVMX_BBP_RX0_BIST_STATUS0 (CVMX_ADD_IO_SEG(0x00010F0000833860ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_BIST_STATUS1 CVMX_BBP_RX0_BIST_STATUS1_FUNC()
static inline uint64_t CVMX_BBP_RX0_BIST_STATUS1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_BIST_STATUS1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833864ull);
}
#else
#define CVMX_BBP_RX0_BIST_STATUS1 (CVMX_ADD_IO_SEG(0x00010F0000833864ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_BIST_STATUS2 CVMX_BBP_RX0_BIST_STATUS2_FUNC()
static inline uint64_t CVMX_BBP_RX0_BIST_STATUS2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_BIST_STATUS2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833868ull);
}
#else
#define CVMX_BBP_RX0_BIST_STATUS2 (CVMX_ADD_IO_SEG(0x00010F0000833868ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C54ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C50ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_DAT CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831CF8ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000831CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_SEL CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831CF4ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000831CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_CLEAR CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C18ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000831C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_ENB CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C1Cull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000831C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_RSTATUS CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C14ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000831C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_STATUS CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C10ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_TEST CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C20ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000831C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_MEMCLR_DATA CVMX_BBP_RX0_DFTDMP_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C90ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000831C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_MODE CVMX_BBP_RX0_DFTDMP_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C04ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000831C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_PRI_MODE CVMX_BBP_RX0_DFTDMP_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C08ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000831C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_START_ADDR0 CVMX_BBP_RX0_DFTDMP_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C30ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_STATUS CVMX_BBP_RX0_DFTDMP_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C00ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C2Cull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000831C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C0Cull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_START CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831C28ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000831C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832054ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832050ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_DAT CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008320F8ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008320F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_SEL CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008320F4ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008320F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_CLEAR CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832018ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000832018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_ENB CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083201Cull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083201Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_RSTATUS CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832014ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000832014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_STATUS CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832010ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_TEST CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832020ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000832020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_MEMCLR_DATA CVMX_BBP_RX0_DFTDMP_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832090ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000832090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_MODE CVMX_BBP_RX0_DFTDMP_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832004ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000832004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_PRI_MODE CVMX_BBP_RX0_DFTDMP_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832008ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000832008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_START_ADDR0 CVMX_BBP_RX0_DFTDMP_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832030ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_STATUS CVMX_BBP_RX0_DFTDMP_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832000ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083202Cull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083202Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083200Cull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083200Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_START CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832028ull);
}
#else
#define CVMX_BBP_RX0_DFTDMP_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000832028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832454ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832450ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_DAT CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008324F8ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008324F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_SEL CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008324F4ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008324F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_CLEAR CVMX_BBP_RX0_EXT_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832418ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000832418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_ENB CVMX_BBP_RX0_EXT_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083241Cull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083241Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_RSTATUS CVMX_BBP_RX0_EXT_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832414ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000832414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_STATUS CVMX_BBP_RX0_EXT_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832410ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_TEST CVMX_BBP_RX0_EXT_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832420ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000832420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_MEMCLR_DATA CVMX_BBP_RX0_EXT_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832490ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000832490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_MODE CVMX_BBP_RX0_EXT_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832404ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000832404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_PRI_MODE CVMX_BBP_RX0_EXT_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832408ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000832408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_START_ADDR0 CVMX_BBP_RX0_EXT_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832430ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_STATUS CVMX_BBP_RX0_EXT_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832400ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX0_EXT_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083242Cull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083242Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX0_EXT_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083240Cull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083240Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_RD_XFER_START CVMX_BBP_RX0_EXT_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832428ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000832428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832854ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832850ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_DAT CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008328F8ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008328F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_SEL CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008328F4ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008328F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_CLEAR CVMX_BBP_RX0_EXT_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832818ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000832818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_ENB CVMX_BBP_RX0_EXT_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083281Cull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083281Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_RSTATUS CVMX_BBP_RX0_EXT_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832814ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000832814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_STATUS CVMX_BBP_RX0_EXT_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832810ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_TEST CVMX_BBP_RX0_EXT_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832820ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000832820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_MEMCLR_DATA CVMX_BBP_RX0_EXT_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832890ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000832890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_MODE CVMX_BBP_RX0_EXT_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832804ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000832804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_PRI_MODE CVMX_BBP_RX0_EXT_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832808ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000832808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_START_ADDR0 CVMX_BBP_RX0_EXT_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832830ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_STATUS CVMX_BBP_RX0_EXT_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832800ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX0_EXT_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083282Cull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083282Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX0_EXT_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083280Cull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083280Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_EXT_DMA_WR_XFER_START CVMX_BBP_RX0_EXT_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_EXT_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_EXT_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832828ull);
}
#else
#define CVMX_BBP_RX0_EXT_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000832828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833454ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000833454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833450ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000833450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_DAT CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008334F8ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008334F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_SEL CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008334F4ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008334F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_CLEAR CVMX_BBP_RX0_INSTR_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833418ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000833418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_ENB CVMX_BBP_RX0_INSTR_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083341Cull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083341Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_RSTATUS CVMX_BBP_RX0_INSTR_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833414ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000833414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_STATUS CVMX_BBP_RX0_INSTR_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833410ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000833410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_TEST CVMX_BBP_RX0_INSTR_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833420ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000833420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_MEMCLR_DATA CVMX_BBP_RX0_INSTR_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833490ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000833490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_MODE CVMX_BBP_RX0_INSTR_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833404ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000833404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_PRI_MODE CVMX_BBP_RX0_INSTR_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833408ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000833408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_START_ADDR0 CVMX_BBP_RX0_INSTR_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833430ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000833430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_STATUS CVMX_BBP_RX0_INSTR_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833400ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000833400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX0_INSTR_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083342Cull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083342Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX0_INSTR_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083340Cull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083340Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INSTR_DMA_WR_XFER_START CVMX_BBP_RX0_INSTR_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_INSTR_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INSTR_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833428ull);
}
#else
#define CVMX_BBP_RX0_INSTR_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000833428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX0_INT_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C54ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX0_INT_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C50ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_DEBUG_DAT CVMX_BBP_RX0_INT_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832CF8ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000832CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_DEBUG_SEL CVMX_BBP_RX0_INT_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832CF4ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000832CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_CLEAR CVMX_BBP_RX0_INT_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C18ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000832C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_ENB CVMX_BBP_RX0_INT_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C1Cull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000832C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_RSTATUS CVMX_BBP_RX0_INT_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C14ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000832C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_STATUS CVMX_BBP_RX0_INT_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C10ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_TEST CVMX_BBP_RX0_INT_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C20ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000832C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_MEMCLR_DATA CVMX_BBP_RX0_INT_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C90ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000832C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_MODE CVMX_BBP_RX0_INT_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C04ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000832C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_PRI_MODE CVMX_BBP_RX0_INT_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C08ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000832C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_START_ADDR0 CVMX_BBP_RX0_INT_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C30ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000832C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_STATUS CVMX_BBP_RX0_INT_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C00ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX0_INT_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C2Cull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000832C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX0_INT_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C0Cull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000832C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_RD_XFER_START CVMX_BBP_RX0_INT_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000832C28ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000832C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX0_INT_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833054ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000833054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX0_INT_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833050ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000833050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_DEBUG_DAT CVMX_BBP_RX0_INT_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008330F8ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008330F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_DEBUG_SEL CVMX_BBP_RX0_INT_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008330F4ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008330F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_CLEAR CVMX_BBP_RX0_INT_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833018ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000833018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_ENB CVMX_BBP_RX0_INT_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083301Cull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083301Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_RSTATUS CVMX_BBP_RX0_INT_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833014ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000833014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_STATUS CVMX_BBP_RX0_INT_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833010ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000833010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_TEST CVMX_BBP_RX0_INT_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833020ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000833020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_MEMCLR_DATA CVMX_BBP_RX0_INT_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833090ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000833090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_MODE CVMX_BBP_RX0_INT_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833004ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000833004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_PRI_MODE CVMX_BBP_RX0_INT_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833008ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000833008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_START_ADDR0 CVMX_BBP_RX0_INT_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833030ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000833030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_STATUS CVMX_BBP_RX0_INT_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833000ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000833000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX0_INT_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083302Cull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083302Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX0_INT_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083300Cull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083300Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_INT_DMA_WR_XFER_START CVMX_BBP_RX0_INT_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_INT_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_INT_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000833028ull);
}
#else
#define CVMX_BBP_RX0_INT_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000833028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831054ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831050ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_DAT CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008310F8ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008310F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_SEL CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008310F4ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008310F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_CLEAR CVMX_BBP_RX0_RACH_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831018ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000831018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_ENB CVMX_BBP_RX0_RACH_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083101Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083101Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_RSTATUS CVMX_BBP_RX0_RACH_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831014ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000831014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_STATUS CVMX_BBP_RX0_RACH_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831010ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_TEST CVMX_BBP_RX0_RACH_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831020ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000831020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_MEMCLR_DATA CVMX_BBP_RX0_RACH_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831090ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000831090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_MODE CVMX_BBP_RX0_RACH_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831004ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000831004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_PRI_MODE CVMX_BBP_RX0_RACH_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831008ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000831008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_START_ADDR0 CVMX_BBP_RX0_RACH_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831030ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_STATUS CVMX_BBP_RX0_RACH_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831000ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX0_RACH_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083102Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083102Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX0_RACH_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083100Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083100Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_RD_XFER_START CVMX_BBP_RX0_RACH_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831028ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000831028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR0 CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831454ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR0 CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831450ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_DAT CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008314F8ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008314F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_SEL CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008314F4ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008314F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_CLEAR CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831418ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000831418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_ENB CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083141Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083141Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_RSTATUS CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831414ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000831414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_STATUS CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831410ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_TEST CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831420ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000831420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_MEMCLR_DATA CVMX_BBP_RX0_RACH_DMA_WR_0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831490ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000831490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_MODE CVMX_BBP_RX0_RACH_DMA_WR_0_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831404ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_MODE (CVMX_ADD_IO_SEG(0x00010F0000831404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_PRI_MODE CVMX_BBP_RX0_RACH_DMA_WR_0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831408ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000831408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_START_ADDR0 CVMX_BBP_RX0_RACH_DMA_WR_0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831430ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_STATUS CVMX_BBP_RX0_RACH_DMA_WR_0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831400ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_MODE_COUNT CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083142Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083142Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_Q_STATUS CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083140Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083140Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_START CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831428ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000831428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR0 CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831854ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR0 CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831850ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_DAT CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008318F8ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008318F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_SEL CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008318F4ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008318F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_CLEAR CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831818ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000831818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_ENB CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083181Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083181Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_RSTATUS CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831814ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000831814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_STATUS CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831810ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_TEST CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831820ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000831820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_MEMCLR_DATA CVMX_BBP_RX0_RACH_DMA_WR_1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831890ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000831890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_MODE CVMX_BBP_RX0_RACH_DMA_WR_1_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831804ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_MODE (CVMX_ADD_IO_SEG(0x00010F0000831804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_PRI_MODE CVMX_BBP_RX0_RACH_DMA_WR_1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831808ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000831808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_START_ADDR0 CVMX_BBP_RX0_RACH_DMA_WR_1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831830ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000831830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_STATUS CVMX_BBP_RX0_RACH_DMA_WR_1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831800ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000831800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_MODE_COUNT CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083182Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083182Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_Q_STATUS CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083180Cull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083180Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_START CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000831828ull);
}
#else
#define CVMX_BBP_RX0_RACH_DMA_WR_1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000831828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR0 CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830054ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR0 CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830050ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_DAT CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008300F8ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008300F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_SEL CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008300F4ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008300F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_CLEAR CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830018ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000830018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_ENB CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083001Cull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083001Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_RSTATUS CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830014ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000830014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_STATUS CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830010ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_TEST CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830020ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000830020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_MEMCLR_DATA CVMX_BBP_RX0_RFIF_DMA_WR_0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830090ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000830090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_MODE CVMX_BBP_RX0_RFIF_DMA_WR_0_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830004ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_MODE (CVMX_ADD_IO_SEG(0x00010F0000830004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_PRI_MODE CVMX_BBP_RX0_RFIF_DMA_WR_0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830008ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000830008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_START_ADDR0 CVMX_BBP_RX0_RFIF_DMA_WR_0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830030ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_STATUS CVMX_BBP_RX0_RFIF_DMA_WR_0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830000ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_MODE_COUNT CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083002Cull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083002Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_Q_STATUS CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083000Cull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083000Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_START CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830028ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000830028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR0 CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830454ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR0 CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830450ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_DAT CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008304F8ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008304F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_SEL CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008304F4ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008304F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_CLEAR CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830418ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000830418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_ENB CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083041Cull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083041Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_RSTATUS CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830414ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000830414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_STATUS CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830410ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_TEST CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830420ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000830420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_MEMCLR_DATA CVMX_BBP_RX0_RFIF_DMA_WR_1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830490ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000830490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_MODE CVMX_BBP_RX0_RFIF_DMA_WR_1_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830404ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_MODE (CVMX_ADD_IO_SEG(0x00010F0000830404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_PRI_MODE CVMX_BBP_RX0_RFIF_DMA_WR_1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830408ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000830408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_START_ADDR0 CVMX_BBP_RX0_RFIF_DMA_WR_1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830430ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_STATUS CVMX_BBP_RX0_RFIF_DMA_WR_1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830400ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_MODE_COUNT CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083042Cull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083042Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_Q_STATUS CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083040Cull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083040Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_START CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830428ull);
}
#else
#define CVMX_BBP_RX0_RFIF_DMA_WR_1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000830428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830854ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830850ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_DAT CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008308F8ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008308F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_SEL CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008308F4ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008308F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_CLEAR CVMX_BBP_RX0_ULFE_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830818ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000830818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_ENB CVMX_BBP_RX0_ULFE_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083081Cull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000083081Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_RSTATUS CVMX_BBP_RX0_ULFE_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830814ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000830814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_STATUS CVMX_BBP_RX0_ULFE_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830810ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_TEST CVMX_BBP_RX0_ULFE_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830820ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000830820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_MEMCLR_DATA CVMX_BBP_RX0_ULFE_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830890ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000830890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_MODE CVMX_BBP_RX0_ULFE_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830804ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000830804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_PRI_MODE CVMX_BBP_RX0_ULFE_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830808ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000830808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_START_ADDR0 CVMX_BBP_RX0_ULFE_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830830ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_STATUS CVMX_BBP_RX0_ULFE_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830800ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX0_ULFE_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083082Cull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000083082Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX0_ULFE_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000083080Cull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000083080Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_RD_XFER_START CVMX_BBP_RX0_ULFE_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830828ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000830828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C54ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C50ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_DAT CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830CF8ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000830CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_SEL CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830CF4ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000830CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_CLEAR CVMX_BBP_RX0_ULFE_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C18ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000830C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_ENB CVMX_BBP_RX0_ULFE_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C1Cull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000830C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_RSTATUS CVMX_BBP_RX0_ULFE_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C14ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000830C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_STATUS CVMX_BBP_RX0_ULFE_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C10ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_TEST CVMX_BBP_RX0_ULFE_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C20ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000830C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_MEMCLR_DATA CVMX_BBP_RX0_ULFE_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C90ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000830C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_MODE CVMX_BBP_RX0_ULFE_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C04ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000830C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_PRI_MODE CVMX_BBP_RX0_ULFE_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C08ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000830C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_START_ADDR0 CVMX_BBP_RX0_ULFE_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C30ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000830C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_STATUS CVMX_BBP_RX0_ULFE_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C00ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX0_ULFE_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C2Cull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000830C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX0_ULFE_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C0Cull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000830C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX0_ULFE_DMA_WR_XFER_START CVMX_BBP_RX0_ULFE_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX0_ULFE_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX0_ULFE_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000830C28ull);
}
#else
#define CVMX_BBP_RX0_ULFE_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000830C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_CNTL_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_CNTL_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008401E4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX1INT_CNTL_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008401E4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_CNTL_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_CNTL_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008401E0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX1INT_CNTL_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008401E0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_INDEX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_INDEX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008401A4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX1INT_INDEX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008401A4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_INDEX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_INDEX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008401A0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX1INT_INDEX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008401A0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_MISC_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840134ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_MISC_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840134ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_MISC_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840114ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_MISC_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840114ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_MISC_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840034ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_MISC_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840034ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_MISC_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840014ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_MISC_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840014ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_MISC_RINT CVMX_BBP_RX1INT_MISC_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_MISC_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840194ull);
}
#else
#define CVMX_BBP_RX1INT_MISC_RINT (CVMX_ADD_IO_SEG(0x00010F0000840194ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_MISC_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008400B4ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_MISC_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008400B4ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_MISC_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_MISC_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840094ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_MISC_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840094ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RDQ_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000084012Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RDQ_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F000084012Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RDQ_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000084010Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RDQ_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000084010Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RDQ_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000084002Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RDQ_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F000084002Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RDQ_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000084000Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RDQ_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000084000Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_RDQ_RINT CVMX_BBP_RX1INT_RDQ_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_RDQ_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084018Cull);
}
#else
#define CVMX_BBP_RX1INT_RDQ_RINT (CVMX_ADD_IO_SEG(0x00010F000084018Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RDQ_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008400ACull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RDQ_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008400ACull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RDQ_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RDQ_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000084008Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RDQ_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000084008Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RD_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RD_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840124ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RD_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840124ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RD_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RD_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840104ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RD_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840104ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RD_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RD_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840024ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RD_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840024ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RD_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RD_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840004ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RD_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840004ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_RD_RINT CVMX_BBP_RX1INT_RD_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_RD_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_RD_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840184ull);
}
#else
#define CVMX_BBP_RX1INT_RD_RINT (CVMX_ADD_IO_SEG(0x00010F0000840184ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RD_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RD_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008400A4ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RD_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008400A4ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_RD_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_RD_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840084ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_RD_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840084ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_STAT_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_STAT_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008401C4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX1INT_STAT_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008401C4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_STAT_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_STAT_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008401C0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_RX1INT_STAT_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008401C0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_SWCLR CVMX_BBP_RX1INT_SWCLR_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_SWCLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_SWCLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840204ull);
}
#else
#define CVMX_BBP_RX1INT_SWCLR (CVMX_ADD_IO_SEG(0x00010F0000840204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_SWSET CVMX_BBP_RX1INT_SWSET_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_SWSET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_SWSET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840200ull);
}
#else
#define CVMX_BBP_RX1INT_SWSET (CVMX_ADD_IO_SEG(0x00010F0000840200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_SW_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_SW_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840130ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_SW_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840130ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_SW_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_SW_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840110ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_SW_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840110ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_SW_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_SW_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840030ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_SW_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840030ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_SW_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_SW_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840010ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_SW_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840010ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_SW_RINT CVMX_BBP_RX1INT_SW_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_SW_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_SW_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840190ull);
}
#else
#define CVMX_BBP_RX1INT_SW_RINT (CVMX_ADD_IO_SEG(0x00010F0000840190ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_SW_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_SW_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008400B0ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_SW_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008400B0ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_SW_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_SW_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840090ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_SW_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840090ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WRQ_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840128ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WRQ_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840128ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WRQ_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840108ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WRQ_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840108ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WRQ_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840028ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WRQ_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840028ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WRQ_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840008ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WRQ_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840008ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_WRQ_RINT CVMX_BBP_RX1INT_WRQ_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_WRQ_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840188ull);
}
#else
#define CVMX_BBP_RX1INT_WRQ_RINT (CVMX_ADD_IO_SEG(0x00010F0000840188ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WRQ_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008400A8ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WRQ_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008400A8ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WRQ_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WRQ_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840088ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WRQ_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840088ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WR_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WR_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840120ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WR_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840120ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WR_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WR_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840100ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WR_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840100ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WR_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WR_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840020ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WR_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840020ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WR_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WR_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840000ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WR_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840000ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1INT_WR_RINT CVMX_BBP_RX1INT_WR_RINT_FUNC()
static inline uint64_t CVMX_BBP_RX1INT_WR_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1INT_WR_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000840180ull);
}
#else
#define CVMX_BBP_RX1INT_WR_RINT (CVMX_ADD_IO_SEG(0x00010F0000840180ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WR_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WR_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008400A0ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WR_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008400A0ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1INT_WR_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_RX1INT_WR_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000840080ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_RX1INT_WR_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000840080ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_AUTOGATE CVMX_BBP_RX1SEQ_AUTOGATE_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_AUTOGATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_AUTOGATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084800Cull);
}
#else
#define CVMX_BBP_RX1SEQ_AUTOGATE (CVMX_ADD_IO_SEG(0x00010F000084800Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_GPI_RD00 CVMX_BBP_RX1SEQ_GPI_RD00_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_GPI_RD00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_GPI_RD00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848240ull);
}
#else
#define CVMX_BBP_RX1SEQ_GPI_RD00 (CVMX_ADD_IO_SEG(0x00010F0000848240ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_GPI_RD01 CVMX_BBP_RX1SEQ_GPI_RD01_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_GPI_RD01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_GPI_RD01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848244ull);
}
#else
#define CVMX_BBP_RX1SEQ_GPI_RD01 (CVMX_ADD_IO_SEG(0x00010F0000848244ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_GPO_CLR00 CVMX_BBP_RX1SEQ_GPO_CLR00_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_GPO_CLR00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_GPO_CLR00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848220ull);
}
#else
#define CVMX_BBP_RX1SEQ_GPO_CLR00 (CVMX_ADD_IO_SEG(0x00010F0000848220ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_GPO_CLR01 CVMX_BBP_RX1SEQ_GPO_CLR01_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_GPO_CLR01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_GPO_CLR01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848224ull);
}
#else
#define CVMX_BBP_RX1SEQ_GPO_CLR01 (CVMX_ADD_IO_SEG(0x00010F0000848224ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_GPO_SET00 CVMX_BBP_RX1SEQ_GPO_SET00_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_GPO_SET00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_GPO_SET00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848200ull);
}
#else
#define CVMX_BBP_RX1SEQ_GPO_SET00 (CVMX_ADD_IO_SEG(0x00010F0000848200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_GPO_SET01 CVMX_BBP_RX1SEQ_GPO_SET01_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_GPO_SET01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_GPO_SET01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848204ull);
}
#else
#define CVMX_BBP_RX1SEQ_GPO_SET01 (CVMX_ADD_IO_SEG(0x00010F0000848204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_PARAM0 CVMX_BBP_RX1SEQ_PARAM0_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_PARAM0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_PARAM0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008480C0ull);
}
#else
#define CVMX_BBP_RX1SEQ_PARAM0 (CVMX_ADD_IO_SEG(0x00010F00008480C0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_PARAM1 CVMX_BBP_RX1SEQ_PARAM1_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_PARAM1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_PARAM1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008480C4ull);
}
#else
#define CVMX_BBP_RX1SEQ_PARAM1 (CVMX_ADD_IO_SEG(0x00010F00008480C4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_RAMACC CVMX_BBP_RX1SEQ_RAMACC_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_RAMACC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_RAMACC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848080ull);
}
#else
#define CVMX_BBP_RX1SEQ_RAMACC (CVMX_ADD_IO_SEG(0x00010F0000848080ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_RAMRD_LSW CVMX_BBP_RX1SEQ_RAMRD_LSW_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_RAMRD_LSW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_RAMRD_LSW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848088ull);
}
#else
#define CVMX_BBP_RX1SEQ_RAMRD_LSW (CVMX_ADD_IO_SEG(0x00010F0000848088ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_RAMRD_MSW CVMX_BBP_RX1SEQ_RAMRD_MSW_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_RAMRD_MSW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_RAMRD_MSW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084808Cull);
}
#else
#define CVMX_BBP_RX1SEQ_RAMRD_MSW (CVMX_ADD_IO_SEG(0x00010F000084808Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_STATUS CVMX_BBP_RX1SEQ_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848000ull);
}
#else
#define CVMX_BBP_RX1SEQ_STATUS (CVMX_ADD_IO_SEG(0x00010F0000848000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_THRDSTAT0 CVMX_BBP_RX1SEQ_THRDSTAT0_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_THRDSTAT0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_THRDSTAT0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848010ull);
}
#else
#define CVMX_BBP_RX1SEQ_THRDSTAT0 (CVMX_ADD_IO_SEG(0x00010F0000848010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1SEQ_THRDX_CFG(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 15)))))
		cvmx_warn("CVMX_BBP_RX1SEQ_THRDX_CFG(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000848100ull) + ((offset) & 15) * 8;
}
#else
#define CVMX_BBP_RX1SEQ_THRDX_CFG(offset) (CVMX_ADD_IO_SEG(0x00010F0000848100ull) + ((offset) & 15) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_RX1SEQ_THRDX_PC(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 15)))))
		cvmx_warn("CVMX_BBP_RX1SEQ_THRDX_PC(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000848104ull) + ((offset) & 15) * 8;
}
#else
#define CVMX_BBP_RX1SEQ_THRDX_PC(offset) (CVMX_ADD_IO_SEG(0x00010F0000848104ull) + ((offset) & 15) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1SEQ_TIMER CVMX_BBP_RX1SEQ_TIMER_FUNC()
static inline uint64_t CVMX_BBP_RX1SEQ_TIMER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1SEQ_TIMER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000848040ull);
}
#else
#define CVMX_BBP_RX1SEQ_TIMER (CVMX_ADD_IO_SEG(0x00010F0000848040ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_BIST_STATUS0 CVMX_BBP_RX1_BIST_STATUS0_FUNC()
static inline uint64_t CVMX_BBP_RX1_BIST_STATUS0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_BIST_STATUS0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853860ull);
}
#else
#define CVMX_BBP_RX1_BIST_STATUS0 (CVMX_ADD_IO_SEG(0x00010F0000853860ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_BIST_STATUS1 CVMX_BBP_RX1_BIST_STATUS1_FUNC()
static inline uint64_t CVMX_BBP_RX1_BIST_STATUS1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_BIST_STATUS1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853864ull);
}
#else
#define CVMX_BBP_RX1_BIST_STATUS1 (CVMX_ADD_IO_SEG(0x00010F0000853864ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_BIST_STATUS2 CVMX_BBP_RX1_BIST_STATUS2_FUNC()
static inline uint64_t CVMX_BBP_RX1_BIST_STATUS2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_BIST_STATUS2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853868ull);
}
#else
#define CVMX_BBP_RX1_BIST_STATUS2 (CVMX_ADD_IO_SEG(0x00010F0000853868ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_BIST_STATUS3 CVMX_BBP_RX1_BIST_STATUS3_FUNC()
static inline uint64_t CVMX_BBP_RX1_BIST_STATUS3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_BIST_STATUS3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085386Cull);
}
#else
#define CVMX_BBP_RX1_BIST_STATUS3 (CVMX_ADD_IO_SEG(0x00010F000085386Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_BIST_STATUS4 CVMX_BBP_RX1_BIST_STATUS4_FUNC()
static inline uint64_t CVMX_BBP_RX1_BIST_STATUS4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_BIST_STATUS4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853870ull);
}
#else
#define CVMX_BBP_RX1_BIST_STATUS4 (CVMX_ADD_IO_SEG(0x00010F0000853870ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C54ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C50ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_DAT CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851CF8ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000851CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_SEL CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851CF4ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000851CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_CLEAR CVMX_BBP_RX1_EXT_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C18ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000851C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_ENB CVMX_BBP_RX1_EXT_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C1Cull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000851C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_RSTATUS CVMX_BBP_RX1_EXT_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C14ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000851C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_STATUS CVMX_BBP_RX1_EXT_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C10ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_TEST CVMX_BBP_RX1_EXT_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C20ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000851C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_MEMCLR_DATA CVMX_BBP_RX1_EXT_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C90ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000851C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_MODE CVMX_BBP_RX1_EXT_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C04ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000851C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_PRI_MODE CVMX_BBP_RX1_EXT_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C08ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000851C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_START_ADDR0 CVMX_BBP_RX1_EXT_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C30ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_STATUS CVMX_BBP_RX1_EXT_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C00ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX1_EXT_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C2Cull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000851C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX1_EXT_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C0Cull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_RD_XFER_START CVMX_BBP_RX1_EXT_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851C28ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000851C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852054ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852050ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_DAT CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008520F8ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008520F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_SEL CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008520F4ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008520F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_CLEAR CVMX_BBP_RX1_EXT_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852018ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000852018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_ENB CVMX_BBP_RX1_EXT_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085201Cull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085201Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_RSTATUS CVMX_BBP_RX1_EXT_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852014ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000852014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_STATUS CVMX_BBP_RX1_EXT_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852010ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_TEST CVMX_BBP_RX1_EXT_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852020ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000852020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_MEMCLR_DATA CVMX_BBP_RX1_EXT_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852090ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000852090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_MODE CVMX_BBP_RX1_EXT_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852004ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000852004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_PRI_MODE CVMX_BBP_RX1_EXT_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852008ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000852008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_START_ADDR0 CVMX_BBP_RX1_EXT_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852030ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_STATUS CVMX_BBP_RX1_EXT_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852000ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX1_EXT_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085202Cull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085202Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX1_EXT_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085200Cull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085200Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_EXT_DMA_WR_XFER_START CVMX_BBP_RX1_EXT_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_EXT_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_EXT_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852028ull);
}
#else
#define CVMX_BBP_RX1_EXT_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000852028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852454ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852450ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_DAT CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008524F8ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008524F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_SEL CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008524F4ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008524F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_CLEAR CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852418ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000852418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_ENB CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085241Cull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085241Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_RSTATUS CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852414ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000852414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_STATUS CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852410ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_TEST CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852420ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000852420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MEMCLR_DATA CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852490ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000852490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MODE CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852404ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000852404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_PRI_MODE CVMX_BBP_RX1_HARQ_DMA_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852408ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000852408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR0 CVMX_BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852430ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_STATUS CVMX_BBP_RX1_HARQ_DMA_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852400ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085242Cull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085242Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085240Cull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085240Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_START CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852428ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000852428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852854ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852850ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_DAT CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008528F8ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008528F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_SEL CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008528F4ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008528F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_CLEAR CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852818ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000852818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_ENB CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085281Cull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085281Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_RSTATUS CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852814ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000852814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_STATUS CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852810ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_TEST CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852820ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000852820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MEMCLR_DATA CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852890ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000852890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MODE CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852804ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000852804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_PRI_MODE CVMX_BBP_RX1_HARQ_DMA_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852808ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000852808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR0 CVMX_BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852830ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_STATUS CVMX_BBP_RX1_HARQ_DMA_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852800ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085282Cull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085282Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085280Cull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085280Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_START CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852828ull);
}
#else
#define CVMX_BBP_RX1_HARQ_DMA_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000852828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853454ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000853454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853450ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000853450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_DAT CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008534F8ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008534F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_SEL CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008534F4ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008534F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_CLEAR CVMX_BBP_RX1_INSTR_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853418ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000853418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_ENB CVMX_BBP_RX1_INSTR_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085341Cull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085341Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_RSTATUS CVMX_BBP_RX1_INSTR_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853414ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000853414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_STATUS CVMX_BBP_RX1_INSTR_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853410ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000853410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_TEST CVMX_BBP_RX1_INSTR_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853420ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000853420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_MEMCLR_DATA CVMX_BBP_RX1_INSTR_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853490ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000853490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_MODE CVMX_BBP_RX1_INSTR_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853404ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000853404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_PRI_MODE CVMX_BBP_RX1_INSTR_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853408ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000853408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_START_ADDR0 CVMX_BBP_RX1_INSTR_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853430ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000853430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_STATUS CVMX_BBP_RX1_INSTR_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853400ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000853400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX1_INSTR_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085342Cull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085342Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX1_INSTR_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085340Cull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085340Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INSTR_DMA_WR_XFER_START CVMX_BBP_RX1_INSTR_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_INSTR_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INSTR_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853428ull);
}
#else
#define CVMX_BBP_RX1_INSTR_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000853428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX1_INT_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C54ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX1_INT_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C50ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_DEBUG_DAT CVMX_BBP_RX1_INT_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852CF8ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000852CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_DEBUG_SEL CVMX_BBP_RX1_INT_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852CF4ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000852CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_CLEAR CVMX_BBP_RX1_INT_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C18ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000852C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_ENB CVMX_BBP_RX1_INT_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C1Cull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000852C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_RSTATUS CVMX_BBP_RX1_INT_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C14ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000852C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_STATUS CVMX_BBP_RX1_INT_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C10ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_TEST CVMX_BBP_RX1_INT_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C20ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000852C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_MEMCLR_DATA CVMX_BBP_RX1_INT_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C90ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000852C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_MODE CVMX_BBP_RX1_INT_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C04ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000852C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_PRI_MODE CVMX_BBP_RX1_INT_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C08ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000852C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_START_ADDR0 CVMX_BBP_RX1_INT_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C30ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000852C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_STATUS CVMX_BBP_RX1_INT_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C00ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX1_INT_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C2Cull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000852C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX1_INT_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C0Cull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000852C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_RD_XFER_START CVMX_BBP_RX1_INT_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000852C28ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000852C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX1_INT_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853054ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000853054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX1_INT_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853050ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000853050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_DEBUG_DAT CVMX_BBP_RX1_INT_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008530F8ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008530F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_DEBUG_SEL CVMX_BBP_RX1_INT_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008530F4ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008530F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_CLEAR CVMX_BBP_RX1_INT_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853018ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000853018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_ENB CVMX_BBP_RX1_INT_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085301Cull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085301Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_RSTATUS CVMX_BBP_RX1_INT_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853014ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000853014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_STATUS CVMX_BBP_RX1_INT_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853010ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000853010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_TEST CVMX_BBP_RX1_INT_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853020ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000853020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_MEMCLR_DATA CVMX_BBP_RX1_INT_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853090ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000853090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_MODE CVMX_BBP_RX1_INT_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853004ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000853004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_PRI_MODE CVMX_BBP_RX1_INT_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853008ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000853008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_START_ADDR0 CVMX_BBP_RX1_INT_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853030ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000853030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_STATUS CVMX_BBP_RX1_INT_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853000ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000853000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX1_INT_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085302Cull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085302Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX1_INT_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085300Cull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085300Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_INT_DMA_WR_XFER_START CVMX_BBP_RX1_INT_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_INT_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_INT_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000853028ull);
}
#else
#define CVMX_BBP_RX1_INT_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000853028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850054ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850050ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_DAT CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008500F8ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008500F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_SEL CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008500F4ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008500F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850454ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850450ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_DAT CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008504F8ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008504F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_SEL CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008504F4ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008504F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_CLEAR CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850418ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000850418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_ENB CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085041Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085041Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_RSTATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850414ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000850414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_STATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850410ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_TEST CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850420ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000850420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MEMCLR_DATA CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850490ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000850490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MODE CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850404ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_MODE (CVMX_ADD_IO_SEG(0x00010F0000850404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_PRI_MODE CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850408ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000850408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850430ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_STATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850400ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_MODE_COUNT CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085042Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085042Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_Q_STATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085040Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085040Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_START CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850428ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_HQ_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000850428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_CLEAR CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850018ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000850018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_ENB CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085001Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085001Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_RSTATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850014ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000850014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_STATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850010ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_TEST CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850020ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000850020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_MEMCLR_DATA CVMX_BBP_RX1_TURBODEC_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850090ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000850090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_MODE CVMX_BBP_RX1_TURBODEC_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850004ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000850004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_PRI_MODE CVMX_BBP_RX1_TURBODEC_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850008ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000850008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850030ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_STATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850000ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085002Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085002Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085000Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085000Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_START CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850028ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000850028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850854ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850850ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_DAT CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008508F8ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008508F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_SEL CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008508F4ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008508F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851054ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851050ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_DAT CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008510F8ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008510F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_SEL CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008510F4ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008510F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_CLEAR CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851018ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000851018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_ENB CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085101Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085101Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_RSTATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851014ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000851014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851010ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_TEST CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851020ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000851020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MEMCLR_DATA CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851090ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000851090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MODE CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851004ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_MODE (CVMX_ADD_IO_SEG(0x00010F0000851004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_PRI_MODE CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851008ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000851008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851030ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851000ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_MODE_COUNT CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085102Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085102Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_Q_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085100Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085100Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_START CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851028ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_HQ_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000851028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_CLEAR CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850818ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000850818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_ENB CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085081Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085081Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_RSTATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850814ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000850814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850810ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_TEST CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850820ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000850820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_MEMCLR_DATA CVMX_BBP_RX1_TURBODEC_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850890ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000850890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_MODE CVMX_BBP_RX1_TURBODEC_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850804ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000850804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_PRI_MODE CVMX_BBP_RX1_TURBODEC_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850808ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000850808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C54ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C50ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_DAT CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850CF8ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000850CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_SEL CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850CF4ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000850CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_CLEAR CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C18ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000850C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_ENB CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C1Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000850C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_RSTATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C14ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000850C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C10ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_TEST CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C20ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000850C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MEMCLR_DATA CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C90ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000850C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MODE CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C04ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_MODE (CVMX_ADD_IO_SEG(0x00010F0000850C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_PRI_MODE CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C08ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000850C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C30ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C00ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_MODE_COUNT CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C2Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000850C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_Q_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C0Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_START CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850C28ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_SB_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000850C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_START_ADDR0 CVMX_BBP_RX1_TURBODEC_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850830ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000850830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850800ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000850800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085082Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085082Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085080Cull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085080Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_START CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000850828ull);
}
#else
#define CVMX_BBP_RX1_TURBODEC_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000850828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851454ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851450ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_DAT CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008514F8ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008514F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_SEL CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008514F4ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008514F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_CLEAR CVMX_BBP_RX1_VDEC_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851418ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000851418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_ENB CVMX_BBP_RX1_VDEC_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085141Cull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085141Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_RSTATUS CVMX_BBP_RX1_VDEC_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851414ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000851414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_STATUS CVMX_BBP_RX1_VDEC_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851410ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_TEST CVMX_BBP_RX1_VDEC_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851420ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000851420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_MEMCLR_DATA CVMX_BBP_RX1_VDEC_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851490ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000851490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_MODE CVMX_BBP_RX1_VDEC_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851404ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000851404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_PRI_MODE CVMX_BBP_RX1_VDEC_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851408ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000851408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_START_ADDR0 CVMX_BBP_RX1_VDEC_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851430ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_STATUS CVMX_BBP_RX1_VDEC_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851400ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_XFER_MODE_COUNT CVMX_BBP_RX1_VDEC_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085142Cull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085142Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_XFER_Q_STATUS CVMX_BBP_RX1_VDEC_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085140Cull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085140Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_RD_XFER_START CVMX_BBP_RX1_VDEC_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851428ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000851428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851854ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851850ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_DAT CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008518F8ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008518F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_SEL CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008518F4ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008518F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_CLEAR CVMX_BBP_RX1_VDEC_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851818ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000851818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_ENB CVMX_BBP_RX1_VDEC_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085181Cull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000085181Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_RSTATUS CVMX_BBP_RX1_VDEC_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851814ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000851814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_STATUS CVMX_BBP_RX1_VDEC_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851810ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_TEST CVMX_BBP_RX1_VDEC_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851820ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000851820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_MEMCLR_DATA CVMX_BBP_RX1_VDEC_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851890ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000851890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_MODE CVMX_BBP_RX1_VDEC_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851804ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000851804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_PRI_MODE CVMX_BBP_RX1_VDEC_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851808ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000851808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_START_ADDR0 CVMX_BBP_RX1_VDEC_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851830ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000851830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_STATUS CVMX_BBP_RX1_VDEC_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851800ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000851800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_XFER_MODE_COUNT CVMX_BBP_RX1_VDEC_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085182Cull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000085182Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_XFER_Q_STATUS CVMX_BBP_RX1_VDEC_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000085180Cull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000085180Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_RX1_VDEC_DMA_WR_XFER_START CVMX_BBP_RX1_VDEC_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_RX1_VDEC_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_RX1_VDEC_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000851828ull);
}
#else
#define CVMX_BBP_RX1_VDEC_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000851828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TOKEN_FREE_ALL CVMX_BBP_TOKEN_FREE_ALL_FUNC()
static inline uint64_t CVMX_BBP_TOKEN_FREE_ALL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TOKEN_FREE_ALL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000849000ull);
}
#else
#define CVMX_BBP_TOKEN_FREE_ALL (CVMX_ADD_IO_SEG(0x00010F0000849000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TOKEN_X(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && (((offset >= 1) && (offset <= 32))))))
		cvmx_warn("CVMX_BBP_TOKEN_X(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000849010ull) + ((offset) & 63) * 16 - 16*1;
}
#else
#define CVMX_BBP_TOKEN_X(offset) (CVMX_ADD_IO_SEG(0x00010F0000849010ull) + ((offset) & 63) * 16 - 16*1)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_CORE_STATUS CVMX_BBP_TURBO_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TURBO_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A008ull);
}
#else
#define CVMX_BBP_TURBO_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F000084A008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_INTR_MSK CVMX_BBP_TURBO_INTR_MSK_FUNC()
static inline uint64_t CVMX_BBP_TURBO_INTR_MSK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_INTR_MSK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A10Cull);
}
#else
#define CVMX_BBP_TURBO_INTR_MSK (CVMX_ADD_IO_SEG(0x00010F000084A10Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_INTR_SRC CVMX_BBP_TURBO_INTR_SRC_FUNC()
static inline uint64_t CVMX_BBP_TURBO_INTR_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_INTR_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A100ull);
}
#else
#define CVMX_BBP_TURBO_INTR_SRC (CVMX_ADD_IO_SEG(0x00010F000084A100ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_MODULE_CTRL CVMX_BBP_TURBO_MODULE_CTRL_FUNC()
static inline uint64_t CVMX_BBP_TURBO_MODULE_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_MODULE_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A004ull);
}
#else
#define CVMX_BBP_TURBO_MODULE_CTRL (CVMX_ADD_IO_SEG(0x00010F000084A004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_MODULE_STATUS CVMX_BBP_TURBO_MODULE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TURBO_MODULE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_MODULE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A000ull);
}
#else
#define CVMX_BBP_TURBO_MODULE_STATUS (CVMX_ADD_IO_SEG(0x00010F000084A000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_STATISTICS0 CVMX_BBP_TURBO_STATISTICS0_FUNC()
static inline uint64_t CVMX_BBP_TURBO_STATISTICS0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_STATISTICS0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A300ull);
}
#else
#define CVMX_BBP_TURBO_STATISTICS0 (CVMX_ADD_IO_SEG(0x00010F000084A300ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_STATISTICS1 CVMX_BBP_TURBO_STATISTICS1_FUNC()
static inline uint64_t CVMX_BBP_TURBO_STATISTICS1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_STATISTICS1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A304ull);
}
#else
#define CVMX_BBP_TURBO_STATISTICS1 (CVMX_ADD_IO_SEG(0x00010F000084A304ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_STATISTICS2 CVMX_BBP_TURBO_STATISTICS2_FUNC()
static inline uint64_t CVMX_BBP_TURBO_STATISTICS2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_STATISTICS2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A308ull);
}
#else
#define CVMX_BBP_TURBO_STATISTICS2 (CVMX_ADD_IO_SEG(0x00010F000084A308ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_STATISTICS3 CVMX_BBP_TURBO_STATISTICS3_FUNC()
static inline uint64_t CVMX_BBP_TURBO_STATISTICS3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_STATISTICS3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A30Cull);
}
#else
#define CVMX_BBP_TURBO_STATISTICS3 (CVMX_ADD_IO_SEG(0x00010F000084A30Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_STATISTICS4 CVMX_BBP_TURBO_STATISTICS4_FUNC()
static inline uint64_t CVMX_BBP_TURBO_STATISTICS4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_STATISTICS4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A310ull);
}
#else
#define CVMX_BBP_TURBO_STATISTICS4 (CVMX_ADD_IO_SEG(0x00010F000084A310ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG0 CVMX_BBP_TURBO_SYS_CFG0_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A200ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG0 (CVMX_ADD_IO_SEG(0x00010F000084A200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG1 CVMX_BBP_TURBO_SYS_CFG1_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A204ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG1 (CVMX_ADD_IO_SEG(0x00010F000084A204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG10 CVMX_BBP_TURBO_SYS_CFG10_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG10_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG10 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A228ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG10 (CVMX_ADD_IO_SEG(0x00010F000084A228ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG11 CVMX_BBP_TURBO_SYS_CFG11_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG11_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG11 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A22Cull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG11 (CVMX_ADD_IO_SEG(0x00010F000084A22Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG12 CVMX_BBP_TURBO_SYS_CFG12_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG12_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG12 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A230ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG12 (CVMX_ADD_IO_SEG(0x00010F000084A230ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG13 CVMX_BBP_TURBO_SYS_CFG13_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG13_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG13 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A234ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG13 (CVMX_ADD_IO_SEG(0x00010F000084A234ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG2 CVMX_BBP_TURBO_SYS_CFG2_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A208ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG2 (CVMX_ADD_IO_SEG(0x00010F000084A208ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG3 CVMX_BBP_TURBO_SYS_CFG3_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A20Cull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG3 (CVMX_ADD_IO_SEG(0x00010F000084A20Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG4 CVMX_BBP_TURBO_SYS_CFG4_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A210ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG4 (CVMX_ADD_IO_SEG(0x00010F000084A210ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG5 CVMX_BBP_TURBO_SYS_CFG5_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A214ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG5 (CVMX_ADD_IO_SEG(0x00010F000084A214ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG6 CVMX_BBP_TURBO_SYS_CFG6_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG6_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG6 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A218ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG6 (CVMX_ADD_IO_SEG(0x00010F000084A218ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG7 CVMX_BBP_TURBO_SYS_CFG7_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG7_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG7 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A21Cull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG7 (CVMX_ADD_IO_SEG(0x00010F000084A21Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG8 CVMX_BBP_TURBO_SYS_CFG8_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG8_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG8 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A220ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG8 (CVMX_ADD_IO_SEG(0x00010F000084A220ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TURBO_SYS_CFG9 CVMX_BBP_TURBO_SYS_CFG9_FUNC()
static inline uint64_t CVMX_BBP_TURBO_SYS_CFG9_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TURBO_SYS_CFG9 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A224ull);
}
#else
#define CVMX_BBP_TURBO_SYS_CFG9 (CVMX_ADD_IO_SEG(0x00010F000084A224ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_CNTL_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_CNTL_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008601E4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_TXINT_CNTL_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008601E4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_CNTL_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_CNTL_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008601E0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_TXINT_CNTL_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008601E0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_INDEX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_INDEX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008601A4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_TXINT_INDEX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008601A4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_INDEX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_INDEX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008601A0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_TXINT_INDEX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008601A0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_MISC_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_MISC_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860134ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_MISC_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860134ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_MISC_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_MISC_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860114ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_MISC_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860114ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_MISC_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_MISC_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860034ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_MISC_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860034ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_MISC_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_MISC_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000000014ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_MISC_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000000014ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_MISC_RINT CVMX_BBP_TXINT_MISC_RINT_FUNC()
static inline uint64_t CVMX_BBP_TXINT_MISC_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_MISC_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860194ull);
}
#else
#define CVMX_BBP_TXINT_MISC_RINT (CVMX_ADD_IO_SEG(0x00010F0000860194ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_MISC_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_MISC_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008600B4ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_MISC_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008600B4ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_MISC_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_MISC_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860094ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_MISC_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860094ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RDQ_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086012Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RDQ_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F000086012Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RDQ_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086010Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RDQ_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000086010Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RDQ_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086002Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RDQ_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F000086002Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RDQ_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086000Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RDQ_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000086000Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_RDQ_RINT CVMX_BBP_TXINT_RDQ_RINT_FUNC()
static inline uint64_t CVMX_BBP_TXINT_RDQ_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086018Cull);
}
#else
#define CVMX_BBP_TXINT_RDQ_RINT (CVMX_ADD_IO_SEG(0x00010F000086018Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RDQ_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008600ACull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RDQ_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008600ACull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RDQ_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RDQ_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086008Cull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RDQ_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F000086008Cull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RD_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RD_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860124ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RD_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860124ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RD_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RD_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860104ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RD_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860104ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RD_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RD_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860024ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RD_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860024ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RD_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RD_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860004ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RD_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860004ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_RD_RINT CVMX_BBP_TXINT_RD_RINT_FUNC()
static inline uint64_t CVMX_BBP_TXINT_RD_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_RD_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860184ull);
}
#else
#define CVMX_BBP_TXINT_RD_RINT (CVMX_ADD_IO_SEG(0x00010F0000860184ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RD_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RD_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008600A4ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RD_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008600A4ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_RD_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_RD_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860084ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_RD_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860084ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_STAT_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_STAT_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008601C4ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_TXINT_STAT_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008601C4ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_STAT_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_STAT_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008601C0ull) + ((offset) & 1) * 8;
}
#else
#define CVMX_BBP_TXINT_STAT_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F00008601C0ull) + ((offset) & 1) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_SWCLR CVMX_BBP_TXINT_SWCLR_FUNC()
static inline uint64_t CVMX_BBP_TXINT_SWCLR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_SWCLR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860204ull);
}
#else
#define CVMX_BBP_TXINT_SWCLR (CVMX_ADD_IO_SEG(0x00010F0000860204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_SWSET CVMX_BBP_TXINT_SWSET_FUNC()
static inline uint64_t CVMX_BBP_TXINT_SWSET_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_SWSET not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860200ull);
}
#else
#define CVMX_BBP_TXINT_SWSET (CVMX_ADD_IO_SEG(0x00010F0000860200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_SW_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_SW_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860130ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_SW_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860130ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_SW_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_SW_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860110ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_SW_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860110ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_SW_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_SW_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860030ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_SW_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860030ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_SW_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_SW_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860010ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_SW_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860010ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_SW_RINT CVMX_BBP_TXINT_SW_RINT_FUNC()
static inline uint64_t CVMX_BBP_TXINT_SW_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_SW_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860190ull);
}
#else
#define CVMX_BBP_TXINT_SW_RINT (CVMX_ADD_IO_SEG(0x00010F0000860190ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_SW_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_SW_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008600B0ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_SW_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008600B0ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_SW_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_SW_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860090ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_SW_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860090ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WRQ_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860128ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WRQ_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860128ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WRQ_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860108ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WRQ_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860108ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WRQ_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860028ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WRQ_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860028ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WRQ_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860008ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WRQ_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860008ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_WRQ_RINT CVMX_BBP_TXINT_WRQ_RINT_FUNC()
static inline uint64_t CVMX_BBP_TXINT_WRQ_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860188ull);
}
#else
#define CVMX_BBP_TXINT_WRQ_RINT (CVMX_ADD_IO_SEG(0x00010F0000860188ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WRQ_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008600A8ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WRQ_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008600A8ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WRQ_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WRQ_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860088ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WRQ_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860088ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WR_IDX_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WR_IDX_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860120ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WR_IDX_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860120ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WR_IDX_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WR_IDX_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860100ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WR_IDX_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860100ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WR_MASK_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WR_MASK_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860020ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WR_MASK_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860020ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WR_MASK_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WR_MASK_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860000ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WR_MASK_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860000ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXINT_WR_RINT CVMX_BBP_TXINT_WR_RINT_FUNC()
static inline uint64_t CVMX_BBP_TXINT_WR_RINT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXINT_WR_RINT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000860180ull);
}
#else
#define CVMX_BBP_TXINT_WR_RINT (CVMX_ADD_IO_SEG(0x00010F0000860180ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WR_STATUS_HIX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WR_STATUS_HIX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F00008600A0ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WR_STATUS_HIX(offset) (CVMX_ADD_IO_SEG(0x00010F00008600A0ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXINT_WR_STATUS_LOX(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 1)))))
		cvmx_warn("CVMX_BBP_TXINT_WR_STATUS_LOX(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F0000860080ull) + ((offset) & 1) * 64;
}
#else
#define CVMX_BBP_TXINT_WR_STATUS_LOX(offset) (CVMX_ADD_IO_SEG(0x00010F0000860080ull) + ((offset) & 1) * 64)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_AUTOGATE CVMX_BBP_TXSEQ_AUTOGATE_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_AUTOGATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_AUTOGATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E00Cull);
}
#else
#define CVMX_BBP_TXSEQ_AUTOGATE (CVMX_ADD_IO_SEG(0x00010F000086E00Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_GPI_RD00 CVMX_BBP_TXSEQ_GPI_RD00_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_GPI_RD00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_GPI_RD00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E240ull);
}
#else
#define CVMX_BBP_TXSEQ_GPI_RD00 (CVMX_ADD_IO_SEG(0x00010F000086E240ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_GPI_RD01 CVMX_BBP_TXSEQ_GPI_RD01_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_GPI_RD01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_GPI_RD01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E244ull);
}
#else
#define CVMX_BBP_TXSEQ_GPI_RD01 (CVMX_ADD_IO_SEG(0x00010F000086E244ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_GPO_CLR00 CVMX_BBP_TXSEQ_GPO_CLR00_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_GPO_CLR00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_GPO_CLR00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E220ull);
}
#else
#define CVMX_BBP_TXSEQ_GPO_CLR00 (CVMX_ADD_IO_SEG(0x00010F000086E220ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_GPO_CLR01 CVMX_BBP_TXSEQ_GPO_CLR01_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_GPO_CLR01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_GPO_CLR01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E224ull);
}
#else
#define CVMX_BBP_TXSEQ_GPO_CLR01 (CVMX_ADD_IO_SEG(0x00010F000086E224ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_GPO_SET00 CVMX_BBP_TXSEQ_GPO_SET00_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_GPO_SET00_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_GPO_SET00 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E200ull);
}
#else
#define CVMX_BBP_TXSEQ_GPO_SET00 (CVMX_ADD_IO_SEG(0x00010F000086E200ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_GPO_SET01 CVMX_BBP_TXSEQ_GPO_SET01_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_GPO_SET01_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_GPO_SET01 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E204ull);
}
#else
#define CVMX_BBP_TXSEQ_GPO_SET01 (CVMX_ADD_IO_SEG(0x00010F000086E204ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_PARAM0 CVMX_BBP_TXSEQ_PARAM0_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_PARAM0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_PARAM0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E0C0ull);
}
#else
#define CVMX_BBP_TXSEQ_PARAM0 (CVMX_ADD_IO_SEG(0x00010F000086E0C0ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_PARAM1 CVMX_BBP_TXSEQ_PARAM1_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_PARAM1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_PARAM1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E0C4ull);
}
#else
#define CVMX_BBP_TXSEQ_PARAM1 (CVMX_ADD_IO_SEG(0x00010F000086E0C4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_RAMACC CVMX_BBP_TXSEQ_RAMACC_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_RAMACC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_RAMACC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E080ull);
}
#else
#define CVMX_BBP_TXSEQ_RAMACC (CVMX_ADD_IO_SEG(0x00010F000086E080ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_RAMRD_LSW CVMX_BBP_TXSEQ_RAMRD_LSW_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_RAMRD_LSW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_RAMRD_LSW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E088ull);
}
#else
#define CVMX_BBP_TXSEQ_RAMRD_LSW (CVMX_ADD_IO_SEG(0x00010F000086E088ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_RAMRD_MSW CVMX_BBP_TXSEQ_RAMRD_MSW_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_RAMRD_MSW_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_RAMRD_MSW not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E08Cull);
}
#else
#define CVMX_BBP_TXSEQ_RAMRD_MSW (CVMX_ADD_IO_SEG(0x00010F000086E08Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_STATUS CVMX_BBP_TXSEQ_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E000ull);
}
#else
#define CVMX_BBP_TXSEQ_STATUS (CVMX_ADD_IO_SEG(0x00010F000086E000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_THRDSTAT0 CVMX_BBP_TXSEQ_THRDSTAT0_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_THRDSTAT0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_THRDSTAT0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E010ull);
}
#else
#define CVMX_BBP_TXSEQ_THRDSTAT0 (CVMX_ADD_IO_SEG(0x00010F000086E010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXSEQ_THRDX_CFG(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 15)))))
		cvmx_warn("CVMX_BBP_TXSEQ_THRDX_CFG(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086E100ull) + ((offset) & 15) * 8;
}
#else
#define CVMX_BBP_TXSEQ_THRDX_CFG(offset) (CVMX_ADD_IO_SEG(0x00010F000086E100ull) + ((offset) & 15) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
static inline uint64_t CVMX_BBP_TXSEQ_THRDX_PC(unsigned long offset)
{
	if (!(
	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 15)))))
		cvmx_warn("CVMX_BBP_TXSEQ_THRDX_PC(%lu) is invalid on this chip\n", offset);
	return CVMX_ADD_IO_SEG(0x00010F000086E104ull) + ((offset) & 15) * 8;
}
#else
#define CVMX_BBP_TXSEQ_THRDX_PC(offset) (CVMX_ADD_IO_SEG(0x00010F000086E104ull) + ((offset) & 15) * 8)
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TXSEQ_TIMER CVMX_BBP_TXSEQ_TIMER_FUNC()
static inline uint64_t CVMX_BBP_TXSEQ_TIMER_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TXSEQ_TIMER not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000086E040ull);
}
#else
#define CVMX_BBP_TXSEQ_TIMER (CVMX_ADD_IO_SEG(0x00010F000086E040ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_BIST_STATUS0 CVMX_BBP_TX_BIST_STATUS0_FUNC()
static inline uint64_t CVMX_BBP_TX_BIST_STATUS0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_BIST_STATUS0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874460ull);
}
#else
#define CVMX_BBP_TX_BIST_STATUS0 (CVMX_ADD_IO_SEG(0x00010F0000874460ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_BIST_STATUS1 CVMX_BBP_TX_BIST_STATUS1_FUNC()
static inline uint64_t CVMX_BBP_TX_BIST_STATUS1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_BIST_STATUS1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874464ull);
}
#else
#define CVMX_BBP_TX_BIST_STATUS1 (CVMX_ADD_IO_SEG(0x00010F0000874464ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_BIST_STATUS2 CVMX_BBP_TX_BIST_STATUS2_FUNC()
static inline uint64_t CVMX_BBP_TX_BIST_STATUS2_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_BIST_STATUS2 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874468ull);
}
#else
#define CVMX_BBP_TX_BIST_STATUS2 (CVMX_ADD_IO_SEG(0x00010F0000874468ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_BIST_STATUS3 CVMX_BBP_TX_BIST_STATUS3_FUNC()
static inline uint64_t CVMX_BBP_TX_BIST_STATUS3_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_BIST_STATUS3 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087446Cull);
}
#else
#define CVMX_BBP_TX_BIST_STATUS3 (CVMX_ADD_IO_SEG(0x00010F000087446Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_BIST_STATUS4 CVMX_BBP_TX_BIST_STATUS4_FUNC()
static inline uint64_t CVMX_BBP_TX_BIST_STATUS4_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_BIST_STATUS4 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874470ull);
}
#else
#define CVMX_BBP_TX_BIST_STATUS4 (CVMX_ADD_IO_SEG(0x00010F0000874470ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_BIST_STATUS5 CVMX_BBP_TX_BIST_STATUS5_FUNC()
static inline uint64_t CVMX_BBP_TX_BIST_STATUS5_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_BIST_STATUS5 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874474ull);
}
#else
#define CVMX_BBP_TX_BIST_STATUS5 (CVMX_ADD_IO_SEG(0x00010F0000874474ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_TX_EXT_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873054ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_TX_EXT_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873050ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_DEBUG_DAT CVMX_BBP_TX_EXT_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008730F8ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008730F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_DEBUG_SEL CVMX_BBP_TX_EXT_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008730F4ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008730F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_CLEAR CVMX_BBP_TX_EXT_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873018ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000873018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_ENB CVMX_BBP_TX_EXT_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087301Cull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087301Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_RSTATUS CVMX_BBP_TX_EXT_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873014ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000873014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_STATUS CVMX_BBP_TX_EXT_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873010ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_TEST CVMX_BBP_TX_EXT_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873020ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000873020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_MEMCLR_DATA CVMX_BBP_TX_EXT_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873090ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000873090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_MODE CVMX_BBP_TX_EXT_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873004ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000873004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_PRI_MODE CVMX_BBP_TX_EXT_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873008ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000873008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_START_ADDR0 CVMX_BBP_TX_EXT_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873030ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_STATUS CVMX_BBP_TX_EXT_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873000ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_XFER_MODE_COUNT CVMX_BBP_TX_EXT_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087302Cull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087302Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_XFER_Q_STATUS CVMX_BBP_TX_EXT_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087300Cull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087300Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_RD_XFER_START CVMX_BBP_TX_EXT_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873028ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000873028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_TX_EXT_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873454ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_TX_EXT_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873450ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_DEBUG_DAT CVMX_BBP_TX_EXT_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008734F8ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008734F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_DEBUG_SEL CVMX_BBP_TX_EXT_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008734F4ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008734F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_CLEAR CVMX_BBP_TX_EXT_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873418ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000873418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_ENB CVMX_BBP_TX_EXT_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087341Cull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087341Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_RSTATUS CVMX_BBP_TX_EXT_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873414ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000873414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_STATUS CVMX_BBP_TX_EXT_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873410ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_TEST CVMX_BBP_TX_EXT_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873420ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000873420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_MEMCLR_DATA CVMX_BBP_TX_EXT_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873490ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000873490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_MODE CVMX_BBP_TX_EXT_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873404ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000873404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_PRI_MODE CVMX_BBP_TX_EXT_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873408ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000873408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_START_ADDR0 CVMX_BBP_TX_EXT_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873430ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_STATUS CVMX_BBP_TX_EXT_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873400ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_XFER_MODE_COUNT CVMX_BBP_TX_EXT_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087342Cull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087342Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_XFER_Q_STATUS CVMX_BBP_TX_EXT_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087340Cull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087340Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_EXT_DMA_WR_XFER_START CVMX_BBP_TX_EXT_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_EXT_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_EXT_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873428ull);
}
#else
#define CVMX_BBP_TX_EXT_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000873428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C54ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C50ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_DAT CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871CF8ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000871CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_SEL CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871CF4ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000871CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_CLEAR CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C18ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000871C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_ENB CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C1Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000871C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_RSTATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C14ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000871C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C10ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_TEST CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C20ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000871C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MEMCLR_DATA CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C90ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000871C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MODE CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C04ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_MODE (CVMX_ADD_IO_SEG(0x00010F0000871C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_PRI_MODE CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C08ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000871C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C30ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C00ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_MODE_COUNT CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C2Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000871C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_Q_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C0Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_START CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871C28ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000871C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872054ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872050ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_DAT CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008720F8ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008720F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_SEL CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008720F4ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008720F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_CLEAR CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872018ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000872018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_ENB CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087201Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087201Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_RSTATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872014ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000872014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872010ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_TEST CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872020ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000872020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MEMCLR_DATA CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872090ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000872090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MODE CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872004ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_MODE (CVMX_ADD_IO_SEG(0x00010F0000872004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_PRI_MODE CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872008ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000872008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872030ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872000ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_MODE_COUNT CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087202Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087202Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_Q_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087200Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087200Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_START CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872028ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000872028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872454ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872450ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_DAT CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008724F8ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008724F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_SEL CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008724F4ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008724F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_CLEAR CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872418ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000872418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_ENB CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087241Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087241Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_RSTATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872414ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000872414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872410ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_TEST CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872420ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000872420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MEMCLR_DATA CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872490ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000872490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MODE CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872404ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_MODE (CVMX_ADD_IO_SEG(0x00010F0000872404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_PRI_MODE CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872408ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000872408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872430ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872400ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_MODE_COUNT CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087242Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087242Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_Q_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087240Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087240Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_START CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872428ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_RD_RM_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000872428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872854ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872850ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_DAT CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008728F8ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008728F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_SEL CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008728F4ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008728F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_CLEAR CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872818ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000872818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_ENB CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087281Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087281Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_RSTATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872814ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000872814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872810ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_TEST CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872820ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000872820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MEMCLR_DATA CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872890ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000872890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MODE CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872804ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_MODE (CVMX_ADD_IO_SEG(0x00010F0000872804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_PRI_MODE CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872808ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000872808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872830ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872800ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_MODE_COUNT CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087282Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087282Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_Q_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087280Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087280Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_START CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872828ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000872828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C54ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C50ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_DAT CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872CF8ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000872CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_SEL CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872CF4ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000872CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_CLEAR CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C18ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000872C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_ENB CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C1Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000872C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_RSTATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C14ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000872C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C10ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_TEST CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C20ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000872C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MEMCLR_DATA CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C90ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000872C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MODE CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C04ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_MODE (CVMX_ADD_IO_SEG(0x00010F0000872C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_PRI_MODE CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C08ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000872C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR0 CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C30ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000872C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C00ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_MODE_COUNT CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C2Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000872C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_Q_STATUS CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C0Cull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000872C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_START CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000872C28ull);
}
#else
#define CVMX_BBP_TX_IFFTPAPR_DMA_WR_1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000872C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874054ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000874054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874050ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000874050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_DAT CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008740F8ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008740F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_SEL CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008740F4ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008740F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_CLEAR CVMX_BBP_TX_INSTR_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874018ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000874018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_ENB CVMX_BBP_TX_INSTR_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087401Cull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087401Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_RSTATUS CVMX_BBP_TX_INSTR_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874014ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000874014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_STATUS CVMX_BBP_TX_INSTR_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874010ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000874010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_TEST CVMX_BBP_TX_INSTR_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874020ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000874020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_MEMCLR_DATA CVMX_BBP_TX_INSTR_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874090ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000874090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_MODE CVMX_BBP_TX_INSTR_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874004ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000874004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_PRI_MODE CVMX_BBP_TX_INSTR_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874008ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000874008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_START_ADDR0 CVMX_BBP_TX_INSTR_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874030ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000874030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_STATUS CVMX_BBP_TX_INSTR_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874000ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000874000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_XFER_MODE_COUNT CVMX_BBP_TX_INSTR_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087402Cull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087402Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_XFER_Q_STATUS CVMX_BBP_TX_INSTR_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087400Cull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087400Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INSTR_DMA_WR_XFER_START CVMX_BBP_TX_INSTR_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_INSTR_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INSTR_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000874028ull);
}
#else
#define CVMX_BBP_TX_INSTR_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000874028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_CBUF_END_ADDR0 CVMX_BBP_TX_INT_DMA_RD_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873854ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_CBUF_START_ADDR0 CVMX_BBP_TX_INT_DMA_RD_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873850ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_DEBUG_DAT CVMX_BBP_TX_INT_DMA_RD_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008738F8ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008738F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_DEBUG_SEL CVMX_BBP_TX_INT_DMA_RD_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008738F4ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008738F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_INTR_CLEAR CVMX_BBP_TX_INT_DMA_RD_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873818ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000873818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_INTR_ENB CVMX_BBP_TX_INT_DMA_RD_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087381Cull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087381Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_INTR_RSTATUS CVMX_BBP_TX_INT_DMA_RD_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873814ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000873814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_INTR_STATUS CVMX_BBP_TX_INT_DMA_RD_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873810ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_INTR_TEST CVMX_BBP_TX_INT_DMA_RD_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873820ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000873820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_MEMCLR_DATA CVMX_BBP_TX_INT_DMA_RD_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873890ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000873890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_MODE CVMX_BBP_TX_INT_DMA_RD_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873804ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_MODE (CVMX_ADD_IO_SEG(0x00010F0000873804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_PRI_MODE CVMX_BBP_TX_INT_DMA_RD_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873808ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000873808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_START_ADDR0 CVMX_BBP_TX_INT_DMA_RD_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873830ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_STATUS CVMX_BBP_TX_INT_DMA_RD_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873800ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_XFER_MODE_COUNT CVMX_BBP_TX_INT_DMA_RD_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087382Cull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087382Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_XFER_Q_STATUS CVMX_BBP_TX_INT_DMA_RD_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087380Cull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087380Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_RD_XFER_START CVMX_BBP_TX_INT_DMA_RD_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_RD_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_RD_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873828ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_RD_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000873828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_CBUF_END_ADDR0 CVMX_BBP_TX_INT_DMA_WR_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C54ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_CBUF_START_ADDR0 CVMX_BBP_TX_INT_DMA_WR_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C50ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_DEBUG_DAT CVMX_BBP_TX_INT_DMA_WR_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873CF8ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000873CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_DEBUG_SEL CVMX_BBP_TX_INT_DMA_WR_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873CF4ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000873CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_INTR_CLEAR CVMX_BBP_TX_INT_DMA_WR_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C18ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000873C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_INTR_ENB CVMX_BBP_TX_INT_DMA_WR_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C1Cull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000873C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_INTR_RSTATUS CVMX_BBP_TX_INT_DMA_WR_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C14ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000873C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_INTR_STATUS CVMX_BBP_TX_INT_DMA_WR_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C10ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_INTR_TEST CVMX_BBP_TX_INT_DMA_WR_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C20ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000873C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_MEMCLR_DATA CVMX_BBP_TX_INT_DMA_WR_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C90ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000873C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_MODE CVMX_BBP_TX_INT_DMA_WR_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C04ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_MODE (CVMX_ADD_IO_SEG(0x00010F0000873C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_PRI_MODE CVMX_BBP_TX_INT_DMA_WR_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C08ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000873C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_START_ADDR0 CVMX_BBP_TX_INT_DMA_WR_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C30ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000873C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_STATUS CVMX_BBP_TX_INT_DMA_WR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C00ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_XFER_MODE_COUNT CVMX_BBP_TX_INT_DMA_WR_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C2Cull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000873C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_XFER_Q_STATUS CVMX_BBP_TX_INT_DMA_WR_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C0Cull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000873C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_INT_DMA_WR_XFER_START CVMX_BBP_TX_INT_DMA_WR_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_INT_DMA_WR_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_INT_DMA_WR_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000873C28ull);
}
#else
#define CVMX_BBP_TX_INT_DMA_WR_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000873C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR0 CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870854ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870850ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_DAT CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008708F8ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008708F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_SEL CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008708F4ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008708F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_CLEAR CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870818ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000870818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_ENB CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087081Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087081Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_RSTATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870814ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000870814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_STATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870810ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_TEST CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870820ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000870820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MEMCLR_DATA CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870890ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000870890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MODE CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870804ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_MODE (CVMX_ADD_IO_SEG(0x00010F0000870804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_PRI_MODE CVMX_BBP_TX_LTEENC_DMA_RD_TB0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870808ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000870808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870830ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_STATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870800ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_MODE_COUNT CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087082Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087082Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_Q_STATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087080Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087080Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_START CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870828ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000870828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR0 CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C54ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870C54ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C50ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870C50ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_DAT CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870CF8ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F0000870CF8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_SEL CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870CF4ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F0000870CF4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_CLEAR CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C18ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000870C18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_ENB CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C1Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F0000870C1Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_RSTATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C14ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000870C14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_STATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C10ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870C10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_TEST CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C20ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000870C20ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MEMCLR_DATA CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C90ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000870C90ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MODE CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C04ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_MODE (CVMX_ADD_IO_SEG(0x00010F0000870C04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_PRI_MODE CVMX_BBP_TX_LTEENC_DMA_RD_TB1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C08ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000870C08ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C30ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870C30ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_STATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C00ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870C00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_MODE_COUNT CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C2Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F0000870C2Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_Q_STATUS CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C0Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870C0Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_START CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870C28ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_RD_TB1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000870C28ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871854ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871854ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871850ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871850ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_DAT CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008718F8ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008718F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_SEL CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008718F4ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008718F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_CLEAR CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871818ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000871818ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_ENB CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087181Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087181Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_RSTATUS CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871814ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000871814ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871810ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871810ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_TEST CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871820ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000871820ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MEMCLR_DATA CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871890ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000871890ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MODE CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871804ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_MODE (CVMX_ADD_IO_SEG(0x00010F0000871804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_PRI_MODE CVMX_BBP_TX_LTEENC_DMA_WR_CCH_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871808ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000871808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871830ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871830ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_CCH_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871800ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_MODE_COUNT CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087182Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087182Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_Q_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087180Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087180Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_START CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871828ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_CCH_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000871828ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871054ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871050ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_DAT CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008710F8ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008710F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_SEL CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008710F4ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008710F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_CLEAR CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871018ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000871018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_ENB CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087101Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087101Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_RSTATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871014ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000871014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871010ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_TEST CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871020ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000871020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MEMCLR_DATA CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871090ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000871090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MODE CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871004ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_MODE (CVMX_ADD_IO_SEG(0x00010F0000871004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_PRI_MODE CVMX_BBP_TX_LTEENC_DMA_WR_TB0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871008ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000871008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871030ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871000ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_MODE_COUNT CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087102Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087102Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_Q_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087100Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087100Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_START CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871028ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000871028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871454ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871450ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_DAT CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008714F8ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008714F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_SEL CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008714F4ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008714F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_CLEAR CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871418ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000871418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_ENB CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087141Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087141Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_RSTATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871414ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000871414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871410ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_TEST CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871420ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000871420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MEMCLR_DATA CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871490ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000871490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MODE CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871404ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_MODE (CVMX_ADD_IO_SEG(0x00010F0000871404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_PRI_MODE CVMX_BBP_TX_LTEENC_DMA_WR_TB1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871408ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000871408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR0 CVMX_BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871430ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000871430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871400ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000871400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_MODE_COUNT CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087142Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087142Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_Q_STATUS CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087140Cull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087140Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_START CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000871428ull);
}
#else
#define CVMX_BBP_TX_LTEENC_DMA_WR_TB1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000871428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR0 CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870054ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870054ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR0 CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870050ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870050ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_DAT CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008700F8ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008700F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_SEL CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008700F4ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008700F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_CLEAR CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870018ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000870018ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_ENB CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087001Cull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087001Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_RSTATUS CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870014ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000870014ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_STATUS CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870010ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870010ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_TEST CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870020ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000870020ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_MEMCLR_DATA CVMX_BBP_TX_RFIF_DMA_RD_0_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870090ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000870090ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_MODE CVMX_BBP_TX_RFIF_DMA_RD_0_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870004ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_MODE (CVMX_ADD_IO_SEG(0x00010F0000870004ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_PRI_MODE CVMX_BBP_TX_RFIF_DMA_RD_0_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870008ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000870008ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_START_ADDR0 CVMX_BBP_TX_RFIF_DMA_RD_0_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870030ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870030ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_STATUS CVMX_BBP_TX_RFIF_DMA_RD_0_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870000ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870000ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_MODE_COUNT CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087002Cull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087002Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_Q_STATUS CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087000Cull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087000Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_START CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870028ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_0_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000870028ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR0 CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870454ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870454ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR0 CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870450ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870450ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_DAT CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_DAT_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_DAT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_DAT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008704F8ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_DAT (CVMX_ADD_IO_SEG(0x00010F00008704F8ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_SEL CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_SEL_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_SEL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_SEL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F00008704F4ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_DEBUG_SEL (CVMX_ADD_IO_SEG(0x00010F00008704F4ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_CLEAR CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_CLEAR_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_CLEAR_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_CLEAR not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870418ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_CLEAR (CVMX_ADD_IO_SEG(0x00010F0000870418ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_ENB CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_ENB_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_ENB_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_ENB not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087041Cull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_ENB (CVMX_ADD_IO_SEG(0x00010F000087041Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_RSTATUS CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_RSTATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_RSTATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_RSTATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870414ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_RSTATUS (CVMX_ADD_IO_SEG(0x00010F0000870414ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_STATUS CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870410ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870410ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_TEST CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_TEST_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_TEST_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_TEST not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870420ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_INTR_TEST (CVMX_ADD_IO_SEG(0x00010F0000870420ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_MEMCLR_DATA CVMX_BBP_TX_RFIF_DMA_RD_1_MEMCLR_DATA_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_MEMCLR_DATA_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_MEMCLR_DATA not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870490ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_MEMCLR_DATA (CVMX_ADD_IO_SEG(0x00010F0000870490ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_MODE CVMX_BBP_TX_RFIF_DMA_RD_1_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870404ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_MODE (CVMX_ADD_IO_SEG(0x00010F0000870404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_PRI_MODE CVMX_BBP_TX_RFIF_DMA_RD_1_PRI_MODE_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_PRI_MODE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_PRI_MODE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870408ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_PRI_MODE (CVMX_ADD_IO_SEG(0x00010F0000870408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_START_ADDR0 CVMX_BBP_TX_RFIF_DMA_RD_1_START_ADDR0_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_START_ADDR0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_START_ADDR0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870430ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_START_ADDR0 (CVMX_ADD_IO_SEG(0x00010F0000870430ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_STATUS CVMX_BBP_TX_RFIF_DMA_RD_1_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870400ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_STATUS (CVMX_ADD_IO_SEG(0x00010F0000870400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_MODE_COUNT CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_MODE_COUNT_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_MODE_COUNT_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_MODE_COUNT not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087042Cull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_MODE_COUNT (CVMX_ADD_IO_SEG(0x00010F000087042Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_Q_STATUS CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_Q_STATUS_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_Q_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_Q_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000087040Cull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_Q_STATUS (CVMX_ADD_IO_SEG(0x00010F000087040Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_START CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_START_FUNC()
static inline uint64_t CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_START_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_START not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000870428ull);
}
#else
#define CVMX_BBP_TX_RFIF_DMA_RD_1_XFER_START (CVMX_ADD_IO_SEG(0x00010F0000870428ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_BYPASS_CONF CVMX_BBP_ULFE_BYPASS_CONF_FUNC()
static inline uint64_t CVMX_BBP_ULFE_BYPASS_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_BYPASS_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828A10ull);
}
#else
#define CVMX_BBP_ULFE_BYPASS_CONF (CVMX_ADD_IO_SEG(0x00010F0000828A10ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_CLK_CTRL CVMX_BBP_ULFE_CLK_CTRL_FUNC()
static inline uint64_t CVMX_BBP_ULFE_CLK_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_CLK_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082880Cull);
}
#else
#define CVMX_BBP_ULFE_CLK_CTRL (CVMX_ADD_IO_SEG(0x00010F000082880Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_COMMON_CTRL0 CVMX_BBP_ULFE_COMMON_CTRL0_FUNC()
static inline uint64_t CVMX_BBP_ULFE_COMMON_CTRL0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_COMMON_CTRL0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828A14ull);
}
#else
#define CVMX_BBP_ULFE_COMMON_CTRL0 (CVMX_ADD_IO_SEG(0x00010F0000828A14ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_COMMON_CTRL1 CVMX_BBP_ULFE_COMMON_CTRL1_FUNC()
static inline uint64_t CVMX_BBP_ULFE_COMMON_CTRL1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_COMMON_CTRL1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828A18ull);
}
#else
#define CVMX_BBP_ULFE_COMMON_CTRL1 (CVMX_ADD_IO_SEG(0x00010F0000828A18ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_CONTROL CVMX_BBP_ULFE_CONTROL_FUNC()
static inline uint64_t CVMX_BBP_ULFE_CONTROL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_CONTROL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828804ull);
}
#else
#define CVMX_BBP_ULFE_CONTROL (CVMX_ADD_IO_SEG(0x00010F0000828804ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_HAB_VERSION CVMX_BBP_ULFE_HAB_VERSION_FUNC()
static inline uint64_t CVMX_BBP_ULFE_HAB_VERSION_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_HAB_VERSION not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828B00ull);
}
#else
#define CVMX_BBP_ULFE_HAB_VERSION (CVMX_ADD_IO_SEG(0x00010F0000828B00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_HW_CORE_STATUS CVMX_BBP_ULFE_HW_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_ULFE_HW_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_HW_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828808ull);
}
#else
#define CVMX_BBP_ULFE_HW_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F0000828808ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_INT_MASK CVMX_BBP_ULFE_INT_MASK_FUNC()
static inline uint64_t CVMX_BBP_ULFE_INT_MASK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_INT_MASK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000082890Cull);
}
#else
#define CVMX_BBP_ULFE_INT_MASK (CVMX_ADD_IO_SEG(0x00010F000082890Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_INT_SRC CVMX_BBP_ULFE_INT_SRC_FUNC()
static inline uint64_t CVMX_BBP_ULFE_INT_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_INT_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828900ull);
}
#else
#define CVMX_BBP_ULFE_INT_SRC (CVMX_ADD_IO_SEG(0x00010F0000828900ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_NOISE_CONF CVMX_BBP_ULFE_NOISE_CONF_FUNC()
static inline uint64_t CVMX_BBP_ULFE_NOISE_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_NOISE_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828A04ull);
}
#else
#define CVMX_BBP_ULFE_NOISE_CONF (CVMX_ADD_IO_SEG(0x00010F0000828A04ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_STATUS CVMX_BBP_ULFE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_ULFE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828800ull);
}
#else
#define CVMX_BBP_ULFE_STATUS (CVMX_ADD_IO_SEG(0x00010F0000828800ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_ULFE_SYS_CONF CVMX_BBP_ULFE_SYS_CONF_FUNC()
static inline uint64_t CVMX_BBP_ULFE_SYS_CONF_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_ULFE_SYS_CONF not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F0000828A00ull);
}
#else
#define CVMX_BBP_ULFE_SYS_CONF (CVMX_ADD_IO_SEG(0x00010F0000828A00ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_AUTO_CLK_GATE CVMX_BBP_VITB_AUTO_CLK_GATE_FUNC()
static inline uint64_t CVMX_BBP_VITB_AUTO_CLK_GATE_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_AUTO_CLK_GATE not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A40Cull);
}
#else
#define CVMX_BBP_VITB_AUTO_CLK_GATE (CVMX_ADD_IO_SEG(0x00010F000084A40Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_CORE_STATUS CVMX_BBP_VITB_CORE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_VITB_CORE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_CORE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A408ull);
}
#else
#define CVMX_BBP_VITB_CORE_STATUS (CVMX_ADD_IO_SEG(0x00010F000084A408ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_INTR_MSK CVMX_BBP_VITB_INTR_MSK_FUNC()
static inline uint64_t CVMX_BBP_VITB_INTR_MSK_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_INTR_MSK not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A50Cull);
}
#else
#define CVMX_BBP_VITB_INTR_MSK (CVMX_ADD_IO_SEG(0x00010F000084A50Cull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_INTR_SRC CVMX_BBP_VITB_INTR_SRC_FUNC()
static inline uint64_t CVMX_BBP_VITB_INTR_SRC_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_INTR_SRC not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A500ull);
}
#else
#define CVMX_BBP_VITB_INTR_SRC (CVMX_ADD_IO_SEG(0x00010F000084A500ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_MODULE_CTRL CVMX_BBP_VITB_MODULE_CTRL_FUNC()
static inline uint64_t CVMX_BBP_VITB_MODULE_CTRL_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_MODULE_CTRL not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A404ull);
}
#else
#define CVMX_BBP_VITB_MODULE_CTRL (CVMX_ADD_IO_SEG(0x00010F000084A404ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_MODULE_STATUS CVMX_BBP_VITB_MODULE_STATUS_FUNC()
static inline uint64_t CVMX_BBP_VITB_MODULE_STATUS_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_MODULE_STATUS not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A400ull);
}
#else
#define CVMX_BBP_VITB_MODULE_STATUS (CVMX_ADD_IO_SEG(0x00010F000084A400ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_STATISTICS0 CVMX_BBP_VITB_STATISTICS0_FUNC()
static inline uint64_t CVMX_BBP_VITB_STATISTICS0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_STATISTICS0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A700ull);
}
#else
#define CVMX_BBP_VITB_STATISTICS0 (CVMX_ADD_IO_SEG(0x00010F000084A700ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_SYS_CFG0 CVMX_BBP_VITB_SYS_CFG0_FUNC()
static inline uint64_t CVMX_BBP_VITB_SYS_CFG0_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_SYS_CFG0 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A600ull);
}
#else
#define CVMX_BBP_VITB_SYS_CFG0 (CVMX_ADD_IO_SEG(0x00010F000084A600ull))
#endif
#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
#define CVMX_BBP_VITB_SYS_CFG1 CVMX_BBP_VITB_SYS_CFG1_FUNC()
static inline uint64_t CVMX_BBP_VITB_SYS_CFG1_FUNC(void)
{
	if (!(OCTEON_IS_MODEL(OCTEON_CNF71XX)))
		cvmx_warn("CVMX_BBP_VITB_SYS_CFG1 not supported on this chip\n");
	return CVMX_ADD_IO_SEG(0x00010F000084A604ull);
}
#else
#define CVMX_BBP_VITB_SYS_CFG1 (CVMX_ADD_IO_SEG(0x00010F000084A604ull))
#endif

/**
 * cvmx_bbp_adma_auto_clk_gate
 */
union cvmx_bbp_adma_auto_clk_gate {
	uint32_t u32;
	struct cvmx_bbp_adma_auto_clk_gate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t auto_gate                    : 1;  /**< 1==enable auto-clock-gating */
#else
	uint32_t auto_gate                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_adma_auto_clk_gate_s  cnf71xx;
};
typedef union cvmx_bbp_adma_auto_clk_gate cvmx_bbp_adma_auto_clk_gate_t;

/**
 * cvmx_bbp_adma_axi_rspcode
 */
union cvmx_bbp_adma_axi_rspcode {
	uint32_t u32;
	struct cvmx_bbp_adma_axi_rspcode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t ch7_axi_rspcode              : 2;  /**< dma \#7 AXI response - 0=OKAY, 2=SLVERR(BBR ECC error) */
	uint32_t ch6_axi_rspcode              : 2;  /**< dma \#6 AXI response - BBR always returns 0=OKAY */
	uint32_t ch5_axi_rspcode              : 2;  /**< dma \#5 AXI response - 0=OKAY, 2=SLVERR(BBR ECC error) */
	uint32_t ch4_axi_rspcode              : 2;  /**< dma \#4 AXI response - BBR always returns 0=OKAY */
	uint32_t ch3_axi_rspcode              : 2;  /**< dma \#3 AXI response - 0=OKAY, 2=SLVERR(BBR ECC error) */
	uint32_t ch2_axi_rspcode              : 2;  /**< dma \#2 AXI response - BBR always returns 0=OKAY */
	uint32_t ch1_axi_rspcode              : 2;  /**< dma \#1 AXI response - 0=OKAY, 2=SLVERR(BBR ECC error) */
	uint32_t ch0_axi_rspcode              : 2;  /**< dma \#0 AXI response - BBR always returns 0=OKAY */
#else
	uint32_t ch0_axi_rspcode              : 2;
	uint32_t ch1_axi_rspcode              : 2;
	uint32_t ch2_axi_rspcode              : 2;
	uint32_t ch3_axi_rspcode              : 2;
	uint32_t ch4_axi_rspcode              : 2;
	uint32_t ch5_axi_rspcode              : 2;
	uint32_t ch6_axi_rspcode              : 2;
	uint32_t ch7_axi_rspcode              : 2;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_adma_axi_rspcode_s    cnf71xx;
};
typedef union cvmx_bbp_adma_axi_rspcode cvmx_bbp_adma_axi_rspcode_t;

/**
 * cvmx_bbp_adma_axi_signal
 */
union cvmx_bbp_adma_axi_signal {
	uint32_t u32;
	struct cvmx_bbp_adma_axi_signal_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_25_31               : 7;
	uint32_t awcobuf                      : 1;  /**< ADMA_COBUF  - not used by BBR in 71xx */
	uint32_t reserved_10_23               : 14;
	uint32_t awlock                       : 2;  /**< ADMA_AWLOCK - not used by BBR in 71xx */
	uint32_t reserved_2_7                 : 6;
	uint32_t arlock                       : 2;  /**< ADMA_ARLOCK - not used by BBR in 71xx */
#else
	uint32_t arlock                       : 2;
	uint32_t reserved_2_7                 : 6;
	uint32_t awlock                       : 2;
	uint32_t reserved_10_23               : 14;
	uint32_t awcobuf                      : 1;
	uint32_t reserved_25_31               : 7;
#endif
	} s;
	struct cvmx_bbp_adma_axi_signal_s     cnf71xx;
};
typedef union cvmx_bbp_adma_axi_signal cvmx_bbp_adma_axi_signal_t;

/**
 * cvmx_bbp_adma_axierr_intr
 */
union cvmx_bbp_adma_axierr_intr {
	uint32_t u32;
	struct cvmx_bbp_adma_axierr_intr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t dma_ch_err                   : 8;  /**< error status of the DMA channel */
	uint32_t reserved_1_15                : 15;
	uint32_t axi_err_int                  : 1;  /**< AXI Error interrupt */
#else
	uint32_t axi_err_int                  : 1;
	uint32_t reserved_1_15                : 15;
	uint32_t dma_ch_err                   : 8;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_adma_axierr_intr_s    cnf71xx;
};
typedef union cvmx_bbp_adma_axierr_intr cvmx_bbp_adma_axierr_intr_t;

/**
 * cvmx_bbp_adma_dma#_addr_hi
 */
union cvmx_bbp_adma_dmax_addr_hi {
	uint32_t u32;
	struct cvmx_bbp_adma_dmax_addr_hi_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t hi_addr                      : 8;  /**< dma high address[39:32] */
#else
	uint32_t hi_addr                      : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_adma_dmax_addr_hi_s   cnf71xx;
};
typedef union cvmx_bbp_adma_dmax_addr_hi cvmx_bbp_adma_dmax_addr_hi_t;

/**
 * cvmx_bbp_adma_dma#_addr_lo
 */
union cvmx_bbp_adma_dmax_addr_lo {
	uint32_t u32;
	struct cvmx_bbp_adma_dmax_addr_lo_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t lo_addr                      : 32; /**< dma low address[31:0] */
#else
	uint32_t lo_addr                      : 32;
#endif
	} s;
	struct cvmx_bbp_adma_dmax_addr_lo_s   cnf71xx;
};
typedef union cvmx_bbp_adma_dmax_addr_lo cvmx_bbp_adma_dmax_addr_lo_t;

/**
 * cvmx_bbp_adma_dma#_cfg
 */
union cvmx_bbp_adma_dmax_cfg {
	uint32_t u32;
	struct cvmx_bbp_adma_dmax_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_30_31               : 2;
	uint32_t padlast                      : 1;  /**< pad unwritten bytes in last burst (wdma only) */
	uint32_t padfirst                     : 1;  /**< pad unwritten bytes in first burst (wdma only) */
	uint32_t reserved_25_27               : 3;
	uint32_t endian                       : 1;  /**< 0==byte-swap, 1==word */
	uint32_t reserved_18_23               : 6;
	uint32_t hmm_ofs                      : 2;  /**< HMM memory byte offset */
	uint32_t reserved_13_15               : 3;
	uint32_t axi_cache_last               : 1;  /**< AXI CACHE last burst mode, 1==force 0 on the last burst (wdma only) */
	uint32_t axi_cache                    : 4;  /**< AXI CACHE sideband
                                                         for wdma channels (0,2,4,6):
                                                            0=write-through, wait for IOB commit
                                                            1=write-allocate, wait for IOB commit
                                                            2=write-through, don't wait for IOB commit
                                                            3=write-allocate, don't wait for IOB commit
                                                         for rdma channels (1,3,5,7):
                                                            0=request L2C to discard the read data
                                                            2=request L2C to cache the read data */
	uint32_t reserved_6_7                 : 2;
	uint32_t bst_bound                    : 1;  /**< burst boundary (0==4kB, 1==128 byte) */
	uint32_t max_bstlen                   : 1;  /**< maximum AXI burst length(0==8 dword, 1==16 dword) */
	uint32_t reserved_1_3                 : 3;
	uint32_t enable                       : 1;  /**< 1 == dma enable */
#else
	uint32_t enable                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t max_bstlen                   : 1;
	uint32_t bst_bound                    : 1;
	uint32_t reserved_6_7                 : 2;
	uint32_t axi_cache                    : 4;
	uint32_t axi_cache_last               : 1;
	uint32_t reserved_13_15               : 3;
	uint32_t hmm_ofs                      : 2;
	uint32_t reserved_18_23               : 6;
	uint32_t endian                       : 1;
	uint32_t reserved_25_27               : 3;
	uint32_t padfirst                     : 1;
	uint32_t padlast                      : 1;
	uint32_t reserved_30_31               : 2;
#endif
	} s;
	struct cvmx_bbp_adma_dmax_cfg_s       cnf71xx;
};
typedef union cvmx_bbp_adma_dmax_cfg cvmx_bbp_adma_dmax_cfg_t;

/**
 * cvmx_bbp_adma_dma#_size
 */
union cvmx_bbp_adma_dmax_size {
	uint32_t u32;
	struct cvmx_bbp_adma_dmax_size_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t dma_size                     : 18; /**< dma transfer byte size */
#else
	uint32_t dma_size                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_adma_dmax_size_s      cnf71xx;
};
typedef union cvmx_bbp_adma_dmax_size cvmx_bbp_adma_dmax_size_t;

/**
 * cvmx_bbp_adma_dma_priority
 */
union cvmx_bbp_adma_dma_priority {
	uint32_t u32;
	struct cvmx_bbp_adma_dma_priority_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t rdma_arb_mode                : 1;  /**< read channel arb, if no favorite.  1=robin, 0=space */
	uint32_t rdma_fav                     : 4;  /**< favored DMA read channel, 0x0 means no favorite */
	uint32_t reserved_5_7                 : 3;
	uint32_t wdma_arb_mode                : 1;  /**< write channel arb, if no favorite.  1=robin, 0=space */
	uint32_t wdma_fav                     : 4;  /**< favored DMA write channel, 0xf means no favorite */
#else
	uint32_t wdma_fav                     : 4;
	uint32_t wdma_arb_mode                : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t rdma_fav                     : 4;
	uint32_t rdma_arb_mode                : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_adma_dma_priority_s   cnf71xx;
};
typedef union cvmx_bbp_adma_dma_priority cvmx_bbp_adma_dma_priority_t;

/**
 * cvmx_bbp_adma_dma_reset
 */
union cvmx_bbp_adma_dma_reset {
	uint32_t u32;
	struct cvmx_bbp_adma_dma_reset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dma_ch_reset                 : 8;  /**< dma channel reset */
#else
	uint32_t dma_ch_reset                 : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_adma_dma_reset_s      cnf71xx;
};
typedef union cvmx_bbp_adma_dma_reset cvmx_bbp_adma_dma_reset_t;

/**
 * cvmx_bbp_adma_dmadone_intr
 */
union cvmx_bbp_adma_dmadone_intr {
	uint32_t u32;
	struct cvmx_bbp_adma_dmadone_intr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dma_ch_done                  : 8;  /**< done-interrupt status of the DMA channel */
#else
	uint32_t dma_ch_done                  : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_adma_dmadone_intr_s   cnf71xx;
};
typedef union cvmx_bbp_adma_dmadone_intr cvmx_bbp_adma_dmadone_intr_t;

/**
 * cvmx_bbp_adma_intr_dis
 */
union cvmx_bbp_adma_intr_dis {
	uint32_t u32;
	struct cvmx_bbp_adma_intr_dis_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t axierr_intr_dis              : 1;  /**< AXI Error interrupt disable (1==enable) */
	uint32_t reserved_8_15                : 8;
	uint32_t dmadone_intr_dis             : 8;  /**< dma done interrupt disable (1==enable) */
#else
	uint32_t dmadone_intr_dis             : 8;
	uint32_t reserved_8_15                : 8;
	uint32_t axierr_intr_dis              : 1;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_adma_intr_dis_s       cnf71xx;
};
typedef union cvmx_bbp_adma_intr_dis cvmx_bbp_adma_intr_dis_t;

/**
 * cvmx_bbp_adma_intr_enb
 */
union cvmx_bbp_adma_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_adma_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t axierr_intr_enb              : 1;  /**< AXI Error interrupt enable (1==enable) */
	uint32_t reserved_8_15                : 8;
	uint32_t dmadone_intr_enb             : 8;  /**< dma done interrupt enable (1==enable) */
#else
	uint32_t dmadone_intr_enb             : 8;
	uint32_t reserved_8_15                : 8;
	uint32_t axierr_intr_enb              : 1;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_adma_intr_enb_s       cnf71xx;
};
typedef union cvmx_bbp_adma_intr_enb cvmx_bbp_adma_intr_enb_t;

/**
 * cvmx_bbp_adma_module_status
 */
union cvmx_bbp_adma_module_status {
	uint32_t u32;
	struct cvmx_bbp_adma_module_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dma_ch_stt                   : 8;  /**< dma channel status (1==transfer in progress) */
#else
	uint32_t dma_ch_stt                   : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_adma_module_status_s  cnf71xx;
};
typedef union cvmx_bbp_adma_module_status cvmx_bbp_adma_module_status_t;

/**
 * cvmx_bbp_dftdmp_bypass_mode
 */
union cvmx_bbp_dftdmp_bypass_mode {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_bypass_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t bypass_mode                  : 2;  /**< Bypass Mode
                                                             '00' = Deault (No Bypass)
                                                             '01' = DFT Engine Bypass (Not Supported)
                                                             '10' = Demapper Bypass
                                                             '11' = All Bypass (Not Supported)
                                                         When the DFT engine uses DFT engine mode, the demapper engine
                                                         doesn't need operation. */
#else
	uint32_t bypass_mode                  : 2;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_dftdmp_bypass_mode_s  cnf71xx;
};
typedef union cvmx_bbp_dftdmp_bypass_mode cvmx_bbp_dftdmp_bypass_mode_t;

/**
 * cvmx_bbp_dftdmp_clk_ctrl
 */
union cvmx_bbp_dftdmp_clk_ctrl {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_clk_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t clock_gating                 : 1;  /**< '0' = auto-clock-gating off (default)
                                                         '1' = auto-clock-gating on */
#else
	uint32_t clock_gating                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_dftdmp_clk_ctrl_s     cnf71xx;
};
typedef union cvmx_bbp_dftdmp_clk_ctrl cvmx_bbp_dftdmp_clk_ctrl_t;

/**
 * cvmx_bbp_dftdmp_control
 */
union cvmx_bbp_dftdmp_control {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_control_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t dftdmp_start                 : 1;  /**< '1'= start the HAB
                                                         (auto-clear) */
#else
	uint32_t dftdmp_start                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_dftdmp_control_s      cnf71xx;
};
typedef union cvmx_bbp_dftdmp_control cvmx_bbp_dftdmp_control_t;

/**
 * cvmx_bbp_dftdmp_demapllr_rd_tout
 */
union cvmx_bbp_dftdmp_demapllr_rd_tout {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_demapllr_rd_tout_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t demaplr_rd_tout              : 32; /**< Demapped LLR Read Timeout Value
                                                         If bypass_mode = 0b00
                                                         QPSK: (number of subcarriers*0.5*2)*2
                                                         16QAM: (number of subcarriers*0.5*2)*2
                                                         64QAM: (number of subcarriers*0.5*3)*2
                                                         If bypass_mode = 0b10
                                                         (number of subcarriers*2)*2 */
#else
	uint32_t demaplr_rd_tout              : 32;
#endif
	} s;
	struct cvmx_bbp_dftdmp_demapllr_rd_tout_s cnf71xx;
};
typedef union cvmx_bbp_dftdmp_demapllr_rd_tout cvmx_bbp_dftdmp_demapllr_rd_tout_t;

/**
 * cvmx_bbp_dftdmp_dft_mode
 */
union cvmx_bbp_dftdmp_dft_mode {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_dft_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t dft_mode                     : 1;  /**< DFT Engine Mode
                                                            '0' = DFT Engine Mode
                                                            '1' = iDFT Engine Mode
                                                         The DFT engine can use DFT mode or iDFT mode. This Filed can decide
                                                         DFT engine mode. */
#else
	uint32_t dft_mode                     : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_dftdmp_dft_mode_s     cnf71xx;
};
typedef union cvmx_bbp_dftdmp_dft_mode cvmx_bbp_dftdmp_dft_mode_t;

/**
 * cvmx_bbp_dftdmp_dmard_gap_cnt
 */
union cvmx_bbp_dftdmp_dmard_gap_cnt {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_dmard_gap_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t dmard_gap_cnt                : 16; /**< DMA Read Gap Counter */
#else
	uint32_t dmard_gap_cnt                : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_dftdmp_dmard_gap_cnt_s cnf71xx;
};
typedef union cvmx_bbp_dftdmp_dmard_gap_cnt cvmx_bbp_dftdmp_dmard_gap_cnt_t;

/**
 * cvmx_bbp_dftdmp_eng_ver
 */
union cvmx_bbp_dftdmp_eng_ver {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_eng_ver_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t demap_ver                    : 16; /**< 16bit Demapper Engine Version */
	uint32_t dft_ver                      : 16; /**< 16bit DFT Engine Version */
#else
	uint32_t dft_ver                      : 16;
	uint32_t demap_ver                    : 16;
#endif
	} s;
	struct cvmx_bbp_dftdmp_eng_ver_s      cnf71xx;
};
typedef union cvmx_bbp_dftdmp_eng_ver cvmx_bbp_dftdmp_eng_ver_t;

/**
 * cvmx_bbp_dftdmp_estsym_wr_cnt
 */
union cvmx_bbp_dftdmp_estsym_wr_cnt {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_estsym_wr_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t estsym_wr_tout               : 32; /**< Estimated Symbol Write Timeout Value
                                                         Set to (number of subcariers*2)*2 */
#else
	uint32_t estsym_wr_tout               : 32;
#endif
	} s;
	struct cvmx_bbp_dftdmp_estsym_wr_cnt_s cnf71xx;
};
typedef union cvmx_bbp_dftdmp_estsym_wr_cnt cvmx_bbp_dftdmp_estsym_wr_cnt_t;

/**
 * cvmx_bbp_dftdmp_hw_core_status
 */
union cvmx_bbp_dftdmp_hw_core_status {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_hw_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t engine_busy                  : 1;  /**< Indicates if the Internal Engine is busy
                                                               '0' = ready
                                                               '1' = busy
                                                         This bit is set 1 when LLR data all transferred
                                                         through DMA write but WR_DONE doesn't assert */
	uint32_t dftdmp_busy                  : 1;  /**< Busy (linked register 0x0 bit0) */
#else
	uint32_t dftdmp_busy                  : 1;
	uint32_t engine_busy                  : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_dftdmp_hw_core_status_s cnf71xx;
};
typedef union cvmx_bbp_dftdmp_hw_core_status cvmx_bbp_dftdmp_hw_core_status_t;

/**
 * cvmx_bbp_dftdmp_hw_test_mode
 */
union cvmx_bbp_dftdmp_hw_test_mode {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_hw_test_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t hw_test_mode                 : 1;  /**< HW Test Mode
                                                         '0' = No HW Test Port Output
                                                         '1' = HW Test Port Output Enable */
#else
	uint32_t hw_test_mode                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_dftdmp_hw_test_mode_s cnf71xx;
};
typedef union cvmx_bbp_dftdmp_hw_test_mode cvmx_bbp_dftdmp_hw_test_mode_t;

/**
 * cvmx_bbp_dftdmp_int_mask
 */
union cvmx_bbp_dftdmp_int_mask {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_int_mask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t int_msk                      : 10; /**< Interrupt Mask */
#else
	uint32_t int_msk                      : 10;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_dftdmp_int_mask_s     cnf71xx;
};
typedef union cvmx_bbp_dftdmp_int_mask cvmx_bbp_dftdmp_int_mask_t;

/**
 * cvmx_bbp_dftdmp_int_src
 */
union cvmx_bbp_dftdmp_int_src {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_int_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t wrong_para                   : 1;  /**< Wrong Parameter Setting
                                                         '0' = Modulation Order and Number of subcarrier are written properly.
                                                         '1' = Modulation Order and Number of subcarrier are not written properly. */
	uint32_t dma_wr_undrflw               : 1;  /**< DMA Write Data Underflow (Only used for debugging)
                                                            '1' = More data(number of words) is being transferred than configured.
                                                         If the proper number of data is transferred but WR_DONE signal isn't
                                                         asserted, wait for WR_DONE signal and set 1 value in 0x8 bit 1. */
	uint32_t dma_wr_tout                  : 1;  /**< DMA Write Data Time Out
                                                         '1' = Last subframe data is not transferred in the expected time stamp */
	uint32_t demapllr_ff_ff               : 1;  /**< DMA Write FIFO Full (Primary FIFO or Secondary FIFO)
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t wr_overflow                  : 1;  /**< DMA Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t rd_overflow                  : 1;  /**< DMA Read Data Overflow
                                                         '1' = HAB recieved more data(number of words) than is programmed for */
	uint32_t rd_underflow                 : 1;  /**< DMA Read Data Underflow
                                                         '1' = HAB recieved less data(number of words) than is programmed for */
	uint32_t rd_timeout                   : 1;  /**< DMA Read Data Time Out
                                                         '1' = Last subframe data is not recieved in the expected time stamp */
	uint32_t abnrm_start                  : 1;  /**< Abnormal Start
                                                         '0' = "start" is inserted on the hab ready state
                                                           '1' = "start" is inserted on the hab busy state */
	uint32_t dftdmp_done                  : 1;  /**< Task Completion
                                                            '0' = task not completed
                                                            '1' = task completed
                                                         This bit is set 1 when parameter are set properly, write start bit and the
                                                         DFTDMP HAB operates normally.
                                                         If this interrupt occurs with errors, the DFTDMP HAB result data can't trust. */
#else
	uint32_t dftdmp_done                  : 1;
	uint32_t abnrm_start                  : 1;
	uint32_t rd_timeout                   : 1;
	uint32_t rd_underflow                 : 1;
	uint32_t rd_overflow                  : 1;
	uint32_t wr_overflow                  : 1;
	uint32_t demapllr_ff_ff               : 1;
	uint32_t dma_wr_tout                  : 1;
	uint32_t dma_wr_undrflw               : 1;
	uint32_t wrong_para                   : 1;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_dftdmp_int_src_s      cnf71xx;
};
typedef union cvmx_bbp_dftdmp_int_src cvmx_bbp_dftdmp_int_src_t;

/**
 * cvmx_bbp_dftdmp_lab_ver
 */
union cvmx_bbp_dftdmp_lab_ver {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_lab_ver_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t lab_ver                      : 32; /**< 16bit Laboratory Version */
#else
	uint32_t lab_ver                      : 32;
#endif
	} s;
	struct cvmx_bbp_dftdmp_lab_ver_s      cnf71xx;
};
typedef union cvmx_bbp_dftdmp_lab_ver cvmx_bbp_dftdmp_lab_ver_t;

/**
 * cvmx_bbp_dftdmp_llr_bit_wid
 */
union cvmx_bbp_dftdmp_llr_bit_wid {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_llr_bit_wid_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t llr_bit_wid                  : 8;  /**< LLR Bit Width
                                                         This is a value of a valid demapped LLR bits.
                                                         8 bits LLR is right shifted if LLR_BIT_WIDTH < 8 */
#else
	uint32_t llr_bit_wid                  : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_dftdmp_llr_bit_wid_s  cnf71xx;
};
typedef union cvmx_bbp_dftdmp_llr_bit_wid cvmx_bbp_dftdmp_llr_bit_wid_t;

/**
 * cvmx_bbp_dftdmp_parameter1
 */
union cvmx_bbp_dftdmp_parameter1 {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_parameter1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t llr_zero_pad                 : 1;  /**< Add LLR Zero Padding
                                                          Some modulation order and RB's need to assert 2 word zero when DMA
                                                          write(LLR data read) operation.
                                                         - 0: No zero padding
                                                         - 1: Zero padding */
	uint32_t reserved_26_27               : 2;
	uint32_t mod_order                    : 2;  /**< Modulation Order
                                                         '00' = Default (No Operation, Error Case)
                                                         '01' = QPSK
                                                         '10' = 16QAM
                                                         '11' = 64QAM */
	uint32_t num_sym_stream               : 8;  /**< Number of Symbol Stream (1~24)
                                                         Number of symbol per a DFTDMP HAB operation */
	uint32_t num_sub_carrier              : 16; /**< Number of Sub-Carrier ; Max ~ 1200 */
#else
	uint32_t num_sub_carrier              : 16;
	uint32_t num_sym_stream               : 8;
	uint32_t mod_order                    : 2;
	uint32_t reserved_26_27               : 2;
	uint32_t llr_zero_pad                 : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_dftdmp_parameter1_s   cnf71xx;
};
typedef union cvmx_bbp_dftdmp_parameter1 cvmx_bbp_dftdmp_parameter1_t;

/**
 * cvmx_bbp_dftdmp_parameter2
 */
union cvmx_bbp_dftdmp_parameter2 {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_parameter2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t tot_num_dma_wr_words         : 16; /**< Total Number of DMA_WR words */
	uint32_t tot_num_sub_carrier          : 16; /**< Number of Sub-Carrier (Max:28800) */
#else
	uint32_t tot_num_sub_carrier          : 16;
	uint32_t tot_num_dma_wr_words         : 16;
#endif
	} s;
	struct cvmx_bbp_dftdmp_parameter2_s   cnf71xx;
};
typedef union cvmx_bbp_dftdmp_parameter2 cvmx_bbp_dftdmp_parameter2_t;

/**
 * cvmx_bbp_dftdmp_qam_dist1
 */
union cvmx_bbp_dftdmp_qam_dist1 {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_qam_dist1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t qam64_distance2              : 16; /**< 64QAM Distance2
                                                         This is a distance2 value for decision symbol when 64QAM demapping operation. */
	uint32_t qam16_distance               : 16; /**< 16QAM Distance
                                                         This is a distance value for decision symbol when 16QAM demapping operation. */
#else
	uint32_t qam16_distance               : 16;
	uint32_t qam64_distance2              : 16;
#endif
	} s;
	struct cvmx_bbp_dftdmp_qam_dist1_s    cnf71xx;
};
typedef union cvmx_bbp_dftdmp_qam_dist1 cvmx_bbp_dftdmp_qam_dist1_t;

/**
 * cvmx_bbp_dftdmp_qam_dist2
 */
union cvmx_bbp_dftdmp_qam_dist2 {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_qam_dist2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t qam64_distance6              : 16; /**< 64QAM Distance6
                                                         This is a distance6 value for decision symbol when 64QAM demapping operation. */
	uint32_t qam64_distance4              : 16; /**< 64QAM Distance4
                                                         This is a distance4 value for decision symbol when 64QAM demapping operation. */
#else
	uint32_t qam64_distance4              : 16;
	uint32_t qam64_distance6              : 16;
#endif
	} s;
	struct cvmx_bbp_dftdmp_qam_dist2_s    cnf71xx;
};
typedef union cvmx_bbp_dftdmp_qam_dist2 cvmx_bbp_dftdmp_qam_dist2_t;

/**
 * cvmx_bbp_dftdmp_ss_ctrl
 */
union cvmx_bbp_dftdmp_ss_ctrl {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_ss_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t qam64_rshift                 : 8;  /**< 64QAM Right Shift
                                                         This is a value of changing from 16 bits I/Q to 8 bits LLR when 64QAM mode. */
	uint32_t qam16_rshift                 : 8;  /**< 16QAM Right Shift
                                                         This is a value of changing from 16 bits I/Q to 8 bits LLR when 16QAM mode. */
	uint32_t qpsk_rshift                  : 8;  /**< QPSK Right Shift
                                                         This is a value of changing from 16 bits I/Q to 8 bits LLR when QPSK mode. */
#else
	uint32_t qpsk_rshift                  : 8;
	uint32_t qam16_rshift                 : 8;
	uint32_t qam64_rshift                 : 8;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_dftdmp_ss_ctrl_s      cnf71xx;
};
typedef union cvmx_bbp_dftdmp_ss_ctrl cvmx_bbp_dftdmp_ss_ctrl_t;

/**
 * cvmx_bbp_dftdmp_status
 *
 * BBP_DFTDMP_CSR_VERSION = v1.0    // hab_source_version
 *
 */
union cvmx_bbp_dftdmp_status {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t dftdmp_busy                  : 1;  /**< Indicates if the Hardware accelerator(DFTDMP) is busy
                                                         '0' = ready
                                                         '1' = busy */
#else
	uint32_t dftdmp_busy                  : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_dftdmp_status_s       cnf71xx;
};
typedef union cvmx_bbp_dftdmp_status cvmx_bbp_dftdmp_status_t;

/**
 * cvmx_bbp_dftdmp_ver
 */
union cvmx_bbp_dftdmp_ver {
	uint32_t u32;
	struct cvmx_bbp_dftdmp_ver_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t drop_ver                     : 16; /**< 16bit Drop Version */
	uint32_t release_ver                  : 16; /**< 16bit Release Version */
#else
	uint32_t release_ver                  : 16;
	uint32_t drop_ver                     : 16;
#endif
	} s;
	struct cvmx_bbp_dftdmp_ver_s          cnf71xx;
};
typedef union cvmx_bbp_dftdmp_ver cvmx_bbp_dftdmp_ver_t;

/**
 * cvmx_bbp_dle_bypass_mode
 */
union cvmx_bbp_dle_bypass_mode {
	uint32_t u32;
	struct cvmx_bbp_dle_bypass_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t pdsch1_bypass_en             : 1;  /**< PDSCH1 Bypass enable */
	uint32_t pdsch0_bypass_en             : 1;  /**< PDSCH0 Bypass enable */
	uint32_t pdcch_bypass_en              : 1;  /**< PDCCH Bypass enable */
#else
	uint32_t pdcch_bypass_en              : 1;
	uint32_t pdsch0_bypass_en             : 1;
	uint32_t pdsch1_bypass_en             : 1;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_dle_bypass_mode_s     cnf71xx;
};
typedef union cvmx_bbp_dle_bypass_mode cvmx_bbp_dle_bypass_mode_t;

/**
 * cvmx_bbp_dle_clk_ctrl
 */
union cvmx_bbp_dle_clk_ctrl {
	uint32_t u32;
	struct cvmx_bbp_dle_clk_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t clock_gating                 : 1;  /**< '0' = auto-clock-gating off (default)
                                                         '1' = auto-clock-gating on */
#else
	uint32_t clock_gating                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_dle_clk_ctrl_s        cnf71xx;
};
typedef union cvmx_bbp_dle_clk_ctrl cvmx_bbp_dle_clk_ctrl_t;

/**
 * cvmx_bbp_dle_control
 */
union cvmx_bbp_dle_control {
	uint32_t u32;
	struct cvmx_bbp_dle_control_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t pdsch_start                  : 1;  /**< '1'= start the HAB(PDSCH)
                                                         (auto-clear) */
	uint32_t pdcch_start                  : 1;  /**< '1'= start the HAB(PDCCH)
                                                         (auto-clear) */
	uint32_t pbch_start                   : 1;  /**< '1'= start the HAB(PBCH)
                                                         (auto-clear) */
#else
	uint32_t pbch_start                   : 1;
	uint32_t pdcch_start                  : 1;
	uint32_t pdsch_start                  : 1;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_dle_control_s         cnf71xx;
};
typedef union cvmx_bbp_dle_control cvmx_bbp_dle_control_t;

/**
 * cvmx_bbp_dle_encoded_pbch0
 */
union cvmx_bbp_dle_encoded_pbch0 {
	uint32_t u32;
	struct cvmx_bbp_dle_encoded_pbch0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t encoded_pbch0                : 32; /**< Encoded PBCH[31:0] */
#else
	uint32_t encoded_pbch0                : 32;
#endif
	} s;
	struct cvmx_bbp_dle_encoded_pbch0_s   cnf71xx;
};
typedef union cvmx_bbp_dle_encoded_pbch0 cvmx_bbp_dle_encoded_pbch0_t;

/**
 * cvmx_bbp_dle_encoded_pbch1
 */
union cvmx_bbp_dle_encoded_pbch1 {
	uint32_t u32;
	struct cvmx_bbp_dle_encoded_pbch1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t encoded_pbch1                : 32; /**< Encoded PBCH[63:32] */
#else
	uint32_t encoded_pbch1                : 32;
#endif
	} s;
	struct cvmx_bbp_dle_encoded_pbch1_s   cnf71xx;
};
typedef union cvmx_bbp_dle_encoded_pbch1 cvmx_bbp_dle_encoded_pbch1_t;

/**
 * cvmx_bbp_dle_encoded_pbch2
 */
union cvmx_bbp_dle_encoded_pbch2 {
	uint32_t u32;
	struct cvmx_bbp_dle_encoded_pbch2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t encoded_pbch2                : 32; /**< Encoded PBCH[95:64] */
#else
	uint32_t encoded_pbch2                : 32;
#endif
	} s;
	struct cvmx_bbp_dle_encoded_pbch2_s   cnf71xx;
};
typedef union cvmx_bbp_dle_encoded_pbch2 cvmx_bbp_dle_encoded_pbch2_t;

/**
 * cvmx_bbp_dle_encoded_pbch3
 */
union cvmx_bbp_dle_encoded_pbch3 {
	uint32_t u32;
	struct cvmx_bbp_dle_encoded_pbch3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t encoded_pbch3                : 24; /**< Encoded PBCH[119:96] */
#else
	uint32_t encoded_pbch3                : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_dle_encoded_pbch3_s   cnf71xx;
};
typedef union cvmx_bbp_dle_encoded_pbch3 cvmx_bbp_dle_encoded_pbch3_t;

/**
 * cvmx_bbp_dle_grant_num
 *
 * Notes:
 * Number of DL grant + Number of RACH grant + Number of UL grant + Number of TPC grant = Number of PDCCH per TTI
 *
 */
union cvmx_bbp_dle_grant_num {
	uint32_t u32;
	struct cvmx_bbp_dle_grant_num_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t tpc_grant_num                : 8;  /**< Number of TPC grant per TTI from higher layer. */
	uint32_t ul_grant_num                 : 8;  /**< Number of UL grant per TTI from higher layer. */
	uint32_t rach_grant_num               : 8;  /**< Number of RACH grant per TTI from higher layer. */
	uint32_t dl_grant_num                 : 8;  /**< Number of DL grant per TTI from higher layer.
                                                         It also represents the number of PDSCH per TTI. */
#else
	uint32_t dl_grant_num                 : 8;
	uint32_t rach_grant_num               : 8;
	uint32_t ul_grant_num                 : 8;
	uint32_t tpc_grant_num                : 8;
#endif
	} s;
	struct cvmx_bbp_dle_grant_num_s       cnf71xx;
};
typedef union cvmx_bbp_dle_grant_num cvmx_bbp_dle_grant_num_t;

/**
 * cvmx_bbp_dle_hab_version
 */
union cvmx_bbp_dle_hab_version {
	uint32_t u32;
	struct cvmx_bbp_dle_hab_version_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t drop_ver                     : 16; /**< 16bit Drop Version */
	uint32_t release_ver                  : 16; /**< 16bit Release Version */
#else
	uint32_t release_ver                  : 16;
	uint32_t drop_ver                     : 16;
#endif
	} s;
	struct cvmx_bbp_dle_hab_version_s     cnf71xx;
};
typedef union cvmx_bbp_dle_hab_version cvmx_bbp_dle_hab_version_t;

/**
 * cvmx_bbp_dle_hmm_rd_tout_val
 */
union cvmx_bbp_dle_hmm_rd_tout_val {
	uint32_t u32;
	struct cvmx_bbp_dle_hmm_rd_tout_val_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t hmm_rd_tout_val              : 18; /**< HMM_RD Timeout value(clks) */
#else
	uint32_t hmm_rd_tout_val              : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_dle_hmm_rd_tout_val_s cnf71xx;
};
typedef union cvmx_bbp_dle_hmm_rd_tout_val cvmx_bbp_dle_hmm_rd_tout_val_t;

/**
 * cvmx_bbp_dle_hw_core_status
 */
union cvmx_bbp_dle_hw_core_status {
	uint32_t u32;
	struct cvmx_bbp_dle_hw_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t pdsch_engn_busy              : 1;  /**< Indicates if the Internal PDSCH Engine is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t pdcch_engn_busy              : 1;  /**< Indicates if the Internal PDCCH Engine is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t pbch_engn_busy               : 1;  /**< Indicates if the Internal PBCH Engine is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t pdsch_busy                   : 1;  /**< PDSCH Busy (linked register 0x0 bit2) */
	uint32_t pdcch_busy                   : 1;  /**< PDCCH Busy (linked register 0x0 bit1) */
	uint32_t pbch_busy                    : 1;  /**< PBCH Busy (linked register 0x0 bit0) */
#else
	uint32_t pbch_busy                    : 1;
	uint32_t pdcch_busy                   : 1;
	uint32_t pdsch_busy                   : 1;
	uint32_t pbch_engn_busy               : 1;
	uint32_t pdcch_engn_busy              : 1;
	uint32_t pdsch_engn_busy              : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_dle_hw_core_status_s  cnf71xx;
};
typedef union cvmx_bbp_dle_hw_core_status cvmx_bbp_dle_hw_core_status_t;

/**
 * cvmx_bbp_dle_int_mask
 */
union cvmx_bbp_dle_int_mask {
	uint32_t u32;
	struct cvmx_bbp_dle_int_mask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t int_msk                      : 32; /**< Interrupt Mask */
#else
	uint32_t int_msk                      : 32;
#endif
	} s;
	struct cvmx_bbp_dle_int_mask_s        cnf71xx;
};
typedef union cvmx_bbp_dle_int_mask cvmx_bbp_dle_int_mask_t;

/**
 * cvmx_bbp_dle_int_src
 */
union cvmx_bbp_dle_int_src {
	uint32_t u32;
	struct cvmx_bbp_dle_int_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t hmm_wr2_full                 : 1;  /**< DMA2 Write FIFO Full
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t hmm_wr1_full                 : 1;  /**< DMA1 Write FIFO Full
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t hmm_wr0_full                 : 1;  /**< DMA0 Write FIFO Full
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t hmm_wr2_oflow                : 1;  /**< DMA2 Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t hmm_wr1_oflow                : 1;  /**< DMA1 Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t hmm_wr0_oflow                : 1;  /**< DMA0 Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t hmm_rd1_oflow                : 1;  /**< DMA1 Read Data Overflow
                                                         '1' = HAB recieved more data(number of words) than is programmed for */
	uint32_t hmm_rd0_oflow                : 1;  /**< DMA0 Read Data Overflow
                                                         '1' = HAB recieved more data(number of words) than is programmed for */
	uint32_t hmm_rd1_uflow                : 1;  /**< DMA1 Read Data Underflow
                                                         '1' = HAB recieved less data(number of words) than is programmed for */
	uint32_t hmm_rd0_uflow                : 1;  /**< DMA0 Read Data Underflow
                                                         '1' = HAB recieved less data(number of words) than is programmed for */
	uint32_t hmm_rd1_rd_tout              : 1;  /**< DMA1 Read Data Time Out
                                                         '1' = Last subframe data is not recieved in the expected time stamp */
	uint32_t hmm_rd0_rd_tout              : 1;  /**< DMA0 Read Data Time Out
                                                         '1' = Last subframe data is not recieved in the expected time stamp */
	uint32_t pdsch_ab_start               : 1;  /**< PDSCH Abnormal Start
                                                         '0' = "start" is inserted on the hab ready state
                                                         '1' = "start" is inserted on the hab busy state */
	uint32_t pdcch_ab_start               : 1;  /**< PDCCH Abnormal Start
                                                         '0' = "start" is inserted on the hab ready state
                                                         '1' = "start" is inserted on the hab busy state */
	uint32_t pbch_ab_start                : 1;  /**< PBCH Abnormal Start
                                                         '0' = "start" is inserted on the hab ready state
                                                         '1' = "start" is inserted on the hab busy state */
	uint32_t pdsch_done                   : 1;  /**< '0' = PDSCH task not completed
                                                         '1' = PDSCH task completed */
	uint32_t pdcch_done                   : 1;  /**< '0' = PDCCH task not completed
                                                         '1' = PDCCH task completed */
	uint32_t pbch_done                    : 1;  /**< '0' = PBCH task not completed
                                                         '1' = PBCH task completed */
#else
	uint32_t pbch_done                    : 1;
	uint32_t pdcch_done                   : 1;
	uint32_t pdsch_done                   : 1;
	uint32_t pbch_ab_start                : 1;
	uint32_t pdcch_ab_start               : 1;
	uint32_t pdsch_ab_start               : 1;
	uint32_t hmm_rd0_rd_tout              : 1;
	uint32_t hmm_rd1_rd_tout              : 1;
	uint32_t hmm_rd0_uflow                : 1;
	uint32_t hmm_rd1_uflow                : 1;
	uint32_t hmm_rd0_oflow                : 1;
	uint32_t hmm_rd1_oflow                : 1;
	uint32_t hmm_wr0_oflow                : 1;
	uint32_t hmm_wr1_oflow                : 1;
	uint32_t hmm_wr2_oflow                : 1;
	uint32_t hmm_wr0_full                 : 1;
	uint32_t hmm_wr1_full                 : 1;
	uint32_t hmm_wr2_full                 : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_dle_int_src_s         cnf71xx;
};
typedef union cvmx_bbp_dle_int_src cvmx_bbp_dle_int_src_t;

/**
 * cvmx_bbp_dle_pbch_conf
 */
union cvmx_bbp_dle_pbch_conf {
	uint32_t u32;
	struct cvmx_bbp_dle_pbch_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t num_of_ap                    : 2;  /**< Number of transmit antenna ports at eNode-B
                                                         '00' - 1
                                                         '01' - 2
                                                         '10' - 4
                                                         '11' - reserved */
	uint32_t pbch_size                    : 6;  /**< PBCH size */
#else
	uint32_t pbch_size                    : 6;
	uint32_t num_of_ap                    : 2;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_dle_pbch_conf_s       cnf71xx;
};
typedef union cvmx_bbp_dle_pbch_conf cvmx_bbp_dle_pbch_conf_t;

/**
 * cvmx_bbp_dle_pbch_data
 */
union cvmx_bbp_dle_pbch_data {
	uint32_t u32;
	struct cvmx_bbp_dle_pbch_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pbch_data                    : 32; /**< PBCH Data */
#else
	uint32_t pbch_data                    : 32;
#endif
	} s;
	struct cvmx_bbp_dle_pbch_data_s       cnf71xx;
};
typedef union cvmx_bbp_dle_pbch_data cvmx_bbp_dle_pbch_data_t;

/**
 * cvmx_bbp_dle_pdcch_conf
 */
union cvmx_bbp_dle_pdcch_conf {
	uint32_t u32;
	struct cvmx_bbp_dle_pdcch_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rnti                         : 16; /**< RNTI Value */
	uint32_t reserved_10_15               : 6;
	uint32_t pdcch_format                 : 2;  /**< PDCCH Format
                                                         '0' - PDCCH format 0 (Num.of CCEs:1)
                                                         '1' - PDCCH format 1 (Num.of CCEs:2)
                                                         '2' - PDCCH format 2 (Num.of CCEs:4)
                                                         '3' - PDCCH format 3 (Num.of CCEs:8) */
	uint32_t ue_as                        : 1;  /**< UE transmit antenna selection
                                                         '0' - UE port 0
                                                         '1' - UE port 1 */
	uint32_t dci_format_0                 : 1;  /**< '1' - DCI Format 0
                                                         '0' - Other DCI Format */
	uint32_t pdcch_size                   : 6;  /**< PDCCH Data size */
#else
	uint32_t pdcch_size                   : 6;
	uint32_t dci_format_0                 : 1;
	uint32_t ue_as                        : 1;
	uint32_t pdcch_format                 : 2;
	uint32_t reserved_10_15               : 6;
	uint32_t rnti                         : 16;
#endif
	} s;
	struct cvmx_bbp_dle_pdcch_conf_s      cnf71xx;
};
typedef union cvmx_bbp_dle_pdcch_conf cvmx_bbp_dle_pdcch_conf_t;

/**
 * cvmx_bbp_dle_pdcch_data0
 */
union cvmx_bbp_dle_pdcch_data0 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdcch_data0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdcch_data0                  : 32; /**< PDCCH Data[31:0] */
#else
	uint32_t pdcch_data0                  : 32;
#endif
	} s;
	struct cvmx_bbp_dle_pdcch_data0_s     cnf71xx;
};
typedef union cvmx_bbp_dle_pdcch_data0 cvmx_bbp_dle_pdcch_data0_t;

/**
 * cvmx_bbp_dle_pdcch_data1
 */
union cvmx_bbp_dle_pdcch_data1 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdcch_data1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdcch_data1                  : 32; /**< PDCCH Data[63:32] */
#else
	uint32_t pdcch_data1                  : 32;
#endif
	} s;
	struct cvmx_bbp_dle_pdcch_data1_s     cnf71xx;
};
typedef union cvmx_bbp_dle_pdcch_data1 cvmx_bbp_dle_pdcch_data1_t;

/**
 * cvmx_bbp_dle_pdcch_idx
 */
union cvmx_bbp_dle_pdcch_idx {
	uint32_t u32;
	struct cvmx_bbp_dle_pdcch_idx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t pdcch_idx                    : 6;  /**< PDCCH Configuration index(0x224~0x22c) */
#else
	uint32_t pdcch_idx                    : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_dle_pdcch_idx_s       cnf71xx;
};
typedef union cvmx_bbp_dle_pdcch_idx cvmx_bbp_dle_pdcch_idx_t;

/**
 * cvmx_bbp_dle_pdsch_idx
 */
union cvmx_bbp_dle_pdsch_idx {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_idx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t pdsch_idx                    : 4;  /**< PDSCH Configuration index(0x244~0x270) */
#else
	uint32_t pdsch_idx                    : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_idx_s       cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_idx cvmx_bbp_dle_pdsch_idx_t;

/**
 * cvmx_bbp_dle_pdsch_tb0_conf0
 */
union cvmx_bbp_dle_pdsch_tb0_conf0 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb0_conf0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch0_size                  : 17; /**< PDSCH0 Data size */
#else
	uint32_t pdsch0_size                  : 17;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb0_conf0_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb0_conf0 cvmx_bbp_dle_pdsch_tb0_conf0_t;

/**
 * cvmx_bbp_dle_pdsch_tb0_conf1
 */
union cvmx_bbp_dle_pdsch_tb0_conf1 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb0_conf1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch0_cb_size               : 13; /**< PDSCH0 CB size */
	uint32_t pdsch0_cb_num                : 4;  /**< PDSCH0 CB number */
#else
	uint32_t pdsch0_cb_num                : 4;
	uint32_t pdsch0_cb_size               : 13;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb0_conf1_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb0_conf1 cvmx_bbp_dle_pdsch_tb0_conf1_t;

/**
 * cvmx_bbp_dle_pdsch_tb0_conf2
 */
union cvmx_bbp_dle_pdsch_tb0_conf2 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb0_conf2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_27_31               : 5;
	uint32_t pdsch0_tenc_f2               : 10; /**< Turbo code internal interleaver parameter, f2 */
	uint32_t pdsch0_tenc_f1               : 9;  /**< Turbo code internal interleaver parameter, f1 */
	uint32_t pdsch0_tenc_idx              : 8;  /**< Turbo code internal interleaver parameter, index */
#else
	uint32_t pdsch0_tenc_idx              : 8;
	uint32_t pdsch0_tenc_f1               : 9;
	uint32_t pdsch0_tenc_f2               : 10;
	uint32_t reserved_27_31               : 5;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb0_conf2_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb0_conf2 cvmx_bbp_dle_pdsch_tb0_conf2_t;

/**
 * cvmx_bbp_dle_pdsch_tb0_conf3
 */
union cvmx_bbp_dle_pdsch_tb0_conf3 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb0_conf3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdsch0_e_r                   : 4;  /**< r = C-gamma (gamma=G' mod C) */
	uint32_t pdsch0_e_offset              : 4;  /**< Offset (Nl*Qm) */
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch0_e                     : 17; /**< E (rate matching output sequence length) */
#else
	uint32_t pdsch0_e                     : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch0_e_offset              : 4;
	uint32_t pdsch0_e_r                   : 4;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb0_conf3_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb0_conf3 cvmx_bbp_dle_pdsch_tb0_conf3_t;

/**
 * cvmx_bbp_dle_pdsch_tb0_conf4
 */
union cvmx_bbp_dle_pdsch_tb0_conf4 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb0_conf4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ncb_wo_null                  : 16; /**< Ncb without Null */
	uint32_t k0_wo_null                   : 16; /**< k0 without Null */
#else
	uint32_t k0_wo_null                   : 16;
	uint32_t ncb_wo_null                  : 16;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb0_conf4_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb0_conf4 cvmx_bbp_dle_pdsch_tb0_conf4_t;

/**
 * cvmx_bbp_dle_pdsch_tb0_conf5
 */
union cvmx_bbp_dle_pdsch_tb0_conf5 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb0_conf5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t ue_addr_offset               : 12; /**< UE Address Offset */
#else
	uint32_t ue_addr_offset               : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb0_conf5_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb0_conf5 cvmx_bbp_dle_pdsch_tb0_conf5_t;

/**
 * cvmx_bbp_dle_pdsch_tb1_conf0
 */
union cvmx_bbp_dle_pdsch_tb1_conf0 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb1_conf0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch1_size                  : 17; /**< PDSCH1 Data size */
#else
	uint32_t pdsch1_size                  : 17;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb1_conf0_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb1_conf0 cvmx_bbp_dle_pdsch_tb1_conf0_t;

/**
 * cvmx_bbp_dle_pdsch_tb1_conf1
 */
union cvmx_bbp_dle_pdsch_tb1_conf1 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb1_conf1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch1_cb_size               : 13; /**< PDSCH1 CB size */
	uint32_t pdsch1_cb_num                : 4;  /**< PDSCH1 CB number */
#else
	uint32_t pdsch1_cb_num                : 4;
	uint32_t pdsch1_cb_size               : 13;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb1_conf1_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb1_conf1 cvmx_bbp_dle_pdsch_tb1_conf1_t;

/**
 * cvmx_bbp_dle_pdsch_tb1_conf2
 */
union cvmx_bbp_dle_pdsch_tb1_conf2 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb1_conf2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_27_31               : 5;
	uint32_t pdsch1_tenc_f2               : 10; /**< Turbo code internal interleaver parameter, f2 */
	uint32_t pdsch1_tenc_f1               : 9;  /**< Turbo code internal interleaver parameter, f1 */
	uint32_t pdsch1_tenc_idx              : 8;  /**< Turbo code internal interleaver parameter, index */
#else
	uint32_t pdsch1_tenc_idx              : 8;
	uint32_t pdsch1_tenc_f1               : 9;
	uint32_t pdsch1_tenc_f2               : 10;
	uint32_t reserved_27_31               : 5;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb1_conf2_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb1_conf2 cvmx_bbp_dle_pdsch_tb1_conf2_t;

/**
 * cvmx_bbp_dle_pdsch_tb1_conf3
 */
union cvmx_bbp_dle_pdsch_tb1_conf3 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb1_conf3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdsch1_e_r                   : 4;  /**< r = C-gamma (gamma=G' mod C) */
	uint32_t pdsch1_e_offset              : 4;  /**< Offset (Nl*Qm) */
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch1_e                     : 17; /**< E (rate matching output sequence length) */
#else
	uint32_t pdsch1_e                     : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch1_e_offset              : 4;
	uint32_t pdsch1_e_r                   : 4;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb1_conf3_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb1_conf3 cvmx_bbp_dle_pdsch_tb1_conf3_t;

/**
 * cvmx_bbp_dle_pdsch_tb1_conf4
 */
union cvmx_bbp_dle_pdsch_tb1_conf4 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb1_conf4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ncb_wo_null                  : 16; /**< Ncb without Null */
	uint32_t k0_wo_null                   : 16; /**< k0 without Null */
#else
	uint32_t k0_wo_null                   : 16;
	uint32_t ncb_wo_null                  : 16;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb1_conf4_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb1_conf4 cvmx_bbp_dle_pdsch_tb1_conf4_t;

/**
 * cvmx_bbp_dle_pdsch_tb1_conf5
 */
union cvmx_bbp_dle_pdsch_tb1_conf5 {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_tb1_conf5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t ue_addr_offset               : 12; /**< UE Address Offset */
#else
	uint32_t ue_addr_offset               : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_tb1_conf5_s cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_tb1_conf5 cvmx_bbp_dle_pdsch_tb1_conf5_t;

/**
 * cvmx_bbp_dle_pdsch_wr_cnt
 */
union cvmx_bbp_dle_pdsch_wr_cnt {
	uint32_t u32;
	struct cvmx_bbp_dle_pdsch_wr_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ns1                          : 3;  /**< reserved. */
	uint32_t no_cw1                       : 1;  /**< No codeword1
                                                         '0' - codeword exist
                                                         '1' - No codeword */
	uint32_t pdsch1_wr_cnt                : 12; /**< PDSCH1 Write count */
	uint32_t ns0                          : 3;  /**< reserved. */
	uint32_t no_cw0                       : 1;  /**< No codeword0
                                                         '0' - codeword exist
                                                         '1' - No codeword */
	uint32_t pdsch0_wr_cnt                : 12; /**< PDSCH0 Write count */
#else
	uint32_t pdsch0_wr_cnt                : 12;
	uint32_t no_cw0                       : 1;
	uint32_t ns0                          : 3;
	uint32_t pdsch1_wr_cnt                : 12;
	uint32_t no_cw1                       : 1;
	uint32_t ns1                          : 3;
#endif
	} s;
	struct cvmx_bbp_dle_pdsch_wr_cnt_s    cnf71xx;
};
typedef union cvmx_bbp_dle_pdsch_wr_cnt cvmx_bbp_dle_pdsch_wr_cnt_t;

/**
 * cvmx_bbp_dle_rd_pdcch_conf
 */
union cvmx_bbp_dle_rd_pdcch_conf {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdcch_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rnti                         : 16; /**< RNTI Value */
	uint32_t reserved_10_15               : 6;
	uint32_t pdcch_format                 : 2;  /**< PDCCH Format
                                                         '0' - PDCCH format 0 (Num.of CCEs:1)
                                                         '1' - PDCCH format 1 (Num.of CCEs:2)
                                                         '2' - PDCCH format 2 (Num.of CCEs:4)
                                                         '3' - PDCCH format 3 (Num.of CCEs:8) */
	uint32_t ue_as                        : 1;  /**< UE transmit antenna selection
                                                         '0' - UE port 0
                                                         '1' - UE port 1 */
	uint32_t dci_format_0                 : 1;  /**< '1' - DCI Format 0
                                                         '0' - Other DCI Format */
	uint32_t pdcch_size                   : 6;  /**< PDCCH Data size */
#else
	uint32_t pdcch_size                   : 6;
	uint32_t dci_format_0                 : 1;
	uint32_t ue_as                        : 1;
	uint32_t pdcch_format                 : 2;
	uint32_t reserved_10_15               : 6;
	uint32_t rnti                         : 16;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdcch_conf_s   cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdcch_conf cvmx_bbp_dle_rd_pdcch_conf_t;

/**
 * cvmx_bbp_dle_rd_pdcch_data0
 */
union cvmx_bbp_dle_rd_pdcch_data0 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdcch_data0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdcch_data0                  : 32; /**< PDCCH Data[31:0] */
#else
	uint32_t pdcch_data0                  : 32;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdcch_data0_s  cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdcch_data0 cvmx_bbp_dle_rd_pdcch_data0_t;

/**
 * cvmx_bbp_dle_rd_pdcch_data1
 */
union cvmx_bbp_dle_rd_pdcch_data1 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdcch_data1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdcch_data1                  : 32; /**< PDCCH Data[63:32] */
#else
	uint32_t pdcch_data1                  : 32;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdcch_data1_s  cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdcch_data1 cvmx_bbp_dle_rd_pdcch_data1_t;

/**
 * cvmx_bbp_dle_rd_pdcch_idx
 */
union cvmx_bbp_dle_rd_pdcch_idx {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdcch_idx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t pdcch_idx                    : 6;  /**< PDCCH Configuration index(0x224~0x22c) */
#else
	uint32_t pdcch_idx                    : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdcch_idx_s    cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdcch_idx cvmx_bbp_dle_rd_pdcch_idx_t;

/**
 * cvmx_bbp_dle_rd_pdsch_idx
 */
union cvmx_bbp_dle_rd_pdsch_idx {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_idx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t pdsch_idx                    : 4;  /**< PDSCH Configuration index(0x244~0x270) */
#else
	uint32_t pdsch_idx                    : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_idx_s    cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_idx cvmx_bbp_dle_rd_pdsch_idx_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb0_conf0
 */
union cvmx_bbp_dle_rd_pdsch_tb0_conf0 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch0_size                  : 17; /**< PDSCH0 Data size */
#else
	uint32_t pdsch0_size                  : 17;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf0_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb0_conf0 cvmx_bbp_dle_rd_pdsch_tb0_conf0_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb0_conf1
 */
union cvmx_bbp_dle_rd_pdsch_tb0_conf1 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch0_cb_size               : 13; /**< PDSCH0 CB size */
	uint32_t pdsch0_cb_num                : 4;  /**< PDSCH0 CB number */
#else
	uint32_t pdsch0_cb_num                : 4;
	uint32_t pdsch0_cb_size               : 13;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf1_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb0_conf1 cvmx_bbp_dle_rd_pdsch_tb0_conf1_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb0_conf2
 */
union cvmx_bbp_dle_rd_pdsch_tb0_conf2 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_27_31               : 5;
	uint32_t pdsch0_tenc_f2               : 10; /**< Turbo code internal interleaver parameter, f2 */
	uint32_t pdsch0_tenc_f1               : 9;  /**< Turbo code internal interleaver parameter, f1 */
	uint32_t pdsch0_tenc_idx              : 8;  /**< Turbo code internal interleaver parameter, index */
#else
	uint32_t pdsch0_tenc_idx              : 8;
	uint32_t pdsch0_tenc_f1               : 9;
	uint32_t pdsch0_tenc_f2               : 10;
	uint32_t reserved_27_31               : 5;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf2_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb0_conf2 cvmx_bbp_dle_rd_pdsch_tb0_conf2_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb0_conf3
 */
union cvmx_bbp_dle_rd_pdsch_tb0_conf3 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdsch0_e_r                   : 4;  /**< r = C-gamma (gamma=G' mod C) */
	uint32_t pdsch0_e_offset              : 4;  /**< Offset (Nl*Qm) */
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch0_e                     : 17; /**< E (rate matching output sequence length) */
#else
	uint32_t pdsch0_e                     : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch0_e_offset              : 4;
	uint32_t pdsch0_e_r                   : 4;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf3_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb0_conf3 cvmx_bbp_dle_rd_pdsch_tb0_conf3_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb0_conf4
 */
union cvmx_bbp_dle_rd_pdsch_tb0_conf4 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ncb_wo_null                  : 16; /**< Ncb without Null */
	uint32_t k0_wo_null                   : 16; /**< k0 without Null */
#else
	uint32_t k0_wo_null                   : 16;
	uint32_t ncb_wo_null                  : 16;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf4_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb0_conf4 cvmx_bbp_dle_rd_pdsch_tb0_conf4_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb0_conf5
 */
union cvmx_bbp_dle_rd_pdsch_tb0_conf5 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t ue_addr_offset               : 12; /**< UE Address Offset */
#else
	uint32_t ue_addr_offset               : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb0_conf5_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb0_conf5 cvmx_bbp_dle_rd_pdsch_tb0_conf5_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb1_conf0
 */
union cvmx_bbp_dle_rd_pdsch_tb1_conf0 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch1_size                  : 17; /**< PDSCH1 Data size */
#else
	uint32_t pdsch1_size                  : 17;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf0_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb1_conf0 cvmx_bbp_dle_rd_pdsch_tb1_conf0_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb1_conf1
 */
union cvmx_bbp_dle_rd_pdsch_tb1_conf1 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t pdsch1_cb_size               : 13; /**< PDSCH1 CB size */
	uint32_t pdsch1_cb_num                : 4;  /**< PDSCH1 CB number */
#else
	uint32_t pdsch1_cb_num                : 4;
	uint32_t pdsch1_cb_size               : 13;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf1_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb1_conf1 cvmx_bbp_dle_rd_pdsch_tb1_conf1_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb1_conf2
 */
union cvmx_bbp_dle_rd_pdsch_tb1_conf2 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_27_31               : 5;
	uint32_t pdsch1_tenc_f2               : 10; /**< Turbo code internal interleaver parameter, f2 */
	uint32_t pdsch1_tenc_f1               : 9;  /**< Turbo code internal interleaver parameter, f1 */
	uint32_t pdsch1_tenc_idx              : 8;  /**< Turbo code internal interleaver parameter, index */
#else
	uint32_t pdsch1_tenc_idx              : 8;
	uint32_t pdsch1_tenc_f1               : 9;
	uint32_t pdsch1_tenc_f2               : 10;
	uint32_t reserved_27_31               : 5;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf2_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb1_conf2 cvmx_bbp_dle_rd_pdsch_tb1_conf2_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb1_conf3
 */
union cvmx_bbp_dle_rd_pdsch_tb1_conf3 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t pdsch1_e_r                   : 4;  /**< r = C-gamma (gamma=G' mod C) */
	uint32_t pdsch1_e_offset              : 4;  /**< Offset (Nl*Qm) */
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch1_e                     : 17; /**< E (rate matching output sequence length) */
#else
	uint32_t pdsch1_e                     : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t pdsch1_e_offset              : 4;
	uint32_t pdsch1_e_r                   : 4;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf3_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb1_conf3 cvmx_bbp_dle_rd_pdsch_tb1_conf3_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb1_conf4
 */
union cvmx_bbp_dle_rd_pdsch_tb1_conf4 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ncb_wo_null                  : 16; /**< Ncb without Null */
	uint32_t k0_wo_null                   : 16; /**< k0 without Null */
#else
	uint32_t k0_wo_null                   : 16;
	uint32_t ncb_wo_null                  : 16;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf4_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb1_conf4 cvmx_bbp_dle_rd_pdsch_tb1_conf4_t;

/**
 * cvmx_bbp_dle_rd_pdsch_tb1_conf5
 */
union cvmx_bbp_dle_rd_pdsch_tb1_conf5 {
	uint32_t u32;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t ue_addr_offset               : 12; /**< UE Address Offset */
#else
	uint32_t ue_addr_offset               : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_dle_rd_pdsch_tb1_conf5_s cnf71xx;
};
typedef union cvmx_bbp_dle_rd_pdsch_tb1_conf5 cvmx_bbp_dle_rd_pdsch_tb1_conf5_t;

/**
 * cvmx_bbp_dle_status
 *
 * &BBP_DID_ID = 0x6F007F844000
 * DLE_CRS_VERSION = v1.0   // hab_source_version
 */
union cvmx_bbp_dle_status {
	uint32_t u32;
	struct cvmx_bbp_dle_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t pdsch_busy                   : 1;  /**< Indicates if the Hardware accelerator(PDSCH encoder) is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t pdcch_busy                   : 1;  /**< Indicates if the Hardware accelerator(PDCCH encoder) is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t pbch_busy                    : 1;  /**< Indicates if the Hardware accelerator(PBCH encoder) is busy
                                                         '0' = ready
                                                         '1' = busy */
#else
	uint32_t pbch_busy                    : 1;
	uint32_t pdcch_busy                   : 1;
	uint32_t pdsch_busy                   : 1;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_dle_status_s          cnf71xx;
};
typedef union cvmx_bbp_dle_status cvmx_bbp_dle_status_t;

/**
 * cvmx_bbp_enc3g_autogate
 */
union cvmx_bbp_enc3g_autogate {
	uint32_t u32;
	struct cvmx_bbp_enc3g_autogate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t autogate                     : 1;  /**< 1==enable auto-clock-gating */
#else
	uint32_t autogate                     : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_enc3g_autogate_s      cnf71xx;
};
typedef union cvmx_bbp_enc3g_autogate cvmx_bbp_enc3g_autogate_t;

/**
 * cvmx_bbp_enc3g_cfg1
 */
union cvmx_bbp_enc3g_cfg1 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_cfg1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t bypass_bc                    : 1;  /**< 0=bit-collection enabled, 1=BC is bypassed */
	uint32_t bypass_rm                    : 1;  /**< 0=rate-matching enabled, 1=RM is bypassed */
	uint32_t punct_rep                    : 3;  /**< puncturing/repetition mode
                                                         0= Puncturing of parity bits P1 and P2 is enabled
                                                         1= Puncturing of systematic bits S and parity bits
                                                                 P1 and P2 is enabled
                                                         2= Repetition is enabled on a single bit sequence
                                                         3= Repetition is enabled on the 3 sequences S, P1
                                                                 and P3
                                                         4= 1st RM puncturing (P1 and P2) and 2nd RM
                                                                 puncturing (S, P1 and P2)
                                                         5= 1st RM puncturing (P1 and P2) and 2nd RM
                                                                 repetition (S, P1 and P2)
                                                         6= Puncturing is enabled on a single bit-sequence */
	uint32_t c                            : 8;  /**< number of code blocks */
	uint32_t rm_e_mode                    : 1;  /**< 0=enables E param loopback, 1=not recommended */
	uint32_t rate                         : 1;  /**< 1=1/2, 0=1/3 */
	uint32_t fec_mode                     : 1;  /**< 1=CC, 0=turbo */
	uint32_t k                            : 13; /**< code block size */
#else
	uint32_t k                            : 13;
	uint32_t fec_mode                     : 1;
	uint32_t rate                         : 1;
	uint32_t rm_e_mode                    : 1;
	uint32_t c                            : 8;
	uint32_t punct_rep                    : 3;
	uint32_t bypass_rm                    : 1;
	uint32_t bypass_bc                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_enc3g_cfg1_s          cnf71xx;
};
typedef union cvmx_bbp_enc3g_cfg1 cvmx_bbp_enc3g_cfg1_t;

/**
 * cvmx_bbp_enc3g_cfg2
 */
union cvmx_bbp_enc3g_cfg2 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_cfg2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t endian                       : 1;  /**< 0=big, 1=little */
	uint32_t output_mode                  : 3;  /**< 0=reserved
                                                         1=triplet interleaved
                                                         2=doublet interleaved
                                                         3=uninterleaved 3-bit
                                                         4=uninterleaved 2-bit */
	uint32_t nfiller                      : 13; /**< number of filler bits */
#else
	uint32_t nfiller                      : 13;
	uint32_t output_mode                  : 3;
	uint32_t endian                       : 1;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_enc3g_cfg2_s          cnf71xx;
};
typedef union cvmx_bbp_enc3g_cfg2 cvmx_bbp_enc3g_cfg2_t;

/**
 * cvmx_bbp_enc3g_eini1
 */
union cvmx_bbp_enc3g_eini1 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eini1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_ini1                       : 18; /**< initial value for E parameter \#1 */
#else
	uint32_t e_ini1                       : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eini1_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_eini1 cvmx_bbp_enc3g_eini1_t;

/**
 * cvmx_bbp_enc3g_eini2
 */
union cvmx_bbp_enc3g_eini2 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eini2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_ini2                       : 18; /**< initial value for E parameter \#2 */
#else
	uint32_t e_ini2                       : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eini2_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_eini2 cvmx_bbp_enc3g_eini2_t;

/**
 * cvmx_bbp_enc3g_eini3
 */
union cvmx_bbp_enc3g_eini3 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eini3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_ini3                       : 18; /**< initial value for E parameter \#3 */
#else
	uint32_t e_ini3                       : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eini3_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_eini3 cvmx_bbp_enc3g_eini3_t;

/**
 * cvmx_bbp_enc3g_eini4
 */
union cvmx_bbp_enc3g_eini4 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eini4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_ini4                       : 18; /**< initial value for E parameter \#4 */
#else
	uint32_t e_ini4                       : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eini4_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_eini4 cvmx_bbp_enc3g_eini4_t;

/**
 * cvmx_bbp_enc3g_eini5
 */
union cvmx_bbp_enc3g_eini5 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eini5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_ini5                       : 18; /**< initial value for E parameter \#5 */
#else
	uint32_t e_ini5                       : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eini5_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_eini5 cvmx_bbp_enc3g_eini5_t;

/**
 * cvmx_bbp_enc3g_eini6
 */
union cvmx_bbp_enc3g_eini6 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eini6_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_ini6                       : 18; /**< initial value for E parameter \#6 */
#else
	uint32_t e_ini6                       : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eini6_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_eini6 cvmx_bbp_enc3g_eini6_t;

/**
 * cvmx_bbp_enc3g_eminus1
 */
union cvmx_bbp_enc3g_eminus1 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eminus1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_minus1                     : 18; /**< decrement value for E parameter \#1 */
#else
	uint32_t e_minus1                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eminus1_s       cnf71xx;
};
typedef union cvmx_bbp_enc3g_eminus1 cvmx_bbp_enc3g_eminus1_t;

/**
 * cvmx_bbp_enc3g_eminus2
 */
union cvmx_bbp_enc3g_eminus2 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eminus2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_minus2                     : 18; /**< decrement value for E parameter \#2 */
#else
	uint32_t e_minus2                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eminus2_s       cnf71xx;
};
typedef union cvmx_bbp_enc3g_eminus2 cvmx_bbp_enc3g_eminus2_t;

/**
 * cvmx_bbp_enc3g_eminus3
 */
union cvmx_bbp_enc3g_eminus3 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eminus3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_minus3                     : 18; /**< decrement value for E parameter \#3 */
#else
	uint32_t e_minus3                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eminus3_s       cnf71xx;
};
typedef union cvmx_bbp_enc3g_eminus3 cvmx_bbp_enc3g_eminus3_t;

/**
 * cvmx_bbp_enc3g_eminus4
 */
union cvmx_bbp_enc3g_eminus4 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eminus4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_minus4                     : 18; /**< decrement value for E parameter \#4 */
#else
	uint32_t e_minus4                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eminus4_s       cnf71xx;
};
typedef union cvmx_bbp_enc3g_eminus4 cvmx_bbp_enc3g_eminus4_t;

/**
 * cvmx_bbp_enc3g_eminus5
 */
union cvmx_bbp_enc3g_eminus5 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eminus5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_minus5                     : 18; /**< decrement value for E parameter \#5 */
#else
	uint32_t e_minus5                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eminus5_s       cnf71xx;
};
typedef union cvmx_bbp_enc3g_eminus5 cvmx_bbp_enc3g_eminus5_t;

/**
 * cvmx_bbp_enc3g_eminus6
 */
union cvmx_bbp_enc3g_eminus6 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eminus6_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_minus6                     : 18; /**< decrement value for E parameter \#6 */
#else
	uint32_t e_minus6                     : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eminus6_s       cnf71xx;
};
typedef union cvmx_bbp_enc3g_eminus6 cvmx_bbp_enc3g_eminus6_t;

/**
 * cvmx_bbp_enc3g_eplus1
 */
union cvmx_bbp_enc3g_eplus1 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eplus1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_plus1                      : 18; /**< increment value for E parameter \#1 */
#else
	uint32_t e_plus1                      : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eplus1_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_eplus1 cvmx_bbp_enc3g_eplus1_t;

/**
 * cvmx_bbp_enc3g_eplus2
 */
union cvmx_bbp_enc3g_eplus2 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eplus2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_plus2                      : 18; /**< increment value for E parameter \#2 */
#else
	uint32_t e_plus2                      : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eplus2_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_eplus2 cvmx_bbp_enc3g_eplus2_t;

/**
 * cvmx_bbp_enc3g_eplus3
 */
union cvmx_bbp_enc3g_eplus3 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eplus3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_plus3                      : 18; /**< increment value for E parameter \#3 */
#else
	uint32_t e_plus3                      : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eplus3_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_eplus3 cvmx_bbp_enc3g_eplus3_t;

/**
 * cvmx_bbp_enc3g_eplus4
 */
union cvmx_bbp_enc3g_eplus4 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eplus4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_plus4                      : 18; /**< increment value for E parameter \#4 */
#else
	uint32_t e_plus4                      : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eplus4_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_eplus4 cvmx_bbp_enc3g_eplus4_t;

/**
 * cvmx_bbp_enc3g_eplus5
 */
union cvmx_bbp_enc3g_eplus5 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eplus5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_plus5                      : 18; /**< increment value for E parameter \#5 */
#else
	uint32_t e_plus5                      : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eplus5_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_eplus5 cvmx_bbp_enc3g_eplus5_t;

/**
 * cvmx_bbp_enc3g_eplus6
 */
union cvmx_bbp_enc3g_eplus6 {
	uint32_t u32;
	struct cvmx_bbp_enc3g_eplus6_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t e_plus6                      : 18; /**< increment value for E parameter \#6 */
#else
	uint32_t e_plus6                      : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_enc3g_eplus6_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_eplus6 cvmx_bbp_enc3g_eplus6_t;

/**
 * cvmx_bbp_enc3g_int
 */
union cvmx_bbp_enc3g_int {
	uint32_t u32;
	struct cvmx_bbp_enc3g_int_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t done_int                     : 1;  /**< ENC3G operation done */
#else
	uint32_t done_int                     : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_enc3g_int_s           cnf71xx;
};
typedef union cvmx_bbp_enc3g_int cvmx_bbp_enc3g_int_t;

/**
 * cvmx_bbp_enc3g_int_en
 */
union cvmx_bbp_enc3g_int_en {
	uint32_t u32;
	struct cvmx_bbp_enc3g_int_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t int_en                       : 1;  /**< enable for ENC3G interrupt */
#else
	uint32_t int_en                       : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_enc3g_int_en_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_int_en cvmx_bbp_enc3g_int_en_t;

/**
 * cvmx_bbp_enc3g_start
 */
union cvmx_bbp_enc3g_start {
	uint32_t u32;
	struct cvmx_bbp_enc3g_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enc_start                    : 1;  /**< start bit for 3G Encoder HAB */
#else
	uint32_t enc_start                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_enc3g_start_s         cnf71xx;
};
typedef union cvmx_bbp_enc3g_start cvmx_bbp_enc3g_start_t;

/**
 * cvmx_bbp_enc3g_status
 */
union cvmx_bbp_enc3g_status {
	uint32_t u32;
	struct cvmx_bbp_enc3g_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t busy                         : 1;  /**< 1== ENC3G is not IDLE */
#else
	uint32_t busy                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_enc3g_status_s        cnf71xx;
};
typedef union cvmx_bbp_enc3g_status cvmx_bbp_enc3g_status_t;

/**
 * cvmx_bbp_ipm_auto_clk_gate
 */
union cvmx_bbp_ipm_auto_clk_gate {
	uint32_t u32;
	struct cvmx_bbp_ipm_auto_clk_gate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t auto_gate                    : 1;  /**< 1==enable auto-clock-gating */
#else
	uint32_t auto_gate                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ipm_auto_clk_gate_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_auto_clk_gate cvmx_bbp_ipm_auto_clk_gate_t;

/**
 * cvmx_bbp_ipm_ch_gain
 */
union cvmx_bbp_ipm_ch_gain {
	uint32_t u32;
	struct cvmx_bbp_ipm_ch_gain_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t ch1_gain_sht                 : 4;  /**< IPM channel1 gain shift off value (default1) */
	uint32_t ch0_gain_sht                 : 4;  /**< IPM channel0 gain shift off value (default1) */
#else
	uint32_t ch0_gain_sht                 : 4;
	uint32_t ch1_gain_sht                 : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_ipm_ch_gain_s         cnf71xx;
};
typedef union cvmx_bbp_ipm_ch_gain cvmx_bbp_ipm_ch_gain_t;

/**
 * cvmx_bbp_ipm_core_status
 */
union cvmx_bbp_ipm_core_status {
	uint32_t u32;
	struct cvmx_bbp_ipm_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t ipm_dl1_busy                 : 1;  /**< 1==ipm dl1 busy */
	uint32_t ipm_dl0_busy                 : 1;  /**< 1==ipm dl0 busy */
#else
	uint32_t ipm_dl0_busy                 : 1;
	uint32_t ipm_dl1_busy                 : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_ipm_core_status_s     cnf71xx;
};
typedef union cvmx_bbp_ipm_core_status cvmx_bbp_ipm_core_status_t;

/**
 * cvmx_bbp_ipm_frm_tic_set
 */
union cvmx_bbp_ipm_frm_tic_set {
	uint32_t u32;
	struct cvmx_bbp_ipm_frm_tic_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t frm_tic_mode                 : 1;  /**< IPM frame_tic mode (1=hab start mode) */
#else
	uint32_t frm_tic_mode                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ipm_frm_tic_set_s     cnf71xx;
};
typedef union cvmx_bbp_ipm_frm_tic_set cvmx_bbp_ipm_frm_tic_set_t;

/**
 * cvmx_bbp_ipm_intr_msk
 */
union cvmx_bbp_ipm_intr_msk {
	uint32_t u32;
	struct cvmx_bbp_ipm_intr_msk_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t ipm_intr_msk                 : 18; /**< ipm interrupt mask */
#else
	uint32_t ipm_intr_msk                 : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_ipm_intr_msk_s        cnf71xx;
};
typedef union cvmx_bbp_ipm_intr_msk cvmx_bbp_ipm_intr_msk_t;

/**
 * cvmx_bbp_ipm_intr_src
 */
union cvmx_bbp_ipm_intr_src {
	uint32_t u32;
	struct cvmx_bbp_ipm_intr_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t ipm_busy                     : 1;  /**< ipm busy */
	uint32_t papr_evm_err                 : 1;  /**< PAPR evm gain write error */
	uint32_t win_coef_err                 : 1;  /**< window coef write error */
	uint32_t wr1_done_err0                : 1;  /**< wr1 wr_done early error */
	uint32_t wr0_done_err0                : 1;  /**< wr0 wr_done early error */
	uint32_t wr1_fifo_full                : 1;  /**< wr1 fifo full */
	uint32_t wr0_fifo_full                : 1;  /**< wr0 fifo full */
	uint32_t no_rd_last2                  : 1;  /**< rd2 no rd_last error */
	uint32_t no_rd_last1                  : 1;  /**< rd1 no rd_last error */
	uint32_t no_rd_last0                  : 1;  /**< rd0 no rd_last error */
	uint32_t rd_last2_err1                : 1;  /**< rd2 rd_last late error */
	uint32_t rd_last1_err1                : 1;  /**< rd1 rd_last late error */
	uint32_t rd_last0_err1                : 1;  /**< rd0 rd_last late error */
	uint32_t rd_last2_err0                : 1;  /**< rd2 rd_last early error */
	uint32_t rd_last1_err0                : 1;  /**< rd1 rd_last early error */
	uint32_t rd_last0_err0                : 1;  /**< rd0 rd_last early error */
	uint32_t frm_tic_err                  : 1;  /**< frame tick error */
	uint32_t ipm_done                     : 1;  /**< ipm done */
#else
	uint32_t ipm_done                     : 1;
	uint32_t frm_tic_err                  : 1;
	uint32_t rd_last0_err0                : 1;
	uint32_t rd_last1_err0                : 1;
	uint32_t rd_last2_err0                : 1;
	uint32_t rd_last0_err1                : 1;
	uint32_t rd_last1_err1                : 1;
	uint32_t rd_last2_err1                : 1;
	uint32_t no_rd_last0                  : 1;
	uint32_t no_rd_last1                  : 1;
	uint32_t no_rd_last2                  : 1;
	uint32_t wr0_fifo_full                : 1;
	uint32_t wr1_fifo_full                : 1;
	uint32_t wr0_done_err0                : 1;
	uint32_t wr1_done_err0                : 1;
	uint32_t win_coef_err                 : 1;
	uint32_t papr_evm_err                 : 1;
	uint32_t ipm_busy                     : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_ipm_intr_src_s        cnf71xx;
};
typedef union cvmx_bbp_ipm_intr_src cvmx_bbp_ipm_intr_src_t;

/**
 * cvmx_bbp_ipm_module_ctrl
 */
union cvmx_bbp_ipm_module_ctrl {
	uint32_t u32;
	struct cvmx_bbp_ipm_module_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ipm_start                    : 1;  /**< 1==start */
#else
	uint32_t ipm_start                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ipm_module_ctrl_s     cnf71xx;
};
typedef union cvmx_bbp_ipm_module_ctrl cvmx_bbp_ipm_module_ctrl_t;

/**
 * cvmx_bbp_ipm_module_status
 *
 * IPM_CSR_VERSION = v1.0  // hab_source_version
 *
 */
union cvmx_bbp_ipm_module_status {
	uint32_t u32;
	struct cvmx_bbp_ipm_module_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ipm_busy                     : 1;  /**< ipm status (1==busy) */
#else
	uint32_t ipm_busy                     : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ipm_module_status_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_module_status cvmx_bbp_ipm_module_status_t;

/**
 * cvmx_bbp_ipm_papr_clip_val
 */
union cvmx_bbp_ipm_papr_clip_val {
	uint32_t u32;
	struct cvmx_bbp_ipm_papr_clip_val_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t papr_clip1_val               : 16; /**< IPM PAPR 2nd Clipping Value */
	uint32_t papr_clip0_val               : 16; /**< IPM PAPR 1st Clipping Value */
#else
	uint32_t papr_clip0_val               : 16;
	uint32_t papr_clip1_val               : 16;
#endif
	} s;
	struct cvmx_bbp_ipm_papr_clip_val_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_papr_clip_val cvmx_bbp_ipm_papr_clip_val_t;

/**
 * cvmx_bbp_ipm_papr_eg_addr
 */
union cvmx_bbp_ipm_papr_eg_addr {
	uint32_t u32;
	struct cvmx_bbp_ipm_papr_eg_addr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t papr_eg_addr                 : 8;  /**< IPM PAPR EVM Gain Read/Write Address */
#else
	uint32_t papr_eg_addr                 : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_ipm_papr_eg_addr_s    cnf71xx;
};
typedef union cvmx_bbp_ipm_papr_eg_addr cvmx_bbp_ipm_papr_eg_addr_t;

/**
 * cvmx_bbp_ipm_papr_eg_data
 */
union cvmx_bbp_ipm_papr_eg_data {
	uint32_t u32;
	struct cvmx_bbp_ipm_papr_eg_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t papr_eg_data                 : 16; /**< IPM PAPR EVM Gain Read/Write Data */
#else
	uint32_t papr_eg_data                 : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_ipm_papr_eg_data_s    cnf71xx;
};
typedef union cvmx_bbp_ipm_papr_eg_data cvmx_bbp_ipm_papr_eg_data_t;

/**
 * cvmx_bbp_ipm_papr_eg_rdata
 */
union cvmx_bbp_ipm_papr_eg_rdata {
	uint32_t u32;
	struct cvmx_bbp_ipm_papr_eg_rdata_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t papr_eg_read_data            : 16; /**< IPM PAPR EVM Gain Data Read */
#else
	uint32_t papr_eg_read_data            : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_ipm_papr_eg_rdata_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_papr_eg_rdata cvmx_bbp_ipm_papr_eg_rdata_t;

/**
 * cvmx_bbp_ipm_papr_evm_ctrl
 */
union cvmx_bbp_ipm_papr_evm_ctrl {
	uint32_t u32;
	struct cvmx_bbp_ipm_papr_evm_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t papr1_64qam_er               : 3;  /**< IPM PAPR 2nd iteration 64QAM EVM Rate */
	uint32_t reserved_19_19               : 1;
	uint32_t papr1_16qam_er               : 3;  /**< IPM PAPR 2nd iteration 16QAM EVM Rate */
	uint32_t reserved_15_15               : 1;
	uint32_t papr1_qpsk_er                : 3;  /**< IPM PAPR 2nd iteration QPSK EVM Rate */
	uint32_t reserved_11_11               : 1;
	uint32_t papr0_64qam_er               : 3;  /**< IPM PAPR 1st iteration 64QAM EVM Rate */
	uint32_t reserved_7_7                 : 1;
	uint32_t papr0_16qam_er               : 3;  /**< IPM PAPR 1st iteration 16QAM EVM Rate */
	uint32_t reserved_3_3                 : 1;
	uint32_t papr0_qpsk_er                : 3;  /**< IPM PAPR 1st iteration QPSK EVM Rate */
#else
	uint32_t papr0_qpsk_er                : 3;
	uint32_t reserved_3_3                 : 1;
	uint32_t papr0_16qam_er               : 3;
	uint32_t reserved_7_7                 : 1;
	uint32_t papr0_64qam_er               : 3;
	uint32_t reserved_11_11               : 1;
	uint32_t papr1_qpsk_er                : 3;
	uint32_t reserved_15_15               : 1;
	uint32_t papr1_16qam_er               : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t papr1_64qam_er               : 3;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_ipm_papr_evm_ctrl_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_papr_evm_ctrl cvmx_bbp_ipm_papr_evm_ctrl_t;

/**
 * cvmx_bbp_ipm_rd_last_wait
 */
union cvmx_bbp_ipm_rd_last_wait {
	uint32_t u32;
	struct cvmx_bbp_ipm_rd_last_wait_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t rd_last_wait                 : 18; /**< IPM RD_LAST Waiting Value */
#else
	uint32_t rd_last_wait                 : 18;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_ipm_rd_last_wait_s    cnf71xx;
};
typedef union cvmx_bbp_ipm_rd_last_wait cvmx_bbp_ipm_rd_last_wait_t;

/**
 * cvmx_bbp_ipm_rf_gain_ctrl
 */
union cvmx_bbp_ipm_rf_gain_ctrl {
	uint32_t u32;
	struct cvmx_bbp_ipm_rf_gain_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t rf1_gain_sat                 : 3;  /**< IPM rf1 gain saturation value(10~16) (default 14)
                                                         Same bit assignment of RF0 */
	uint32_t reserved_19_19               : 1;
	uint32_t rf0_gain_sat                 : 3;  /**< IPM rf0 gain saturation value(10~16) (default 14)
                                                         '000' = 10bit
                                                         '010' = 11bit
                                                         '010' = 12bit
                                                         '011' = 13bit
                                                         '100' = 14bit (default)
                                                         '101' = 15bit
                                                         '110' = 16bit
                                                         '111' = Reserved */
	uint32_t reserved_7_15                : 9;
	uint32_t rf1_gain_sft                 : 3;  /**< IPM rf1 gain shift value(10~16) (default 13)
                                                         Same bit assignment of RF0 */
	uint32_t reserved_3_3                 : 1;
	uint32_t rf0_gain_sft                 : 3;  /**< IPM rf0 gain shift value(10~16) (default 13)
                                                         '000' = 10bit
                                                         '010' = 11bit
                                                         '010' = 12bit
                                                         '011' = 13bit (default)
                                                         '100' = 14bit
                                                         '101' = 15bit
                                                         '110' = 16bit
                                                         '111' = Reserved */
#else
	uint32_t rf0_gain_sft                 : 3;
	uint32_t reserved_3_3                 : 1;
	uint32_t rf1_gain_sft                 : 3;
	uint32_t reserved_7_15                : 9;
	uint32_t rf0_gain_sat                 : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t rf1_gain_sat                 : 3;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_ipm_rf_gain_ctrl_s    cnf71xx;
};
typedef union cvmx_bbp_ipm_rf_gain_ctrl cvmx_bbp_ipm_rf_gain_ctrl_t;

/**
 * cvmx_bbp_ipm_rf_gain_set
 */
union cvmx_bbp_ipm_rf_gain_set {
	uint32_t u32;
	struct cvmx_bbp_ipm_rf_gain_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_ant1_gain                 : 16; /**< IPM tx rf antenna1 gain */
	uint32_t rf_ant0_gain                 : 16; /**< IPM tx rf antenna0 gain */
#else
	uint32_t rf_ant0_gain                 : 16;
	uint32_t rf_ant1_gain                 : 16;
#endif
	} s;
	struct cvmx_bbp_ipm_rf_gain_set_s     cnf71xx;
};
typedef union cvmx_bbp_ipm_rf_gain_set cvmx_bbp_ipm_rf_gain_set_t;

/**
 * cvmx_bbp_ipm_status
 */
union cvmx_bbp_ipm_status {
	uint32_t u32;
	struct cvmx_bbp_ipm_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t no_ipm_start                 : 1;  /**< no ipm start */
	uint32_t no_frm_tic                   : 1;  /**< no frame tic */
	uint32_t no_clk_sts                   : 1;  /**< no clock (active high) */
#else
	uint32_t no_clk_sts                   : 1;
	uint32_t no_frm_tic                   : 1;
	uint32_t no_ipm_start                 : 1;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_ipm_status_s          cnf71xx;
};
typedef union cvmx_bbp_ipm_status cvmx_bbp_ipm_status_t;

/**
 * cvmx_bbp_ipm_symb_tic_set0
 */
union cvmx_bbp_ipm_symb_tic_set0 {
	uint32_t u32;
	struct cvmx_bbp_ipm_symb_tic_set0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ncp_clk_en                   : 1;  /**< HAB clock set enable */
	uint32_t ncp_s_clk_num                : 15; /**< IPM Symbol1-6 Clock number of N-CP */
	uint32_t reserved_15_15               : 1;
	uint32_t ncp_s0_clk_num               : 15; /**< IPM Symbol0 Clock number of N-CP */
#else
	uint32_t ncp_s0_clk_num               : 15;
	uint32_t reserved_15_15               : 1;
	uint32_t ncp_s_clk_num                : 15;
	uint32_t ncp_clk_en                   : 1;
#endif
	} s;
	struct cvmx_bbp_ipm_symb_tic_set0_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_symb_tic_set0 cvmx_bbp_ipm_symb_tic_set0_t;

/**
 * cvmx_bbp_ipm_symb_tic_set1
 */
union cvmx_bbp_ipm_symb_tic_set1 {
	uint32_t u32;
	struct cvmx_bbp_ipm_symb_tic_set1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ecp_clk_en                   : 1;  /**< HAB clock set enable */
	uint32_t ecp_s_clk_num                : 15; /**< IPM Symbol1-6 Clock number of E-CP */
	uint32_t reserved_15_15               : 1;
	uint32_t ecp_s0_clk_num               : 15; /**< IPM Symbol0 Clock number of E-CP */
#else
	uint32_t ecp_s0_clk_num               : 15;
	uint32_t reserved_15_15               : 1;
	uint32_t ecp_s_clk_num                : 15;
	uint32_t ecp_clk_en                   : 1;
#endif
	} s;
	struct cvmx_bbp_ipm_symb_tic_set1_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_symb_tic_set1 cvmx_bbp_ipm_symb_tic_set1_t;

/**
 * cvmx_bbp_ipm_sys_cfg0
 */
union cvmx_bbp_ipm_sys_cfg0 {
	uint32_t u32;
	struct cvmx_bbp_ipm_sys_cfg0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t tdd_tti_type                 : 2;  /**< TDD_TTI_TYPE 0=DL frame/1=DL SS frame/2=UL frame/3=NA */
	uint32_t reserved_5_7                 : 3;
	uint32_t mbsfn_en                     : 1;  /**< MBSFN Enable (Mixed Mode Only) 1=Enable/0-default */
	uint32_t reserved_2_3                 : 2;
	uint32_t cfi_num                      : 2;  /**< cfi number (0=CFI1/1=CFI2/2=CFI3/3=NA) */
#else
	uint32_t cfi_num                      : 2;
	uint32_t reserved_2_3                 : 2;
	uint32_t mbsfn_en                     : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t tdd_tti_type                 : 2;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_ipm_sys_cfg0_s        cnf71xx;
};
typedef union cvmx_bbp_ipm_sys_cfg0 cvmx_bbp_ipm_sys_cfg0_t;

/**
 * cvmx_bbp_ipm_sys_cfg1
 */
union cvmx_bbp_ipm_sys_cfg1 {
	uint32_t u32;
	struct cvmx_bbp_ipm_sys_cfg1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t papr_en                      : 1;  /**< PAPR enable(0=diable/1=enable) */
	uint32_t reserved_25_27               : 3;
	uint32_t win_sz                       : 1;  /**< windowing size(0=win16/1=win32) */
	uint32_t reserved_21_23               : 3;
	uint32_t win_en                       : 1;  /**< windowing enable(0=diable/1=enable) */
	uint32_t reserved_18_19               : 2;
	uint32_t pb_val                       : 2;  /**< PB value(0,1,2,3) */
	uint32_t tdd_ss_cfg                   : 3;  /**< TDD SS config(0=conf0,5/1=conf1,6/2=conf2,7/3=conf3,8/4=conf4) */
	uint32_t fs_type                      : 1;  /**< frame structure type(0=FDD/1=TDD) */
	uint32_t reserved_9_11                : 3;
	uint32_t cp_type                      : 1;  /**< 0=normal CP/1=extened CP */
	uint32_t reserved_6_7                 : 2;
	uint32_t num_ant                      : 2;  /**< Number of TX antenna(0=1ant/1=2ant/2,3=NA) */
	uint32_t reserved_2_3                 : 2;
	uint32_t sys_bw                       : 2;  /**< system bandwidth(0=20MHz/1=10MHz/2=5MHz/3=NA) */
#else
	uint32_t sys_bw                       : 2;
	uint32_t reserved_2_3                 : 2;
	uint32_t num_ant                      : 2;
	uint32_t reserved_6_7                 : 2;
	uint32_t cp_type                      : 1;
	uint32_t reserved_9_11                : 3;
	uint32_t fs_type                      : 1;
	uint32_t tdd_ss_cfg                   : 3;
	uint32_t pb_val                       : 2;
	uint32_t reserved_18_19               : 2;
	uint32_t win_en                       : 1;
	uint32_t reserved_21_23               : 3;
	uint32_t win_sz                       : 1;
	uint32_t reserved_25_27               : 3;
	uint32_t papr_en                      : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_ipm_sys_cfg1_s        cnf71xx;
};
typedef union cvmx_bbp_ipm_sys_cfg1 cvmx_bbp_ipm_sys_cfg1_t;

/**
 * cvmx_bbp_ipm_tx_out_ctrl
 */
union cvmx_bbp_ipm_tx_out_ctrl {
	uint32_t u32;
	struct cvmx_bbp_ipm_tx_out_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t dsp_iq_swap_en               : 1;  /**< IQ swap enable from DSP (default0) */
	uint32_t reserved_5_11                : 7;
	uint32_t ipm_bypass_en                : 1;  /**< IPM processing bypass enable (default0) */
	uint32_t reserved_2_3                 : 2;
	uint32_t tx_out1_en                   : 1;  /**< TX DATA to Antenna1 Enable (default:0) */
	uint32_t tx_out0_en                   : 1;  /**< TX DATA to Antenna0 Enable (default:0) */
#else
	uint32_t tx_out0_en                   : 1;
	uint32_t tx_out1_en                   : 1;
	uint32_t reserved_2_3                 : 2;
	uint32_t ipm_bypass_en                : 1;
	uint32_t reserved_5_11                : 7;
	uint32_t dsp_iq_swap_en               : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_ipm_tx_out_ctrl_s     cnf71xx;
};
typedef union cvmx_bbp_ipm_tx_out_ctrl cvmx_bbp_ipm_tx_out_ctrl_t;

/**
 * cvmx_bbp_ipm_version
 */
union cvmx_bbp_ipm_version {
	uint32_t u32;
	struct cvmx_bbp_ipm_version_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ipm_ver                      : 32; /**< IPM Version */
#else
	uint32_t ipm_ver                      : 32;
#endif
	} s;
	struct cvmx_bbp_ipm_version_s         cnf71xx;
};
typedef union cvmx_bbp_ipm_version cvmx_bbp_ipm_version_t;

/**
 * cvmx_bbp_ipm_win_coef_addr
 */
union cvmx_bbp_ipm_win_coef_addr {
	uint32_t u32;
	struct cvmx_bbp_ipm_win_coef_addr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t win_coef_addr                : 6;  /**< IPM windowing coefficent Read/Write address */
#else
	uint32_t win_coef_addr                : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_ipm_win_coef_addr_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_win_coef_addr cvmx_bbp_ipm_win_coef_addr_t;

/**
 * cvmx_bbp_ipm_win_coef_data
 */
union cvmx_bbp_ipm_win_coef_data {
	uint32_t u32;
	struct cvmx_bbp_ipm_win_coef_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t win_coef_data                : 16; /**< IPM windowing coefficent write data */
#else
	uint32_t win_coef_data                : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_ipm_win_coef_data_s   cnf71xx;
};
typedef union cvmx_bbp_ipm_win_coef_data cvmx_bbp_ipm_win_coef_data_t;

/**
 * cvmx_bbp_ipm_win_coef_rdata
 */
union cvmx_bbp_ipm_win_coef_rdata {
	uint32_t u32;
	struct cvmx_bbp_ipm_win_coef_rdata_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t win_coef_read_data           : 16; /**< IPM Windowing Coefficent Data Read */
#else
	uint32_t win_coef_read_data           : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_ipm_win_coef_rdata_s  cnf71xx;
};
typedef union cvmx_bbp_ipm_win_coef_rdata cvmx_bbp_ipm_win_coef_rdata_t;

/**
 * cvmx_bbp_rafe_clk_ctrl
 */
union cvmx_bbp_rafe_clk_ctrl {
	uint32_t u32;
	struct cvmx_bbp_rafe_clk_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t clock_gating                 : 1;  /**< '0' = auto-clock-gating off (default)
                                                         '1' = auto-clock-gating on */
#else
	uint32_t clock_gating                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rafe_clk_ctrl_s       cnf71xx;
};
typedef union cvmx_bbp_rafe_clk_ctrl cvmx_bbp_rafe_clk_ctrl_t;

/**
 * cvmx_bbp_rafe_control
 */
union cvmx_bbp_rafe_control {
	uint32_t u32;
	struct cvmx_bbp_rafe_control_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t hab_start                    : 1;  /**< '1'= start the HAB per config in HC_CONFIGURATION
                                                         (auto-clear) */
#else
	uint32_t hab_start                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rafe_control_s        cnf71xx;
};
typedef union cvmx_bbp_rafe_control cvmx_bbp_rafe_control_t;

/**
 * cvmx_bbp_rafe_fir1_coef
 */
union cvmx_bbp_rafe_fir1_coef {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir1_coef_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir1_coef2                   : 12; /**< FIR1 Coefficient [2] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir1_coef0                   : 12; /**< FIR1 Coefficient [0] */
#else
	uint32_t fir1_coef0                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir1_coef2                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir1_coef_s      cnf71xx;
};
typedef union cvmx_bbp_rafe_fir1_coef cvmx_bbp_rafe_fir1_coef_t;

/**
 * cvmx_bbp_rafe_fir2_coef_02
 */
union cvmx_bbp_rafe_fir2_coef_02 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir2_coef_02_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir2_coef2                   : 12; /**< FIR2 Coefficient [2] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir2_coef0                   : 12; /**< FIR2 Coefficient [0] */
#else
	uint32_t fir2_coef0                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir2_coef2                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir2_coef_02_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_fir2_coef_02 cvmx_bbp_rafe_fir2_coef_02_t;

/**
 * cvmx_bbp_rafe_fir2_coef_4
 */
union cvmx_bbp_rafe_fir2_coef_4 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir2_coef_4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t fir2_coef4                   : 12; /**< FIR2 Coefficient [4] */
#else
	uint32_t fir2_coef4                   : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rafe_fir2_coef_4_s    cnf71xx;
};
typedef union cvmx_bbp_rafe_fir2_coef_4 cvmx_bbp_rafe_fir2_coef_4_t;

/**
 * cvmx_bbp_rafe_fir3_coef_01
 */
union cvmx_bbp_rafe_fir3_coef_01 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir3_coef_01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir3_coef1                   : 12; /**< FIR3 Coefficient [1] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef0                   : 12; /**< FIR3 Coefficient [0] */
#else
	uint32_t fir3_coef0                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef1                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir3_coef_01_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_fir3_coef_01 cvmx_bbp_rafe_fir3_coef_01_t;

/**
 * cvmx_bbp_rafe_fir3_coef_23
 */
union cvmx_bbp_rafe_fir3_coef_23 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir3_coef_23_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir3_coef3                   : 12; /**< FIR3 Coefficient [3] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef2                   : 12; /**< FIR3 Coefficient [2] */
#else
	uint32_t fir3_coef2                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef3                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir3_coef_23_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_fir3_coef_23 cvmx_bbp_rafe_fir3_coef_23_t;

/**
 * cvmx_bbp_rafe_fir3_coef_45
 */
union cvmx_bbp_rafe_fir3_coef_45 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir3_coef_45_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir3_coef5                   : 12; /**< FIR3 Coefficient [5] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef4                   : 12; /**< FIR3 Coefficient [4] */
#else
	uint32_t fir3_coef4                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef5                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir3_coef_45_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_fir3_coef_45 cvmx_bbp_rafe_fir3_coef_45_t;

/**
 * cvmx_bbp_rafe_fir3_coef_67
 */
union cvmx_bbp_rafe_fir3_coef_67 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir3_coef_67_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir3_coef7                   : 12; /**< FIR3 Coefficient [7] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef6                   : 12; /**< FIR3 Coefficient [6] */
#else
	uint32_t fir3_coef6                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef7                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir3_coef_67_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_fir3_coef_67 cvmx_bbp_rafe_fir3_coef_67_t;

/**
 * cvmx_bbp_rafe_fir3_coef_89
 */
union cvmx_bbp_rafe_fir3_coef_89 {
	uint32_t u32;
	struct cvmx_bbp_rafe_fir3_coef_89_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_28_31               : 4;
	uint32_t fir3_coef9                   : 12; /**< FIR3 Coefficient [9] */
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef8                   : 12; /**< FIR3 Coefficient [8] */
#else
	uint32_t fir3_coef8                   : 12;
	uint32_t reserved_12_15               : 4;
	uint32_t fir3_coef9                   : 12;
	uint32_t reserved_28_31               : 4;
#endif
	} s;
	struct cvmx_bbp_rafe_fir3_coef_89_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_fir3_coef_89 cvmx_bbp_rafe_fir3_coef_89_t;

/**
 * cvmx_bbp_rafe_hab_version
 */
union cvmx_bbp_rafe_hab_version {
	uint32_t u32;
	struct cvmx_bbp_rafe_hab_version_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t drop_ver                     : 16; /**< 16bit Drop Version */
	uint32_t release_ver                  : 16; /**< 16bit Release Version */
#else
	uint32_t release_ver                  : 16;
	uint32_t drop_ver                     : 16;
#endif
	} s;
	struct cvmx_bbp_rafe_hab_version_s    cnf71xx;
};
typedef union cvmx_bbp_rafe_hab_version cvmx_bbp_rafe_hab_version_t;

/**
 * cvmx_bbp_rafe_hw_core_status
 */
union cvmx_bbp_rafe_hw_core_status {
	uint32_t u32;
	struct cvmx_bbp_rafe_hw_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t engine_busy                  : 1;  /**< Indicates if the Internal Engine is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t hab_busy                     : 1;  /**< Busy (linked register 0x0 bit0) */
#else
	uint32_t hab_busy                     : 1;
	uint32_t engine_busy                  : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rafe_hw_core_status_s cnf71xx;
};
typedef union cvmx_bbp_rafe_hw_core_status cvmx_bbp_rafe_hw_core_status_t;

/**
 * cvmx_bbp_rafe_int_mask
 */
union cvmx_bbp_rafe_int_mask {
	uint32_t u32;
	struct cvmx_bbp_rafe_int_mask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t int_msk                      : 32; /**< Interrupt Mask */
#else
	uint32_t int_msk                      : 32;
#endif
	} s;
	struct cvmx_bbp_rafe_int_mask_s       cnf71xx;
};
typedef union cvmx_bbp_rafe_int_mask cvmx_bbp_rafe_int_mask_t;

/**
 * cvmx_bbp_rafe_int_src
 */
union cvmx_bbp_rafe_int_src {
	uint32_t u32;
	struct cvmx_bbp_rafe_int_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_7_31                : 25;
	uint32_t wr_fifo_full_1               : 1;  /**< DMA1 Write FIFO Full
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t wr_overflow_1                : 1;  /**< DMA1 Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t wr_fifo_full_0               : 1;  /**< DMA0 Write FIFO Full
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t wr_overflow_0                : 1;  /**< DMA0 Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t rd_timeout                   : 1;  /**< DMA Read Data Time Out
                                                         '1' = Last subframe data is not recieved in the expected time stamp */
	uint32_t ab_start                     : 1;  /**< Abnormal Start
                                                         '0' = "start" is inserted on the hab ready state
                                                         '1' = "start" is inserted on the hab busy state */
	uint32_t hab_done                     : 1;  /**< '0' = task not completed
                                                         '1' = task completed */
#else
	uint32_t hab_done                     : 1;
	uint32_t ab_start                     : 1;
	uint32_t rd_timeout                   : 1;
	uint32_t wr_overflow_0                : 1;
	uint32_t wr_fifo_full_0               : 1;
	uint32_t wr_overflow_1                : 1;
	uint32_t wr_fifo_full_1               : 1;
	uint32_t reserved_7_31                : 25;
#endif
	} s;
	struct cvmx_bbp_rafe_int_src_s        cnf71xx;
};
typedef union cvmx_bbp_rafe_int_src cvmx_bbp_rafe_int_src_t;

/**
 * cvmx_bbp_rafe_intr_cnt_max
 */
union cvmx_bbp_rafe_intr_cnt_max {
	uint32_t u32;
	struct cvmx_bbp_rafe_intr_cnt_max_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t cnt_en                       : 1;  /**< Enable Internal Count */
	uint32_t reserved_24_30               : 7;
	uint32_t intr_cnt_max                 : 24; /**< Internal Count MAX Value */
#else
	uint32_t intr_cnt_max                 : 24;
	uint32_t reserved_24_30               : 7;
	uint32_t cnt_en                       : 1;
#endif
	} s;
	struct cvmx_bbp_rafe_intr_cnt_max_s   cnf71xx;
};
typedef union cvmx_bbp_rafe_intr_cnt_max cvmx_bbp_rafe_intr_cnt_max_t;

/**
 * cvmx_bbp_rafe_out_end_sample
 */
union cvmx_bbp_rafe_out_end_sample {
	uint32_t u32;
	struct cvmx_bbp_rafe_out_end_sample_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t rafe_out_end                 : 13; /**< RACH DATA OUT End Position */
#else
	uint32_t rafe_out_end                 : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rafe_out_end_sample_s cnf71xx;
};
typedef union cvmx_bbp_rafe_out_end_sample cvmx_bbp_rafe_out_end_sample_t;

/**
 * cvmx_bbp_rafe_out_start_sample
 */
union cvmx_bbp_rafe_out_start_sample {
	uint32_t u32;
	struct cvmx_bbp_rafe_out_start_sample_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_7_31                : 25;
	uint32_t rafe_out_start               : 7;  /**< RACH DATA OUT Start Position */
#else
	uint32_t rafe_out_start               : 7;
	uint32_t reserved_7_31                : 25;
#endif
	} s;
	struct cvmx_bbp_rafe_out_start_sample_s cnf71xx;
};
typedef union cvmx_bbp_rafe_out_start_sample cvmx_bbp_rafe_out_start_sample_t;

/**
 * cvmx_bbp_rafe_phase_inc
 */
union cvmx_bbp_rafe_phase_inc {
	uint32_t u32;
	struct cvmx_bbp_rafe_phase_inc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_15_31               : 17;
	uint32_t phase_inc                    : 15; /**< Phase Rotator Increment Value */
#else
	uint32_t phase_inc                    : 15;
	uint32_t reserved_15_31               : 17;
#endif
	} s;
	struct cvmx_bbp_rafe_phase_inc_s      cnf71xx;
};
typedef union cvmx_bbp_rafe_phase_inc cvmx_bbp_rafe_phase_inc_t;

/**
 * cvmx_bbp_rafe_proc_start
 */
union cvmx_bbp_rafe_proc_start {
	uint32_t u32;
	struct cvmx_bbp_rafe_proc_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t proc_start                   : 16; /**< RACH DATA Start Position */
#else
	uint32_t proc_start                   : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_rafe_proc_start_s     cnf71xx;
};
typedef union cvmx_bbp_rafe_proc_start cvmx_bbp_rafe_proc_start_t;

/**
 * cvmx_bbp_rafe_status
 *
 * &BBP_RAFE_DID_ID = 0x6F007F844000
 * RAFE_CSR_VERSION = v1.0 // hab_source_version
 */
union cvmx_bbp_rafe_status {
	uint32_t u32;
	struct cvmx_bbp_rafe_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t hab_busy                     : 1;  /**< Indicates if the Hardware accelerator is busy
                                                         '0' = ready
                                                         '1' = busy */
#else
	uint32_t hab_busy                     : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rafe_status_s         cnf71xx;
};
typedef union cvmx_bbp_rafe_status cvmx_bbp_rafe_status_t;

/**
 * cvmx_bbp_rafe_sys_conf
 */
union cvmx_bbp_rafe_sys_conf {
	uint32_t u32;
	struct cvmx_bbp_rafe_sys_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t prt_test                     : 1;  /**< Phase Rotator test mode
                                                         0 - Normal
                                                         1 - test mode */
	uint32_t cp_rmv_test                  : 1;  /**< CP remove test mode
                                                         0 - Normal
                                                         1 - test mode */
	uint32_t reserved_3_15                : 13;
	uint32_t fir_mode                     : 3;  /**< Selection FIR mode
                                                         0 = 20MHz, PF0~3
                                                         1 = 10MHz, PF0~3
                                                         2 = 05MHz, PF0~3
                                                         3 = TEST MODE
                                                         4 = 20MHz, PF4
                                                         5 = 10MHz, PF4
                                                         6 = 05MHz, PF4
                                                         7 = reserved */
#else
	uint32_t fir_mode                     : 3;
	uint32_t reserved_3_15                : 13;
	uint32_t cp_rmv_test                  : 1;
	uint32_t prt_test                     : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rafe_sys_conf_s       cnf71xx;
};
typedef union cvmx_bbp_rafe_sys_conf cvmx_bbp_rafe_sys_conf_t;

/**
 * cvmx_bbp_rfif_1pps_gen_cfg
 */
union cvmx_bbp_rfif_1pps_gen_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_1pps_gen_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ena                          : 1;  /**< Enable 1PPS Tracking
                                                         - 0: 1PPS signal not tracked
                                                         - 1: 1PPS signal tracked */
#else
	uint32_t ena                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_1pps_gen_cfg_s   cnf71xx;
};
typedef union cvmx_bbp_rfif_1pps_gen_cfg cvmx_bbp_rfif_1pps_gen_cfg_t;

/**
 * cvmx_bbp_rfif_1pps_sample_cnt_offset
 */
union cvmx_bbp_rfif_1pps_sample_cnt_offset {
	uint32_t u32;
	struct cvmx_bbp_rfif_1pps_sample_cnt_offset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t offset                       : 20; /**< This register holds the sample count at which the 1PPS
                                                         was received.
                                                         Upon reset, the sample counter starts at 0 when the
                                                         first 1PPS is received and then increments to wrap
                                                         around at FRAME_L-1. At each subsequent 1PPS, a
                                                         snapshot of the sample counter is taken and the count
                                                         is made available via this register. This enables
                                                         software to monitor the RF clock drift relative to
                                                         the 1PPS. */
#else
	uint32_t offset                       : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_1pps_sample_cnt_offset_s cnf71xx;
};
typedef union cvmx_bbp_rfif_1pps_sample_cnt_offset cvmx_bbp_rfif_1pps_sample_cnt_offset_t;

/**
 * cvmx_bbp_rfif_1pps_verif_gen_en
 */
union cvmx_bbp_rfif_1pps_verif_gen_en {
	uint32_t u32;
	struct cvmx_bbp_rfif_1pps_verif_gen_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ena                          : 1;  /**< 1PPS generation for verification purposes
                                                         - 0: Disabled (default)
                                                         - 1: Enabled
                                                          Note the external 1PPS is not considered, when this bit
                                                          is set to 1. */
#else
	uint32_t ena                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_1pps_verif_gen_en_s cnf71xx;
};
typedef union cvmx_bbp_rfif_1pps_verif_gen_en cvmx_bbp_rfif_1pps_verif_gen_en_t;

/**
 * cvmx_bbp_rfif_1pps_verif_scnt
 */
union cvmx_bbp_rfif_1pps_verif_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_1pps_verif_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Sample count at which the 1PPS is generated for
                                                         verification purposes. */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_1pps_verif_scnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_1pps_verif_scnt cvmx_bbp_rfif_1pps_verif_scnt_t;

/**
 * cvmx_bbp_rfif_conf
 */
union cvmx_bbp_rfif_conf {
	uint32_t u32;
	struct cvmx_bbp_rfif_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t loopback                     : 1;  /**< FDD loop back mode
                                                         - 0: Not in loopback mode(default)
                                                         - 1: loops back the tx ouput to the rx input inside the
                                                          rf_if */
	uint32_t mol                          : 1;  /**< Manual Override Lock
                                                         1 : Unlocks access to bits 9, 10 and 11. */
	uint32_t upd_style                    : 1;  /**< TX and RX Windows parameters update style (default:0)
                                                         - 0: updated as written to the register (on the fly)
                                                          (not fully verified but kept in case limitations are
                                                          found with the other update scheme.)
                                                         - 1: updated at the specified time by registers 00F and
                                                          90F(recommended). */
	uint32_t diversity                    : 1;  /**< RX diversity disable (Used to support FDD SISO with CLK
                                                          4X)
                                                         - 0: Data gets written to the diversity FIFO in MIMO mode
                                                          (default).
                                                         - 1: No data written to the diversity FIFO in MIMO mode. */
	uint32_t duplex                       : 1;  /**< Division Duplex Mode
                                                         - 0: TDD (default)
                                                         - 1: FDD */
	uint32_t prod_type                    : 1;  /**< Product Type
                                                          0 : UE (default),
                                                         - 1: eNB, enables using 1PPS synchronization scheme. */
	uint32_t txnrx_ctrl                   : 1;  /**< RFIC IF TXnRX signal pulse control. Changing the value
                                                         of this bit generates a pulse on the TXNRX signal of
                                                         the RFIC interface. This feature is enabled when bit
                                                         9 has already been asserted. */
	uint32_t ena_ctrl                     : 1;  /**< RFIC IF ENABLE signal pulse control. Changing the value
                                                         of this bit generates a pulse on the ENABLE signal of
                                                         the RFIC interface. This feature is enabled when bit 9
                                                         has already been asserted. */
	uint32_t man_ctrl                     : 1;  /**< RF IC Manual Control Enable. Setting this bit to 1
                                                         enables manual control of the TXNRX and ENABLE signals.
                                                         When set to 0 (default), the TXNRX and ENABLE signals
                                                         are automatically controlled when opening and closing
                                                         RX/TX windows. The manual mode is used to initialize
                                                         the RFIC in alert mode. */
	uint32_t dsp_rx_int_en                : 1;  /**< DSP RX interrupt mask enable
                                                         - 0: DSP RX receives interrupts
                                                         - 1: DSP RX doesn't receive interrupts, needs to poll
                                                          ISRs */
	uint32_t adi_en                       : 1;  /**< ADI enable signal pulsed or leveled behavior
                                                         - 0: pulsed
                                                         - 1: leveled */
	uint32_t clr_fifo_of                  : 1;  /**< Clear RX FIFO overflow flag  (auto clear) */
	uint32_t clr_fifo_ur                  : 1;  /**< Clear RX FIFO under run flag (auto clear) */
	uint32_t ind_ctrl_mode                : 1;  /**< AD9361 FDD independent control mode, where enable
                                                          becomes rx_control and txnrx becomes tx_control.Enables
                                                          the FDD independent control of the rx and tx data
                                                          flows.
                                                         - 0: independent control mode
                                                         - 1: regular mode */
	uint32_t flush                        : 1;  /**< Flush RX FIFO (auto clear register) */
	uint32_t inv                          : 1;  /**< Data bus inversion
                                                         0 : Straight
                                                         1 : Inverted, bit 0 becomes bit 11, bit 1 becomes 10... */
	uint32_t mode                         : 1;  /**< RX MIMO/SISO mode of operation
                                                         - 0: SISO 1: MIMO */
	uint32_t enable                       : 1;  /**< Enable the interface after the 1PPS synchronization
                                                         1=enable, 0=disabled */
#else
	uint32_t enable                       : 1;
	uint32_t mode                         : 1;
	uint32_t inv                          : 1;
	uint32_t flush                        : 1;
	uint32_t ind_ctrl_mode                : 1;
	uint32_t clr_fifo_ur                  : 1;
	uint32_t clr_fifo_of                  : 1;
	uint32_t adi_en                       : 1;
	uint32_t dsp_rx_int_en                : 1;
	uint32_t man_ctrl                     : 1;
	uint32_t ena_ctrl                     : 1;
	uint32_t txnrx_ctrl                   : 1;
	uint32_t prod_type                    : 1;
	uint32_t duplex                       : 1;
	uint32_t diversity                    : 1;
	uint32_t upd_style                    : 1;
	uint32_t mol                          : 1;
	uint32_t loopback                     : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rfif_conf_s           cnf71xx;
};
typedef union cvmx_bbp_rfif_conf cvmx_bbp_rfif_conf_t;

/**
 * cvmx_bbp_rfif_conf2
 */
union cvmx_bbp_rfif_conf2 {
	uint32_t u32;
	struct cvmx_bbp_rfif_conf2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t latency                      : 1;  /**< RF DATA variable latency
                                                         - 0: fixed latency (prior to AD9361)
                                                         - 1: variable latency (recommended) */
	uint32_t iq_cfg                       : 1;  /**< IQ port configuration
                                                         - 0: Single port (10Mhz BW and less)
                                                         - 1: Dual ports (more then 10Mhz BW) */
	uint32_t behavior                     : 1;  /**< RX and TX FRAME signals behavior:
                                                         - 0: Pulsed every frame (not recommended)
                                                         - 1: Leveled during the whole RX and TX periods */
#else
	uint32_t behavior                     : 1;
	uint32_t iq_cfg                       : 1;
	uint32_t latency                      : 1;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_rfif_conf2_s          cnf71xx;
};
typedef union cvmx_bbp_rfif_conf2 cvmx_bbp_rfif_conf2_t;

/**
 * cvmx_bbp_rfif_dsp_rx_is
 */
union cvmx_bbp_rfif_dsp_rx_is {
	uint32_t u32;
	struct cvmx_bbp_rfif_dsp_rx_is_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_0_31                : 32;
#else
	uint32_t reserved_0_31                : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_dsp_rx_is_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_dsp_rx_is cvmx_bbp_rfif_dsp_rx_is_t;

/**
 * cvmx_bbp_rfif_dsp_rx_ism
 */
union cvmx_bbp_rfif_dsp_rx_ism {
	uint32_t u32;
	struct cvmx_bbp_rfif_dsp_rx_ism_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t pps_sync_done                : 1;  /**< PPS sync done interrupt enable */
	uint32_t spi_skipped                  : 1;  /**< SPI event skipped interrupt enable */
	uint32_t spi_xfer_done_3              : 1;  /**< SPI transfer done 3 interrupt enable */
	uint32_t spi_xfer_done_2              : 1;  /**< SPI transfer done 2 interrupt enable */
	uint32_t spi_xfer_done_1              : 1;  /**< SPI transfer done 1 interrupt enable */
	uint32_t spi_xfer_done_0              : 1;  /**< SPI transfer done 0 interrupt enable */
	uint32_t st_tx_frame                  : 1;  /**< Start of TX frame interrupt enable */
	uint32_t st_rx_frame                  : 1;  /**< Start of RX frame interrupt enable */
	uint32_t rx_div_flags                 : 1;  /**< RX FIFO flags interrupt enable */
	uint32_t rx_div_thresh                : 1;  /**< RX DIV FIFO threshold interrupt enable */
	uint32_t rx_flags                     : 1;  /**< RX FIFO flags interrupt enable */
	uint32_t rx_thresh                    : 1;  /**< RX FIFO threshold interrupt enable */
#else
	uint32_t rx_thresh                    : 1;
	uint32_t rx_flags                     : 1;
	uint32_t rx_div_thresh                : 1;
	uint32_t rx_div_flags                 : 1;
	uint32_t st_rx_frame                  : 1;
	uint32_t st_tx_frame                  : 1;
	uint32_t spi_xfer_done_0              : 1;
	uint32_t spi_xfer_done_1              : 1;
	uint32_t spi_xfer_done_2              : 1;
	uint32_t spi_xfer_done_3              : 1;
	uint32_t spi_skipped                  : 1;
	uint32_t pps_sync_done                : 1;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rfif_dsp_rx_ism_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_dsp_rx_ism cvmx_bbp_rfif_dsp_rx_ism_t;

/**
 * cvmx_bbp_rfif_dsp_tx_is
 */
union cvmx_bbp_rfif_dsp_tx_is {
	uint32_t u32;
	struct cvmx_bbp_rfif_dsp_tx_is_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_0_31                : 32;
#else
	uint32_t reserved_0_31                : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_dsp_tx_is_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_dsp_tx_is cvmx_bbp_rfif_dsp_tx_is_t;

/**
 * cvmx_bbp_rfif_dsp_tx_ism
 */
union cvmx_bbp_rfif_dsp_tx_ism {
	uint32_t u32;
	struct cvmx_bbp_rfif_dsp_tx_ism_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t pps_sync_done                : 1;  /**< PPS sync done interrupt enable */
	uint32_t spi_skipped                  : 1;  /**< SPI event skipped interrupt enable */
	uint32_t spi_xfer_done_3              : 1;  /**< SPI transfer done 3 interrupt enable */
	uint32_t spi_xfer_done_2              : 1;  /**< SPI transfer done 2 interrupt enable */
	uint32_t spi_xfer_done_1              : 1;  /**< SPI transfer done 1 interrupt enable */
	uint32_t spi_xfer_done_0              : 1;  /**< SPI transfer done 0 interrupt enable */
	uint32_t st_tx_frame                  : 1;  /**< Start of TX frame interrupt enable */
	uint32_t st_rx_frame                  : 1;  /**< Start of RX frame interrupt enable */
	uint32_t tx_div_flags                 : 1;  /**< RX FIFO flags interrupt enable */
	uint32_t tx_div_thresh                : 1;  /**< RX DIV FIFO threshold interrupt enable */
	uint32_t tx_flags                     : 1;  /**< RX FIFO flags interrupt enable */
	uint32_t tx_thresh                    : 1;  /**< RX FIFO threshold interrupt enable */
#else
	uint32_t tx_thresh                    : 1;
	uint32_t tx_flags                     : 1;
	uint32_t tx_div_thresh                : 1;
	uint32_t tx_div_flags                 : 1;
	uint32_t st_rx_frame                  : 1;
	uint32_t st_tx_frame                  : 1;
	uint32_t spi_xfer_done_0              : 1;
	uint32_t spi_xfer_done_1              : 1;
	uint32_t spi_xfer_done_2              : 1;
	uint32_t spi_xfer_done_3              : 1;
	uint32_t spi_skipped                  : 1;
	uint32_t pps_sync_done                : 1;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rfif_dsp_tx_ism_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_dsp_tx_ism cvmx_bbp_rfif_dsp_tx_ism_t;

/**
 * cvmx_bbp_rfif_firs_enable
 *
 * Notes:
 * This register must be set to 0 for eNB products, since the filtering is not supported.
 *
 */
union cvmx_bbp_rfif_firs_enable {
	uint32_t u32;
	struct cvmx_bbp_rfif_firs_enable_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t tx_div_fil                   : 1;  /**< TX DIV filtering control bit
                                                         - 0: TX DIV filtering disabled
                                                         - 1: TX DIV filtering enabled */
	uint32_t tx_fil                       : 1;  /**< TX filtering control bit
                                                         - 0: TX filtering disabled
                                                         - 1: TX filtering enabled */
	uint32_t rx_dif_fil                   : 1;  /**< RX DIV filtering control bit
                                                         - 0: RX DIV filtering disabled
                                                         - 1: RX DIV filtering enabled */
	uint32_t rx_fil                       : 1;  /**< RX filtering control bit
                                                         - 0: RX filtering disabled
                                                         - 1: RX filtering enabled */
#else
	uint32_t rx_fil                       : 1;
	uint32_t rx_dif_fil                   : 1;
	uint32_t tx_fil                       : 1;
	uint32_t tx_div_fil                   : 1;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_firs_enable_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_firs_enable cvmx_bbp_rfif_firs_enable_t;

/**
 * cvmx_bbp_rfif_frame_cnt
 */
union cvmx_bbp_rfif_frame_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_frame_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Frame count (value wraps around 2**16) */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_frame_cnt_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_frame_cnt cvmx_bbp_rfif_frame_cnt_t;

/**
 * cvmx_bbp_rfif_frame_l
 */
union cvmx_bbp_rfif_frame_l {
	uint32_t u32;
	struct cvmx_bbp_rfif_frame_l_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t frame_l                      : 20; /**< Frame length in terms of RF clock cycles:
                                                         RFIC in single port modes
                                                         TDD SISO -> FRAME_L = num_samples
                                                         TDD MIMO -> FRAME_L = num_samples * 2
                                                         FDD SISO -> FRAME_L = num_samples * 2
                                                         FDD MIMO -> FRAME_L = num_samples * 4
                                                         RFIC in dual ports modes
                                                         TDD SISO -> FRAME_L = num_samples * 0.5
                                                         TDD MIMO -> FRAME_L = num_samples
                                                         FDD SISO -> FRAME_L = num_samples
                                                         FDD MIMO -> FRAME_L = num_samples * 2 */
#else
	uint32_t frame_l                      : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_frame_l_s        cnf71xx;
};
typedef union cvmx_bbp_rfif_frame_l cvmx_bbp_rfif_frame_l_t;

/**
 * cvmx_bbp_rfif_gpo
 */
union cvmx_bbp_rfif_gpo {
	uint32_t u32;
	struct cvmx_bbp_rfif_gpo_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t val                          : 4;  /**< Values to output to the DSP1_GPIO ports */
#else
	uint32_t val                          : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_gpo_s            cnf71xx;
};
typedef union cvmx_bbp_rfif_gpo cvmx_bbp_rfif_gpo_t;

/**
 * cvmx_bbp_rfif_gpo_#
 */
union cvmx_bbp_rfif_gpo_x {
	uint32_t u32;
	struct cvmx_bbp_rfif_gpo_x_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t fall_val                     : 11; /**< Signed value (lead/lag) on falling edge of level signal */
	uint32_t rise_val                     : 11; /**< Signed value (lead/lag) on rising edge of level signal */
	uint32_t src                          : 2;  /**< Signal active high source:
                                                         - 00: idle
                                                         - 01: RX
                                                         - 10: TX
                                                         - 11: idle */
#else
	uint32_t src                          : 2;
	uint32_t rise_val                     : 11;
	uint32_t fall_val                     : 11;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_gpo_x_s          cnf71xx;
};
typedef union cvmx_bbp_rfif_gpo_x cvmx_bbp_rfif_gpo_x_t;

/**
 * cvmx_bbp_rfif_int_ctrl_status
 */
union cvmx_bbp_rfif_int_ctrl_status {
	uint32_t u32;
	struct cvmx_bbp_rfif_int_ctrl_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpint_en_7                   : 1;  /**< General purpose interrupt 7 enable (rising edge detect) */
	uint32_t gpint_en_6                   : 1;  /**< General purpose interrupt 6 enable (rising edge detect) */
	uint32_t gpint_en_5                   : 1;  /**< General purpose interrupt 5 enable (rising edge detect) */
	uint32_t gpint_en_4                   : 1;  /**< General purpose interrupt 4 enable (rising edge detect) */
	uint32_t gpint_en_3                   : 1;  /**< General purpose interrupt 3 enable (rising edge detect) */
	uint32_t gpint_en_2                   : 1;  /**< General purpose interrupt 2 enable (rising edge detect) */
	uint32_t gpint_en_1                   : 1;  /**< General purpose interrupt 1 enable (rising edge detect) */
	uint32_t gpint_en_0                   : 1;  /**< General purpose interrupt 0 enable (rising edge detect) */
	uint32_t exwunden                     : 1;  /**< Extended write FIFO Overflow interrupt enable */
	uint32_t exrovren                     : 1;  /**< Extended read FIFO overflow interrupt enable */
	uint32_t boen                         : 1;  /**< Bit count overflow interrupt enable (active high) */
	uint32_t roen                         : 1;  /**< RX FIFO overflow interrupt enable (active high) */
	uint32_t rfen                         : 1;  /**< RX FIFO full interrupt enable (active high) */
	uint32_t reen                         : 1;  /**< RX FIFO not empty interrupt enable (active high) */
	uint32_t tfen                         : 1;  /**< TX FIFO full interrupt enable (active high) */
	uint32_t teen                         : 1;  /**< TX FIFO empty interrupt enable (active high) */
	uint32_t gp_int7                      : 1;  /**< General purpose interrupt 7 (rising edge detect) */
	uint32_t gp_int6                      : 1;  /**< General purpose interrupt 6 (rising edge detect) */
	uint32_t gp_int5                      : 1;  /**< General purpose interrupt 5 (rising edge detect) */
	uint32_t gp_int4                      : 1;  /**< General purpose interrupt 4 (rising edge detect) */
	uint32_t gp_int3                      : 1;  /**< General purpose interrupt 3 (rising edge detect) */
	uint32_t gp_int2                      : 1;  /**< General purpose interrupt 2 (rising edge detect) */
	uint32_t gp_int1                      : 1;  /**< General purpose interrupt 1 (rising edge detect) */
	uint32_t gp_int0                      : 1;  /**< General purpose interrupt 0 (rising edge detect) */
	uint32_t exwund_int                   : 1;  /**< Extended write FIFO underflow Interrupt (active high) */
	uint32_t exrovr_int                   : 1;  /**< Extended read FIFO Overflow Interrupt (active high) */
	uint32_t bo                           : 1;  /**< Bit count overflow status (not valid in masteROmode) */
	uint32_t ro                           : 1;  /**< RX FIFO overflow status (1 when overflowed,0 otherwise) */
	uint32_t rf                           : 1;  /**< RX FIFO full status (active high) */
	uint32_t re                           : 1;  /**< RX FIFO not empty status (active high) */
	uint32_t tf                           : 1;  /**< TX FIFO full status (active high) */
	uint32_t te                           : 1;  /**< TX FIFO empty status (active high) */
#else
	uint32_t te                           : 1;
	uint32_t tf                           : 1;
	uint32_t re                           : 1;
	uint32_t rf                           : 1;
	uint32_t ro                           : 1;
	uint32_t bo                           : 1;
	uint32_t exrovr_int                   : 1;
	uint32_t exwund_int                   : 1;
	uint32_t gp_int0                      : 1;
	uint32_t gp_int1                      : 1;
	uint32_t gp_int2                      : 1;
	uint32_t gp_int3                      : 1;
	uint32_t gp_int4                      : 1;
	uint32_t gp_int5                      : 1;
	uint32_t gp_int6                      : 1;
	uint32_t gp_int7                      : 1;
	uint32_t teen                         : 1;
	uint32_t tfen                         : 1;
	uint32_t reen                         : 1;
	uint32_t rfen                         : 1;
	uint32_t roen                         : 1;
	uint32_t boen                         : 1;
	uint32_t exrovren                     : 1;
	uint32_t exwunden                     : 1;
	uint32_t gpint_en_0                   : 1;
	uint32_t gpint_en_1                   : 1;
	uint32_t gpint_en_2                   : 1;
	uint32_t gpint_en_3                   : 1;
	uint32_t gpint_en_4                   : 1;
	uint32_t gpint_en_5                   : 1;
	uint32_t gpint_en_6                   : 1;
	uint32_t gpint_en_7                   : 1;
#endif
	} s;
	struct cvmx_bbp_rfif_int_ctrl_status_s cnf71xx;
};
typedef union cvmx_bbp_rfif_int_ctrl_status cvmx_bbp_rfif_int_ctrl_status_t;

/**
 * cvmx_bbp_rfif_int_ctrl_status_shadow
 */
union cvmx_bbp_rfif_int_ctrl_status_shadow {
	uint32_t u32;
	struct cvmx_bbp_rfif_int_ctrl_status_shadow_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpint_en_7_stat              : 1;  /**< General purpose interrupt 7 enable (rising edge detect) */
	uint32_t gpint_en_6_stat              : 1;  /**< General purpose interrupt 6 enable (rising edge detect) */
	uint32_t gpint_en_5_stat              : 1;  /**< General purpose interrupt 5 enable (rising edge detect) */
	uint32_t gpint_en_4_stat              : 1;  /**< General purpose interrupt 4 enable (rising edge detect) */
	uint32_t gpint_en_3_stat              : 1;  /**< General purpose interrupt 3 enable (rising edge detect) */
	uint32_t gpint_en_2_stat              : 1;  /**< General purpose interrupt 2 enable (rising edge detect) */
	uint32_t gpint_en_1_stat              : 1;  /**< General purpose interrupt 1 enable (rising edge detect) */
	uint32_t gpint_en_0_stat              : 1;  /**< General purpose interrupt 0 enable (rising edge detect) */
	uint32_t exwunden_stat                : 1;  /**< Extended write FIFO Overflow interrupt enable
                                                         (active high) */
	uint32_t exrovren_stat                : 1;  /**< Extended read FIFO overflow interrupt enable
                                                         (active high) */
	uint32_t boen_stat                    : 1;  /**< Bit count overflow interrupt enable (active high) */
	uint32_t roen_stat                    : 1;  /**< RX FIFO overflow interrupt enable (active high) */
	uint32_t rfen_stat                    : 1;  /**< RX FIFO full interrupt enable (active high) */
	uint32_t reen_stat                    : 1;  /**< RX FIFO not empty interrupt enable (active high) */
	uint32_t tfen_stat                    : 1;  /**< TX FIFO full interrupt enable (active high) */
	uint32_t teen_stat                    : 1;  /**< TX FIFO empty interrupt enable (active high) */
	uint32_t reserved_0_15                : 16;
#else
	uint32_t reserved_0_15                : 16;
	uint32_t teen_stat                    : 1;
	uint32_t tfen_stat                    : 1;
	uint32_t reen_stat                    : 1;
	uint32_t rfen_stat                    : 1;
	uint32_t roen_stat                    : 1;
	uint32_t boen_stat                    : 1;
	uint32_t exrovren_stat                : 1;
	uint32_t exwunden_stat                : 1;
	uint32_t gpint_en_0_stat              : 1;
	uint32_t gpint_en_1_stat              : 1;
	uint32_t gpint_en_2_stat              : 1;
	uint32_t gpint_en_3_stat              : 1;
	uint32_t gpint_en_4_stat              : 1;
	uint32_t gpint_en_5_stat              : 1;
	uint32_t gpint_en_6_stat              : 1;
	uint32_t gpint_en_7_stat              : 1;
#endif
	} s;
	struct cvmx_bbp_rfif_int_ctrl_status_shadow_s cnf71xx;
};
typedef union cvmx_bbp_rfif_int_ctrl_status_shadow cvmx_bbp_rfif_int_ctrl_status_shadow_t;

/**
 * cvmx_bbp_rfif_max_sample_adj
 */
union cvmx_bbp_rfif_max_sample_adj {
	uint32_t u32;
	struct cvmx_bbp_rfif_max_sample_adj_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t num                          : 3;  /**< Indicates the maximum number of samples that can be
                                                         adjusted per frame. Note the value to be programmed
                                                         varies with the mode of operation as follow:
                                                         MAX_SAMPLE_ADJ  = num_samples*MIMO*FDD*DP
                                                         Where:
                                                         MIMO = 2 in MIMO mode and 1 otherwise.
                                                         FDD = 2 in FDD mode and 1 otherwise.
                                                         DP = 0.5 in RF IF Dual Port mode, 1 otherwise.
                                                         num_samples(max) = 6. */
#else
	uint32_t num                          : 3;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_rfif_max_sample_adj_s cnf71xx;
};
typedef union cvmx_bbp_rfif_max_sample_adj cvmx_bbp_rfif_max_sample_adj_t;

/**
 * cvmx_bbp_rfif_min_sample_adj
 */
union cvmx_bbp_rfif_min_sample_adj {
	uint32_t u32;
	struct cvmx_bbp_rfif_min_sample_adj_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t num                          : 3;  /**< Indicates the minimum number of samples that can be
                                                         adjusted per frame. Note the value to be programmed
                                                         varies with the mode of operation as follow:
                                                         MIN_SAMPLE_ADJ  = num_samples*MIMO*FDD*DP
                                                         Where:
                                                         MIMO = 2 in MIMO mode and 1 otherwise.
                                                         FDD = 2 in FDD mode and 1 otherwise.
                                                         DP = 0.5 in RF IF Dual Port mode, 1 otherwise. */
#else
	uint32_t num                          : 3;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_rfif_min_sample_adj_s cnf71xx;
};
typedef union cvmx_bbp_rfif_min_sample_adj cvmx_bbp_rfif_min_sample_adj_t;

/**
 * cvmx_bbp_rfif_num_rx_win
 */
union cvmx_bbp_rfif_num_rx_win {
	uint32_t u32;
	struct cvmx_bbp_rfif_num_rx_win_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t num                          : 3;  /**< Number of RX windows
                                                         - 0: No RX window
                                                         - 1: One RX window
                                                          - ...
                                                         - 4: Four RX windows
                                                          Other: Not defined */
#else
	uint32_t num                          : 3;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_rfif_num_rx_win_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_num_rx_win cvmx_bbp_rfif_num_rx_win_t;

/**
 * cvmx_bbp_rfif_num_tx_win
 */
union cvmx_bbp_rfif_num_tx_win {
	uint32_t u32;
	struct cvmx_bbp_rfif_num_tx_win_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t num                          : 3;  /**< Number of TX windows
                                                         - 0: No TX window
                                                         - 1: One TX window
                                                          - ...
                                                         - 4: Four TX windows
                                                          Other: Not defined */
#else
	uint32_t num                          : 3;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_rfif_num_tx_win_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_num_tx_win cvmx_bbp_rfif_num_tx_win_t;

/**
 * cvmx_bbp_rfif_pwm_enable
 */
union cvmx_bbp_rfif_pwm_enable {
	uint32_t u32;
	struct cvmx_bbp_rfif_pwm_enable_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ena                          : 1;  /**< PWM signal generation enable:
                                                         - 1: PWM enabled
                                                         - 0: PWM disabled (default) */
#else
	uint32_t ena                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_pwm_enable_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_pwm_enable cvmx_bbp_rfif_pwm_enable_t;

/**
 * cvmx_bbp_rfif_pwm_high_time
 */
union cvmx_bbp_rfif_pwm_high_time {
	uint32_t u32;
	struct cvmx_bbp_rfif_pwm_high_time_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t hi_time                      : 24; /**< PWM high time. The default is 0h00FFFF cycles. Program
                                                         to n for n+1 high cycles. */
#else
	uint32_t hi_time                      : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_pwm_high_time_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_pwm_high_time cvmx_bbp_rfif_pwm_high_time_t;

/**
 * cvmx_bbp_rfif_pwm_low_time
 */
union cvmx_bbp_rfif_pwm_low_time {
	uint32_t u32;
	struct cvmx_bbp_rfif_pwm_low_time_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t lo_time                      : 24; /**< PWM low time. The default is 0h00FFFF cycles. Program
                                                         to n for n+1 low cycles. */
#else
	uint32_t lo_time                      : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_pwm_low_time_s   cnf71xx;
};
typedef union cvmx_bbp_rfif_pwm_low_time cvmx_bbp_rfif_pwm_low_time_t;

/**
 * cvmx_bbp_rfif_rd_timer64_lsb
 */
union cvmx_bbp_rfif_rd_timer64_lsb {
	uint32_t u32;
	struct cvmx_bbp_rfif_rd_timer64_lsb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t val                          : 32; /**< 64-bit timer initial value of the 32 LSB.
                                                         Note the value written in WR_TIMER64_LSB is not
                                                         propagating until the timer64 is enabled. */
#else
	uint32_t val                          : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_rd_timer64_lsb_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rd_timer64_lsb cvmx_bbp_rfif_rd_timer64_lsb_t;

/**
 * cvmx_bbp_rfif_rd_timer64_msb
 */
union cvmx_bbp_rfif_rd_timer64_msb {
	uint32_t u32;
	struct cvmx_bbp_rfif_rd_timer64_msb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t val                          : 32; /**< 64-bit timer initial value of the 32 MSB.
                                                         Note the value written in WR_TIMER64_MSB is not
                                                         propagating until the timer64 is enabled. */
#else
	uint32_t val                          : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_rd_timer64_msb_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rd_timer64_msb cvmx_bbp_rfif_rd_timer64_msb_t;

/**
 * cvmx_bbp_rfif_real_time_timer
 */
union cvmx_bbp_rfif_real_time_timer {
	uint32_t u32;
	struct cvmx_bbp_rfif_real_time_timer_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t timer                        : 32; /**< The full 32 bits of the real time timer fed from a core
                                                         clock based counter. */
#else
	uint32_t timer                        : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_real_time_timer_s cnf71xx;
};
typedef union cvmx_bbp_rfif_real_time_timer cvmx_bbp_rfif_real_time_timer_t;

/**
 * cvmx_bbp_rfif_rf_clk_timer
 */
union cvmx_bbp_rfif_rf_clk_timer {
	uint32_t u32;
	struct cvmx_bbp_rfif_rf_clk_timer_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t timer                        : 32; /**< Timer running off the RF CLK.
                                                         1- The counter is disabled by default;
                                                         2- The counter is enabled by writing register 0x198
                                                         3- The counter waits for the 1PPS to start incrementing
                                                         4- The 1PPS is received and the counter starts
                                                         incrementing;
                                                         5- The counter is reset after receiving the 30th 1PPS
                                                         (after 30 seconds);
                                                         6- The counter keeps incrementing and is reset as in 5,
                                                         unless it is disabled. */
#else
	uint32_t timer                        : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_rf_clk_timer_s   cnf71xx;
};
typedef union cvmx_bbp_rfif_rf_clk_timer cvmx_bbp_rfif_rf_clk_timer_t;

/**
 * cvmx_bbp_rfif_rf_clk_timer_en
 */
union cvmx_bbp_rfif_rf_clk_timer_en {
	uint32_t u32;
	struct cvmx_bbp_rfif_rf_clk_timer_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ena                          : 1;  /**< RF CLK based timer enable
                                                         - 0: Disabled
                                                         - 1: Enabled */
#else
	uint32_t ena                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_rf_clk_timer_en_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rf_clk_timer_en cvmx_bbp_rfif_rf_clk_timer_en_t;

/**
 * cvmx_bbp_rfif_rx_correct_adj
 */
union cvmx_bbp_rfif_rx_correct_adj {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_correct_adj_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t offset                       : 4;  /**< Indicates the sample counter offset for the last sample
                                                         flag insertion, which determines when the rx samples
                                                         are dropped or added. This register can take values
                                                         from 0 to 15 and should be configured as follow:
                                                         4 : when MIN_SAMPLE_ADJ = 1
                                                         5 : when MIN_SAMPLE_ADJ = 2
                                                         6 : when MIN_SAMPLE_ADJ = 4 */
#else
	uint32_t offset                       : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_correct_adj_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_correct_adj cvmx_bbp_rfif_rx_correct_adj_t;

/**
 * cvmx_bbp_rfif_rx_div_fifo_cnt
 */
union cvmx_bbp_rfif_rx_div_fifo_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_div_fifo_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t cnt                          : 13; /**< RX DIV FIFO fill level. This register can take values
                                                         between 0 and 2048. */
#else
	uint32_t cnt                          : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_div_fifo_cnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_div_fifo_cnt cvmx_bbp_rfif_rx_div_fifo_cnt_t;

/**
 * cvmx_bbp_rfif_rx_div_gen_purp
 */
union cvmx_bbp_rfif_rx_div_gen_purp {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_div_gen_purp_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t int_mask                     : 1;  /**< DSP RX diversity interrupt mask enable
                                                         0 : Enabled
                                                         1 : Disabled, need to pll ISRs. */
	uint32_t reserved_3_7                 : 5;
	uint32_t clr_ovflw                    : 1;  /**< RX diversity FIFO overflow clear
                                                         0 : Do not clear
                                                         1 : Clear the the overflow flag */
	uint32_t clr_underrun                 : 1;  /**< RX diversity FIFO underrun clear
                                                         0 : Do not clear
                                                         1 : Clear the the underrun flag */
	uint32_t ff_flush                     : 1;  /**< RX diversity FIFO flush
                                                         0 : Do not flush
                                                         1 : Flush the FIFO */
#else
	uint32_t ff_flush                     : 1;
	uint32_t clr_underrun                 : 1;
	uint32_t clr_ovflw                    : 1;
	uint32_t reserved_3_7                 : 5;
	uint32_t int_mask                     : 1;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_div_gen_purp_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_div_gen_purp cvmx_bbp_rfif_rx_div_gen_purp_t;

/**
 * cvmx_bbp_rfif_rx_div_load_cfg
 */
union cvmx_bbp_rfif_rx_div_load_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_div_load_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t exe                          : 1;  /**< Setting this bit to 1 indicates the RF_IF to load
                                                         and execute the programmed DMA transfer size (register
                                                         RX_DIV_TRANSFER_SIZE) from the FIFO to a destination. */
#else
	uint32_t exe                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_div_load_cfg_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_div_load_cfg cvmx_bbp_rfif_rx_div_load_cfg_t;

/**
 * cvmx_bbp_rfif_rx_div_status
 */
union cvmx_bbp_rfif_rx_div_status {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_div_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t rfic_ena                     : 1;  /**< RFIC enabled (in alert state) */
	uint32_t sync_late                    : 1;  /**< Sync late (Used for UE products). */
	uint32_t reserved_19_20               : 2;
	uint32_t thresh_rch                   : 1;  /**< Threshold Reached (RX/RX_div/TX) */
	uint32_t fifo_of                      : 1;  /**< FIFO overflow */
	uint32_t fifo_ur                      : 1;  /**< FIFO underrun */
	uint32_t rx_tx_sm                     : 4;  /**< RX and TX state machine status
                                                         - 13:12  FDD RX state machine status
                                                         0 : RX off
                                                         1 : RX on
                                                         - 15:14  FDD TX state machine status
                                                         0 : TX off
                                                         1 : TX on
                                                         - 15:12  TDD state machine status
                                                         0 : IDLE
                                                         1 : DDR_RX
                                                         2 : DDR_TX */
	uint32_t hab_req_sm                   : 4;  /**< HAB request manager SM
                                                         - 0: idle
                                                         - 1: wait RX DIV FIFO threshold
                                                         - 2: NA
                                                         - 3: read RX DIV FIFO
                                                         - 4: NA
                                                         - 5: wait until the cache is not empty
                                                          Others: not used */
	uint32_t reserved_0_7                 : 8;
#else
	uint32_t reserved_0_7                 : 8;
	uint32_t hab_req_sm                   : 4;
	uint32_t rx_tx_sm                     : 4;
	uint32_t fifo_ur                      : 1;
	uint32_t fifo_of                      : 1;
	uint32_t thresh_rch                   : 1;
	uint32_t reserved_19_20               : 2;
	uint32_t sync_late                    : 1;
	uint32_t rfic_ena                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_div_status_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_div_status cvmx_bbp_rfif_rx_div_status_t;

/**
 * cvmx_bbp_rfif_rx_div_transfer_size
 */
union cvmx_bbp_rfif_rx_div_transfer_size {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_div_transfer_size_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t size                         : 13; /**< Indicates the size of the DMA data transfer from the
                                                         rf_if RX DIV FIFO out via the HMI IF. */
#else
	uint32_t size                         : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_div_transfer_size_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_div_transfer_size cvmx_bbp_rfif_rx_div_transfer_size_t;

/**
 * cvmx_bbp_rfif_rx_fifo_cnt
 */
union cvmx_bbp_rfif_rx_fifo_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_fifo_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t cnt                          : 13; /**< RX FIFO fill level. This register can take values
                                                         between 0 and 2048. */
#else
	uint32_t cnt                          : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_fifo_cnt_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_fifo_cnt cvmx_bbp_rfif_rx_fifo_cnt_t;

/**
 * cvmx_bbp_rfif_rx_if_cfg
 */
union cvmx_bbp_rfif_rx_if_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_if_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t eorl                         : 1;  /**< Early or Late TX_FRAME
                                                         - 0: The TX_FRAME asserts after the tx_lead and deasserts
                                                          before the tx_lag (late).
                                                         - 1: The TX_FRAME asserts (3:0) cycles after the
                                                          TX_ON/ENABLE and deasserts (3:0) cycles after the
                                                          TX_ON/ENABLE signal (early). */
	uint32_t half_lat                     : 1;  /**< Half cycle latency
                                                         - 0: Captures I and Q on the falling and rising edge of
                                                          the clock respectively.
                                                         - 1: Captures I and Q on the rising and falling edge of
                                                          the clock respectively. */
	uint32_t cap_lat                      : 4;  /**< Enable to capture latency
                                                          The data from the RF IC starts and stops being captured
                                                          a number of cycles after the enable pulse.
                                                         - 0: Invalid
                                                         - 1: One cycle latency
                                                         - 2: Two cycles of latency
                                                         - 3: Three cycles of latency
                                                          - ...
                                                          - 15: Fifteen cycles of latency */
#else
	uint32_t cap_lat                      : 4;
	uint32_t half_lat                     : 1;
	uint32_t eorl                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_if_cfg_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_if_cfg cvmx_bbp_rfif_rx_if_cfg_t;

/**
 * cvmx_bbp_rfif_rx_lead_lag
 */
union cvmx_bbp_rfif_rx_lead_lag {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_lead_lag_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t rx_lag                       : 12; /**< Lag on the end of the window
                                                         (unsigned number of RF clock cycles) */
	uint32_t rx_lead                      : 12; /**< Lead on beginning of the window
                                                         (unsigned number of RF clock cycles) */
#else
	uint32_t rx_lead                      : 12;
	uint32_t rx_lag                       : 12;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_lead_lag_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_lead_lag cvmx_bbp_rfif_rx_lead_lag_t;

/**
 * cvmx_bbp_rfif_rx_load_cfg
 *
 * Notes:
 * This register is automatically cleared after being loaded.
 *
 */
union cvmx_bbp_rfif_rx_load_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_load_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t hidden                       : 1;  /**< *DO NOT PUT IN HRM* Hidden bit set to 1 during
                                                         synthesis(set_case_analysis) if only one destination
                                                         can be programmed at a time. In this case there is no
                                                         need to gate the VLD with the RDYs, to ease timing
                                                         closure. */
	uint32_t reserved_9_11                : 3;
	uint32_t alt_ant                      : 1;  /**< Send data alternating antenna 0 (first) and antenna 1
                                                         (second) data on the RX HMI interface when set to 1.
                                                         By default, only the data from antenna 0 is sent on
                                                         this interface. */
	uint32_t reserved_3_7                 : 5;
	uint32_t exe3                         : 1;  /**< Setting this bit to 1 indicates the RF_IF to load
                                                         and execute the programmed DMA transfer size (register
                                                         RX_TRANSFER_SIZE) from the FIFO to RACH via the HMM. */
	uint32_t exe2                         : 1;  /**< Setting this bit to 1 indicates the RF_IF to load
                                                         and execute the programmed DMA transfer size (register
                                                         RX_TRANSFER_SIZE) from the FIFO to the ULFE HAB. */
	uint32_t exe1                         : 1;  /**< Setting this bit to 1 indicates the RF_IF to load
                                                         and execute the programmed DMA transfer size (register
                                                         RX_TRANSFER_SIZE) from the FIFO to the SMEM HAB. */
#else
	uint32_t exe1                         : 1;
	uint32_t exe2                         : 1;
	uint32_t exe3                         : 1;
	uint32_t reserved_3_7                 : 5;
	uint32_t alt_ant                      : 1;
	uint32_t reserved_9_11                : 3;
	uint32_t hidden                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_load_cfg_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_load_cfg cvmx_bbp_rfif_rx_load_cfg_t;

/**
 * cvmx_bbp_rfif_rx_offset
 */
union cvmx_bbp_rfif_rx_offset {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_offset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t rx_offset                    : 20; /**< Indicates the number of RF clock cycles after the
                                                         GPS/ETH 1PPS is received before the start of the RX
                                                         frame. */
#else
	uint32_t rx_offset                    : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_offset_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_offset cvmx_bbp_rfif_rx_offset_t;

/**
 * cvmx_bbp_rfif_rx_offset_adj_scnt
 */
union cvmx_bbp_rfif_rx_offset_adj_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_offset_adj_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Indicates the RX sample count at which the 1PPS
                                                         incremental adjustments will be applied to the internal
                                                         sample counter */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_offset_adj_scnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_offset_adj_scnt cvmx_bbp_rfif_rx_offset_adj_scnt_t;

/**
 * cvmx_bbp_rfif_rx_status
 */
union cvmx_bbp_rfif_rx_status {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t rfic_ena                     : 1;  /**< RFIC enabled (in alert state) */
	uint32_t sync_late                    : 1;  /**< Sync late (Used for UE products). */
	uint32_t reserved_19_20               : 2;
	uint32_t thresh_rch                   : 1;  /**< Threshold Reached (RX/RX_div/TX) */
	uint32_t fifo_of                      : 1;  /**< FIFO overflow */
	uint32_t fifo_ur                      : 1;  /**< FIFO underrun */
	uint32_t rx_tx_sm                     : 4;  /**< RX and TX state machine status
                                                         - 13:12  FDD RX state machine status
                                                         0 : RX off
                                                         1 : RX on
                                                         - 15:14  FDD TX state machine status
                                                         0 : TX off
                                                         1 : TX on
                                                         - 15:12  TDD state machine status
                                                         0 : IDLE
                                                         1 : DDR_RX
                                                         2 : DDR_TX */
	uint32_t hab_req_sm                   : 4;  /**< HAB request manager SM
                                                         - 0: idle
                                                         - 1: wait RX FIFO threshold
                                                         - 2: NA
                                                         - 3: read RX FIFO
                                                         - 4: NA
                                                         - 5: wait until the cache is not empty
                                                          Others: not used */
	uint32_t reserved_0_7                 : 8;
#else
	uint32_t reserved_0_7                 : 8;
	uint32_t hab_req_sm                   : 4;
	uint32_t rx_tx_sm                     : 4;
	uint32_t fifo_ur                      : 1;
	uint32_t fifo_of                      : 1;
	uint32_t thresh_rch                   : 1;
	uint32_t reserved_19_20               : 2;
	uint32_t sync_late                    : 1;
	uint32_t rfic_ena                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_status_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_status cvmx_bbp_rfif_rx_status_t;

/**
 * cvmx_bbp_rfif_rx_sync_scnt
 */
union cvmx_bbp_rfif_rx_sync_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_sync_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Sample count at which the start of frame reference will
                                                         be modified as described with register 0x30. */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_sync_scnt_s   cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_sync_scnt cvmx_bbp_rfif_rx_sync_scnt_t;

/**
 * cvmx_bbp_rfif_rx_sync_value
 */
union cvmx_bbp_rfif_rx_sync_value {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_sync_value_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t val                          : 20; /**< RX Synchronization offset value. This register
                                                         indicates the sample number at which the start of frame
                                                         must be moved to. This value must be smaller than
                                                         FRAME_L, but it cannot be negative. See below how the
                                                         sample count gets updated based on registers 0x30 and
                                                         0x31 at sample count RX_SYNC_VALUE.
                                                         If RX_SYNC_SCNT >= RX_SYNC_VALUE
                                                         sample_count = RX_SYNC_SCNT ? RX_SYNC_VALUE + 1
                                                         Else
                                                         sample_count = RX_SYNC_SCNT + FRAME_L ?
                                                         RX_SYNC_VALUE + 1
                                                         Note this is not used for eNB products, only for UE
                                                         products.
                                                         Note this register is automatically cleared after the
                                                         correction is applied. */
#else
	uint32_t val                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_sync_value_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_sync_value cvmx_bbp_rfif_rx_sync_value_t;

/**
 * cvmx_bbp_rfif_rx_th
 */
union cvmx_bbp_rfif_rx_th {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_th_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t thr                          : 12; /**< FIFO level reached before granting a RX DMA request.
                                                         This RX FIFO fill level threshold can be used
                                                         in a few ways:
                                                              1- When the FIFO fill level reaches the threshold,
                                                         there is enough data in the FIFO to start the data
                                                         transfer, so it grants a DMA transfer from the RX FIFO
                                                         to the HAB's memory.
                                                              2- It can also be used to generate an interrupt to
                                                         the DSP when the FIFO threshold is reached.
                                                              3- It can be set to 1 to permit samples transfers
                                                         as soon as one sample is available. */
#else
	uint32_t thr                          : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_th_s          cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_th cvmx_bbp_rfif_rx_th_t;

/**
 * cvmx_bbp_rfif_rx_transfer_size
 */
union cvmx_bbp_rfif_rx_transfer_size {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_transfer_size_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t size                         : 13; /**< Indicates the number of IQ samples per antenna to be
                                                         transferred from the rf_if RX FIFO to the SMEM, ULFE
                                                         and/or RACH. The value should not be doubled when
                                                         alternating samples from both antennas to the SMEM,
                                                         ULFE and/or RACH. */
#else
	uint32_t size                         : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_transfer_size_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_transfer_size cvmx_bbp_rfif_rx_transfer_size_t;

/**
 * cvmx_bbp_rfif_rx_w_e#
 */
union cvmx_bbp_rfif_rx_w_ex {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_w_ex_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t end_cnt                      : 20; /**< End count for each of the 4 RX windows. The maximum
                                                         value should be FRAME_L, unless the window must stay
                                                         opened for ever. */
#else
	uint32_t end_cnt                      : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_w_ex_s        cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_w_ex cvmx_bbp_rfif_rx_w_ex_t;

/**
 * cvmx_bbp_rfif_rx_w_s#
 */
union cvmx_bbp_rfif_rx_w_sx {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_w_sx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t start_pnt                    : 20; /**< Start points for each of the 4 RX windows
                                                         Some restrictions applies to the start and end values:
                                                         1- The first RX window must always start at the sample
                                                         count 0.
                                                         2- The other start point must be greater than rx_lead,
                                                         refer to 0x008.
                                                         3- All start point values must be smaller than the
                                                         endpoints in TDD mode.
                                                         4- RX windows have priorities over TX windows in TDD
                                                         mode.
                                                         5- There must be a minimum of 7 samples between
                                                         closing a window and opening a new one. However, it is
                                                         recommended to leave a 10 samples gap. Note that this
                                                         number could increase with different RF ICs used. */
#else
	uint32_t start_pnt                    : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_w_sx_s        cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_w_sx cvmx_bbp_rfif_rx_w_sx_t;

/**
 * cvmx_bbp_rfif_rx_win_en
 */
union cvmx_bbp_rfif_rx_win_en {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_win_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t enable                       : 4;  /**< Receive windows enable (all enabled by default)
                                                         Bit 0: 1, window 1 enabled; 0, window 1 disabled;
                                                         - ...
                                                         Bit 3: 1, window 3 enabled; 0, window 3 disabled; */
#else
	uint32_t enable                       : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_win_en_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_win_en cvmx_bbp_rfif_rx_win_en_t;

/**
 * cvmx_bbp_rfif_rx_win_upd_scnt
 */
union cvmx_bbp_rfif_rx_win_upd_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_rx_win_upd_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t scnt                         : 20; /**< Receive window update sample count. This is the count
                                                         at which the following registers newly programmed value
                                                         will take effect. RX_WIN_EN(3-0), RX_W_S (19-0),
                                                         RX_W_E(19-0), NUM_RX_WIN(3-0),  FRAME_L(19-0),
                                                         RX_LEAD_LAG(23-0) */
#else
	uint32_t scnt                         : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_rx_win_upd_scnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_rx_win_upd_scnt cvmx_bbp_rfif_rx_win_upd_scnt_t;

/**
 * cvmx_bbp_rfif_sample_adj_cfg
 */
union cvmx_bbp_rfif_sample_adj_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_sample_adj_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t adj                          : 1;  /**< Indicates whether samples must be removed from the
                                                          beginning or the end of the frame.
                                                         - 1: add/remove samples from the beginning of the frame
                                                         - 0: add/remove samples from the end of the frame
                                                          (default, must be used) */
#else
	uint32_t adj                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_sample_adj_cfg_s cnf71xx;
};
typedef union cvmx_bbp_rfif_sample_adj_cfg cvmx_bbp_rfif_sample_adj_cfg_t;

/**
 * cvmx_bbp_rfif_sample_adj_error
 */
union cvmx_bbp_rfif_sample_adj_error {
	uint32_t u32;
	struct cvmx_bbp_rfif_sample_adj_error_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t offset                       : 24; /**< Count of the number of times the TX FIFO did not have
                                                         enough IQ samples to be dropped for a TX timing
                                                         adjustment.
                                                         0-7 = TX FIFO sample adjustment error
                                                         - 16:23 = TX DIV sample adjustment error */
#else
	uint32_t offset                       : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_sample_adj_error_s cnf71xx;
};
typedef union cvmx_bbp_rfif_sample_adj_error cvmx_bbp_rfif_sample_adj_error_t;

/**
 * cvmx_bbp_rfif_sample_cnt
 */
union cvmx_bbp_rfif_sample_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_sample_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Sample count modulo FRAME_L. The start of frame is
                                                         aligned with count 0. */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_sample_cnt_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_sample_cnt cvmx_bbp_rfif_sample_cnt_t;

/**
 * cvmx_bbp_rfif_skip_frm_cnt_bits
 */
union cvmx_bbp_rfif_skip_frm_cnt_bits {
	uint32_t u32;
	struct cvmx_bbp_rfif_skip_frm_cnt_bits_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t bits                         : 2;  /**< Indicates the number of sample count bits to skip, in
                                                          order to reduce the sample count update frequency and
                                                          permit a reliable clock crossing from the RF to the
                                                          HAB clock domain.
                                                         - 0: No bits are skipped
                                                          - ...
                                                         - 3: 3 bits are skipped */
#else
	uint32_t bits                         : 2;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rfif_skip_frm_cnt_bits_s cnf71xx;
};
typedef union cvmx_bbp_rfif_skip_frm_cnt_bits cvmx_bbp_rfif_skip_frm_cnt_bits_t;

/**
 * cvmx_bbp_rfif_spi_#_ll
 */
union cvmx_bbp_rfif_spi_x_ll {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_x_ll_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t num                          : 20; /**< SPI event X start sample count */
#else
	uint32_t num                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_x_ll_s       cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_x_ll cvmx_bbp_rfif_spi_x_ll_t;

/**
 * cvmx_bbp_rfif_spi_cmd_attr#
 */
union cvmx_bbp_rfif_spi_cmd_attrx {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_cmd_attrx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t slave                        : 1;  /**< Slave select (in case there are 2 ADI chips)
                                                         - 0: slave 1
                                                         - 1: slave 2 */
	uint32_t bytes                        : 1;  /**< Number of address bytes
                                                         - 0: 1 byte transfer mode
                                                         - 1: 2 bytes transfer mode */
	uint32_t gen_int                      : 1;  /**< Generate an interrupt upon the SPI event completion:
                                                         - 0: no interrupt generated  1: interrupt generated */
	uint32_t rw                           : 1;  /**< r/w: r:0 ; w:1. */
#else
	uint32_t rw                           : 1;
	uint32_t gen_int                      : 1;
	uint32_t bytes                        : 1;
	uint32_t slave                        : 1;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_cmd_attrx_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_cmd_attrx cvmx_bbp_rfif_spi_cmd_attrx_t;

/**
 * cvmx_bbp_rfif_spi_cmds#
 */
union cvmx_bbp_rfif_spi_cmdsx {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_cmdsx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t word                         : 24; /**< Spi command word. */
#else
	uint32_t word                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_cmdsx_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_cmdsx cvmx_bbp_rfif_spi_cmdsx_t;

/**
 * cvmx_bbp_rfif_spi_conf0
 */
union cvmx_bbp_rfif_spi_conf0 {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_conf0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t num_cmds3                    : 6;  /**< Number of SPI cmds to transfer for event 3 */
	uint32_t num_cmds2                    : 6;  /**< Number of SPI cmds to transfer for event 2 */
	uint32_t num_cmds1                    : 6;  /**< Number of SPI cmds to transfer for event 1 */
	uint32_t num_cmds0                    : 6;  /**< Number of SPI cmds to transfer for event 0 */
#else
	uint32_t num_cmds0                    : 6;
	uint32_t num_cmds1                    : 6;
	uint32_t num_cmds2                    : 6;
	uint32_t num_cmds3                    : 6;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_conf0_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_conf0 cvmx_bbp_rfif_spi_conf0_t;

/**
 * cvmx_bbp_rfif_spi_conf1
 */
union cvmx_bbp_rfif_spi_conf1 {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_conf1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t start3                       : 6;  /**< SPI commands start address for event 3 */
	uint32_t start2                       : 6;  /**< SPI commands start address for event 2 */
	uint32_t start1                       : 6;  /**< SPI commands start address for event 1 */
	uint32_t start0                       : 6;  /**< SPI commands start address for event 0 */
#else
	uint32_t start0                       : 6;
	uint32_t start1                       : 6;
	uint32_t start2                       : 6;
	uint32_t start3                       : 6;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_conf1_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_conf1 cvmx_bbp_rfif_spi_conf1_t;

/**
 * cvmx_bbp_rfif_spi_ctrl
 */
union cvmx_bbp_rfif_spi_ctrl {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_26_31               : 6;
	uint32_t slave_select                 : 1;  /**< Slave select
                                                         0 : Select slave 0
                                                         1 : Select slave 1 */
	uint32_t sspol_1                      : 1;  /**< Slave select 1 polarity
                                                         0 : Slave select active low
                                                         1 : Slave select active high */
	uint32_t ext_dword_cnt                : 5;  /**< Extended read/write DWORD count (master mode only)
                                                         00000 : Not supported
                                                         00001 : 1 DWORD (default)
                                                         00010 : 2 DWORD
                                                         00011 : 3 DWORD
                                                         - ...
                                                         10000 : 16 DWORD */
	uint32_t extrwen                      : 1;  /**< Extended read/write enable (master mode)
                                                         0 : Disabled
                                                         1 : Enabled */
	uint32_t rwpol3w                      : 1;  /**< SPI Read/write bit polarity in 3-wire mode
                                                         0 : Read -> 1, Write -> 0
                                                         1 : Read -> 0, Write -> 1 */
	uint32_t sdbidir                      : 1;  /**< Serial data bi-directional enable for 3-wire mode op.
                                                         0 : Disabled (4-wire mode)
                                                         1 : Enabled (3-wire mode) */
	uint32_t fss                          : 1;  /**< Force slave select
                                                         0 : Normal mode of operation
                                                         1 : Slave select forced asserted */
	uint32_t rate                         : 3;  /**< HAB clock (250Mhz) to SPI clock divider
                                                         000 : Divide by 2 (250Mhz/2)
                                                         001 : Divide by 4 (250Mhz/4)
                                                         010 : Divide by 8 (250Mhz/8)
                                                         011 : Divide by 16 (250Mhz/16)
                                                         - ...
                                                         111 : Divide by 256 (250Mhz/256) */
	uint32_t ms                           : 1;  /**< SPI mode select
                                                         0 : Slave mode
                                                         1 : Master mode, only mode supported */
	uint32_t spien                        : 1;  /**< SPI module enable
                                                         0 : Disable the SPI
                                                         1 : Enable the SPI */
	uint32_t lbc                          : 1;  /**< Loop back control
                                                         0 : Loop back disabled
                                                         1 : Loop back enabled */
	uint32_t sspol_0                      : 1;  /**< Slave select 0 polarity
                                                         0 : Slave select active low
                                                         1 : Slave select active high */
	uint32_t ssctl                        : 1;  /**< Slave waveform select
                                                         0 : SS stays low between SPI bursts
                                                         1 : SS stays pulses high between SPI bursts */
	uint32_t phase                        : 1;  /**< Clock/data phase relationship, 4 wire mode only
                                                         0 : Launch on falling and capture on rising, when POL=0
                                                         1 : Launch on rising and capture on falling, when POL=0 */
	uint32_t pol                          : 1;  /**< SPI clock polarity
                                                         0 : Straight, use with ADI RFIC
                                                         1 : Inverted */
	uint32_t bit_count                    : 5;  /**< Length of the data transfer, in bits, minus 1 */
#else
	uint32_t bit_count                    : 5;
	uint32_t pol                          : 1;
	uint32_t phase                        : 1;
	uint32_t ssctl                        : 1;
	uint32_t sspol_0                      : 1;
	uint32_t lbc                          : 1;
	uint32_t spien                        : 1;
	uint32_t ms                           : 1;
	uint32_t rate                         : 3;
	uint32_t fss                          : 1;
	uint32_t sdbidir                      : 1;
	uint32_t rwpol3w                      : 1;
	uint32_t extrwen                      : 1;
	uint32_t ext_dword_cnt                : 5;
	uint32_t sspol_1                      : 1;
	uint32_t slave_select                 : 1;
	uint32_t reserved_26_31               : 6;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_ctrl_s       cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_ctrl cvmx_bbp_rfif_spi_ctrl_t;

/**
 * cvmx_bbp_rfif_spi_din#
 */
union cvmx_bbp_rfif_spi_dinx {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_dinx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t data                         : 16; /**< Right aligned data read back from spi commands. */
#else
	uint32_t data                         : 16;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_dinx_s       cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_dinx cvmx_bbp_rfif_spi_dinx_t;

/**
 * cvmx_bbp_rfif_spi_rx_data
 */
union cvmx_bbp_rfif_spi_rx_data {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_rx_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rd_data                      : 32; /**< SPI Read Data, right aligned */
#else
	uint32_t rd_data                      : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_rx_data_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_rx_data cvmx_bbp_rfif_spi_rx_data_t;

/**
 * cvmx_bbp_rfif_spi_status
 */
union cvmx_bbp_rfif_spi_status {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t sr_state                     : 4;  /**< SPI State Machine
                                                         1 : INIT
                                                         2 : IDLE
                                                         3 : WAIT_FIFO
                                                         4 : READ_FIFO
                                                         5 : LOAD_SR
                                                         6 : SHIFT_SR
                                                         7 : WAIT_CLK
                                                         8 : WAIT_FOR_SS */
	uint32_t rx_fifo_lvl                  : 4;  /**< Level of RX FIFO */
	uint32_t tx_fifo_lvl                  : 4;  /**< Level of TX FIFO */
#else
	uint32_t tx_fifo_lvl                  : 4;
	uint32_t rx_fifo_lvl                  : 4;
	uint32_t sr_state                     : 4;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_status_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_status cvmx_bbp_rfif_spi_status_t;

/**
 * cvmx_bbp_rfif_spi_tx_data
 */
union cvmx_bbp_rfif_spi_tx_data {
	uint32_t u32;
	struct cvmx_bbp_rfif_spi_tx_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t cmd_word                     : 32; /**< SPI read or write command, left aligned */
#else
	uint32_t cmd_word                     : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_spi_tx_data_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_spi_tx_data cvmx_bbp_rfif_spi_tx_data_t;

/**
 * cvmx_bbp_rfif_timer64_cfg
 */
union cvmx_bbp_rfif_timer64_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_timer64_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t clks                         : 8;  /**< 7-0: Number of rf clock cycles per 64-bit timer
                                                         increment. Set to n for n+1 cycles. The valid range for
                                                         the register is 3 to 255. */
#else
	uint32_t clks                         : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rfif_timer64_cfg_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_timer64_cfg cvmx_bbp_rfif_timer64_cfg_t;

/**
 * cvmx_bbp_rfif_timer64_en
 *
 * Notes:
 * This is how the 64-bit timer works:
 * 1- Configuration
 *     - Write counter LSB (reg:0x1A4)
 *     - Write counter MSB (reg:0x1A8)
 *     - Write config (reg:0x1A0)
 * 2- Enable the counter
 * 3- Wait for the 1PPS
 * 4- Start incrementing the counter every n+1 rf clock cycles
 * 5- Read the MSB and LSB registers (reg:0x1AC and 0x1B0)
 * 6- There is no 64-bit snapshot mechanism. Software has to consider the
 *    32 LSB might rollover and increment the 32 MSB between the LSB and the
 *    MSB reads. You may want to use the following concatenation recipe:
 *
 * a) Read the 32 MSB (MSB1)
 * b) Read the 32 LSB
 * c) Read the 32 MSB again (MSB2)
 * d) Concatenate the 32 MSB an 32 LSB
 *      -If both 32 MSB are equal or LSB(31)=1, concatenate MSB1 and LSB
 *      -Else concatenate the MSB2 and LSB
 */
union cvmx_bbp_rfif_timer64_en {
	uint32_t u32;
	struct cvmx_bbp_rfif_timer64_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t ena                          : 1;  /**< Enable for the 64-bit rf clock based timer.
                                                         - 0: Disabled
                                                         - 1: Enabled */
#else
	uint32_t ena                          : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_timer64_en_s     cnf71xx;
};
typedef union cvmx_bbp_rfif_timer64_en cvmx_bbp_rfif_timer64_en_t;

/**
 * cvmx_bbp_rfif_tti_scnt_int#
 */
union cvmx_bbp_rfif_tti_scnt_intx {
	uint32_t u32;
	struct cvmx_bbp_rfif_tti_scnt_intx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t intr                         : 20; /**< TTI Sample Count Interrupt:
                                                         Indicates the sample count of the selected reference
                                                         counter at which to generate an interrupt. */
#else
	uint32_t intr                         : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tti_scnt_intx_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_tti_scnt_intx cvmx_bbp_rfif_tti_scnt_intx_t;

/**
 * cvmx_bbp_rfif_tti_scnt_int_clr
 */
union cvmx_bbp_rfif_tti_scnt_int_clr {
	uint32_t u32;
	struct cvmx_bbp_rfif_tti_scnt_int_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t cnt                          : 8;  /**< TTI Sample Count Interrupt Status register:
                                                         Writing 0x1 to clear the TTI_SCNT_INT_STAT(0), writing
                                                         0x2 to clear the TTI_SCNT_INT_STAT(1) and so on. */
#else
	uint32_t cnt                          : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rfif_tti_scnt_int_clr_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tti_scnt_int_clr cvmx_bbp_rfif_tti_scnt_int_clr_t;

/**
 * cvmx_bbp_rfif_tti_scnt_int_en
 */
union cvmx_bbp_rfif_tti_scnt_int_en {
	uint32_t u32;
	struct cvmx_bbp_rfif_tti_scnt_int_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t ena                          : 8;  /**< TTI Sample Counter Interrupt Enable:
                                                         Bit 0: 1  Enables TTI_SCNT_INT_0
                                                         Bit 1: 1 Enables TTI_SCNT_INT_1
                                                         - ...
                                                         Bit 7: 1  Enables TTI_SCNT_INT_7
                                                         Note these interrupts are disabled by default (=0x00). */
#else
	uint32_t ena                          : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rfif_tti_scnt_int_en_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tti_scnt_int_en cvmx_bbp_rfif_tti_scnt_int_en_t;

/**
 * cvmx_bbp_rfif_tti_scnt_int_map
 */
union cvmx_bbp_rfif_tti_scnt_int_map {
	uint32_t u32;
	struct cvmx_bbp_rfif_tti_scnt_int_map_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t map                          : 8;  /**< TTI Sample Count Interrupt Mapping to a Reference
                                                         Counter:
                                                         Indicates the reference counter the TTI Sample Count
                                                         Interrupts must be generated from. A value of 0
                                                         indicates the RX reference counter (default) and a
                                                         value of 1 indicates the TX reference counter. The
                                                         bit 0 is associated with TTI_SCNT_INT_0, the bit 1
                                                         is associated with TTI_SCNT_INT_1 and so on.
                                                         Note that This register has not effect in TDD mode,
                                                         only in FDD mode. */
#else
	uint32_t map                          : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rfif_tti_scnt_int_map_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tti_scnt_int_map cvmx_bbp_rfif_tti_scnt_int_map_t;

/**
 * cvmx_bbp_rfif_tti_scnt_int_stat
 */
union cvmx_bbp_rfif_tti_scnt_int_stat {
	uint32_t u32;
	struct cvmx_bbp_rfif_tti_scnt_int_stat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t cnt                          : 8;  /**< TTI Sample Count Interrupt Status register:
                                                         Indicates if a TTI_SCNT_INT_X occurred (1) or not (0).
                                                         The bit 0 is associated with TTI_SCNT_INT_0 and so on
                                                         incrementally. */
#else
	uint32_t cnt                          : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rfif_tti_scnt_int_stat_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tti_scnt_int_stat cvmx_bbp_rfif_tti_scnt_int_stat_t;

/**
 * cvmx_bbp_rfif_tx_correct_adj
 */
union cvmx_bbp_rfif_tx_correct_adj {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_correct_adj_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t offset                       : 4;  /**< Indicates the sample counter offset at which the tx
                                                         samples are dropped or added. This register can take
                                                         a values from 0 to 15 and should be configured as
                                                         follow:
                                                         5 : when MIN_SAMPLE_ADJ = 1
                                                         8 : when MIN_SAMPLE_ADJ = 2
                                                         9 : when MIN_SAMPLE_ADJ = 4 */
#else
	uint32_t offset                       : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_correct_adj_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_correct_adj cvmx_bbp_rfif_tx_correct_adj_t;

/**
 * cvmx_bbp_rfif_tx_div_fifo_cnt
 */
union cvmx_bbp_rfif_tx_div_fifo_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_div_fifo_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t cnt                          : 13; /**< TX DIV FIFO fill level. This register can take values
                                                         between 0 and 2560. */
#else
	uint32_t cnt                          : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_div_fifo_cnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_div_fifo_cnt cvmx_bbp_rfif_tx_div_fifo_cnt_t;

/**
 * cvmx_bbp_rfif_tx_div_gen_purp
 *
 * Notes:
 * the FLUSH an CLR register bits are auto clear.
 *
 */
union cvmx_bbp_rfif_tx_div_gen_purp {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_div_gen_purp_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t int_mask                     : 1;  /**< DSP TX interrupt mask
                                                         0 : Enables interrupts
                                                         1 : Disables interrupts, ISR polling available */
	uint32_t reserved_3_7                 : 5;
	uint32_t over_clr                     : 1;  /**< TX DIV FIFO overflow clear, set to 1 to clear */
	uint32_t under_clr                    : 1;  /**< TX DIV FIFO under run clear, set to 1 to clear */
	uint32_t fifo_flush                   : 1;  /**< TX DIV FIFO FLUSH, set to 1 to flush */
#else
	uint32_t fifo_flush                   : 1;
	uint32_t under_clr                    : 1;
	uint32_t over_clr                     : 1;
	uint32_t reserved_3_7                 : 5;
	uint32_t int_mask                     : 1;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_div_gen_purp_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_div_gen_purp cvmx_bbp_rfif_tx_div_gen_purp_t;

/**
 * cvmx_bbp_rfif_tx_div_load_cfg
 */
union cvmx_bbp_rfif_tx_div_load_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_div_load_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t load                         : 1;  /**< Indicates to load and execute the programmed DMA
                                                         transfer size (TX_DIV_TRANSFER_SIZE) via the HMI IF to
                                                         the rf_if TX DIV FIFO. */
#else
	uint32_t load                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_div_load_cfg_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_div_load_cfg cvmx_bbp_rfif_tx_div_load_cfg_t;

/**
 * cvmx_bbp_rfif_tx_div_status
 */
union cvmx_bbp_rfif_tx_div_status {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_div_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t rfic_ena                     : 1;  /**< RFIC enabled (in alert state) */
	uint32_t sync_late                    : 1;  /**< Sync late (Used for UE products). */
	uint32_t reserved_19_20               : 2;
	uint32_t thresh_rch                   : 1;  /**< Threshold Reached (RX/RX_div/TX) */
	uint32_t fifo_of                      : 1;  /**< FIFO overflow */
	uint32_t fifo_ur                      : 1;  /**< FIFO underrun */
	uint32_t rx_tx_sm                     : 4;  /**< RX and TX state machine status
                                                         - 13:12  FDD RX state machine status
                                                         0 : RX off
                                                         1 : RX on
                                                         - 15:14  FDD TX state machine status
                                                         0 : TX off
                                                         1 : TX on
                                                         - 15:12  TDD state machine status
                                                         0 : IDLE
                                                         1 : DDR_RX
                                                         2 : DDR_TX */
	uint32_t hab_req_sm                   : 4;  /**< HAB request manager SM
                                                         - 0: idle
                                                         - 1: wait TX DIV FIFO threshold
                                                         - 2: NA
                                                         - 3: write TX DIV FIFO
                                                         - 4: NA
                                                         - 5: wait until TX FIFO DIV empties
                                                          Others: not used */
	uint32_t reserved_0_7                 : 8;
#else
	uint32_t reserved_0_7                 : 8;
	uint32_t hab_req_sm                   : 4;
	uint32_t rx_tx_sm                     : 4;
	uint32_t fifo_ur                      : 1;
	uint32_t fifo_of                      : 1;
	uint32_t thresh_rch                   : 1;
	uint32_t reserved_19_20               : 2;
	uint32_t sync_late                    : 1;
	uint32_t rfic_ena                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_div_status_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_div_status cvmx_bbp_rfif_tx_div_status_t;

/**
 * cvmx_bbp_rfif_tx_div_transfer_size
 */
union cvmx_bbp_rfif_tx_div_transfer_size {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_div_transfer_size_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t size                         : 13; /**< Indicates the size of the DMA data transfer via the
                                                         HMI IF to the rf_if TX DIV FIFO. */
#else
	uint32_t size                         : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_div_transfer_size_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_div_transfer_size cvmx_bbp_rfif_tx_div_transfer_size_t;

/**
 * cvmx_bbp_rfif_tx_fifo_cnt
 */
union cvmx_bbp_rfif_tx_fifo_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_fifo_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t cnt                          : 13; /**< TX FIFO fill level. This register can take values
                                                         between 0 and 2560. */
#else
	uint32_t cnt                          : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_fifo_cnt_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_fifo_cnt cvmx_bbp_rfif_tx_fifo_cnt_t;

/**
 * cvmx_bbp_rfif_tx_gen_purp
 *
 * Notes:
 * the FLUSH and CLR register bits are auto clear.
 *
 */
union cvmx_bbp_rfif_tx_gen_purp {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_gen_purp_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t int_mask                     : 1;  /**< DSP TX interrupt mask
                                                         0 : Enables interrupts
                                                         1 : Disables interrupts, ISR polling available */
	uint32_t reserved_3_7                 : 5;
	uint32_t over_clr                     : 1;  /**< TX FIFO overflow clear, set to 1 to clear the overflow */
	uint32_t under_clr                    : 1;  /**< TX FIFO under run clear, set to 1 to clear under run */
	uint32_t fifo_flush                   : 1;  /**< TX FIFO FLUSH, set to 1 to flush */
#else
	uint32_t fifo_flush                   : 1;
	uint32_t under_clr                    : 1;
	uint32_t over_clr                     : 1;
	uint32_t reserved_3_7                 : 5;
	uint32_t int_mask                     : 1;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_gen_purp_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_gen_purp cvmx_bbp_rfif_tx_gen_purp_t;

/**
 * cvmx_bbp_rfif_tx_if_cfg
 */
union cvmx_bbp_rfif_tx_if_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_if_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t mode                         : 1;  /**< TX communication mode
                                                         - 0: TX SISO (default)
                                                         - 1: TX MIMO */
	uint32_t dis_sch                      : 1;  /**< Disabled antenna driving scheme (TX SISO/RX MIMO
                                                          feature only)
                                                         - 0: Constant 0 for debugging (default)
                                                         - 1: Same as previous cycle to minimize IO switching */
	uint32_t antenna                      : 2;  /**< Transmit on antenna A and/or B (TX SISO/RX MIMO
                                                          feature only)
                                                         - 0: Transmit on antenna A (default)
                                                         - 1: Transmit on antenna B
                                                         - 2: Transmit on A and B
                                                         - 3: Reserved */
#else
	uint32_t antenna                      : 2;
	uint32_t dis_sch                      : 1;
	uint32_t mode                         : 1;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_if_cfg_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_if_cfg cvmx_bbp_rfif_tx_if_cfg_t;

/**
 * cvmx_bbp_rfif_tx_lead_lag
 */
union cvmx_bbp_rfif_tx_lead_lag {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_lead_lag_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t tx_lag                       : 12; /**< Lag on the end of the window
                                                         (unsigned number of RF clock cycles) */
	uint32_t tx_lead                      : 12; /**< Lead on beginning of the window
                                                         (unsigned number of RF clock cycles) */
#else
	uint32_t tx_lead                      : 12;
	uint32_t tx_lag                       : 12;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_lead_lag_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_lead_lag cvmx_bbp_rfif_tx_lead_lag_t;

/**
 * cvmx_bbp_rfif_tx_load_cfg
 */
union cvmx_bbp_rfif_tx_load_cfg {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_load_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t load                         : 1;  /**< Indicates to load and execute the programmed DMA
                                                         transfer size (TX_TRANSFER_SIZE) via the HMI IF to the
                                                         rf_if TX FIFO. */
#else
	uint32_t load                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_load_cfg_s    cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_load_cfg cvmx_bbp_rfif_tx_load_cfg_t;

/**
 * cvmx_bbp_rfif_tx_offset
 */
union cvmx_bbp_rfif_tx_offset {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_offset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t tx_offset                    : 20; /**< Indicates the number of RF clock cycles after the
                                                         GPS/ETH 1PPS is received before the start of the TX
                                                         frame. */
#else
	uint32_t tx_offset                    : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_offset_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_offset cvmx_bbp_rfif_tx_offset_t;

/**
 * cvmx_bbp_rfif_tx_offset_adj_scnt
 */
union cvmx_bbp_rfif_tx_offset_adj_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_offset_adj_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Indicates the TX sample count at which the 1PPS
                                                         incremental adjustments will be applied to the internal
                                                         sample counter. */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_offset_adj_scnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_offset_adj_scnt cvmx_bbp_rfif_tx_offset_adj_scnt_t;

/**
 * cvmx_bbp_rfif_tx_sample_cnt
 */
union cvmx_bbp_rfif_tx_sample_cnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_sample_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< TX sample count modulo FRAME_L. The start of frame is
                                                         aligned with count 0. */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_sample_cnt_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_sample_cnt cvmx_bbp_rfif_tx_sample_cnt_t;

/**
 * cvmx_bbp_rfif_tx_status
 */
union cvmx_bbp_rfif_tx_status {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t rfic_ena                     : 1;  /**< RFIC enabled (in alert state) */
	uint32_t sync_late                    : 1;  /**< Sync late (Used for UE products). */
	uint32_t reserved_19_20               : 2;
	uint32_t thresh_rch                   : 1;  /**< Threshold Reached (RX/RX_div/TX) */
	uint32_t fifo_of                      : 1;  /**< FIFO overflow */
	uint32_t fifo_ur                      : 1;  /**< FIFO underrun */
	uint32_t rx_tx_sm                     : 4;  /**< RX and TX state machine status
                                                         - 13:12  FDD RX state machine status
                                                         0 : RX off
                                                         1 : RX on
                                                         - 15:14  FDD TX state machine status
                                                         0 : TX off
                                                         1 : TX on
                                                         - 15:12  TDD state machine status
                                                         0 : IDLE
                                                         1 : DDR_RX
                                                         2 : DDR_TX */
	uint32_t hab_req_sm                   : 4;  /**< HAB request manager SM
                                                         - 0: idle
                                                         - 1: wait TX FIFO threshold
                                                         - 2: NA
                                                         - 3: write TX FIFO
                                                         - 4: NA
                                                         - 5: wait until TX FIFO empties
                                                          Others: not used */
	uint32_t reserved_0_7                 : 8;
#else
	uint32_t reserved_0_7                 : 8;
	uint32_t hab_req_sm                   : 4;
	uint32_t rx_tx_sm                     : 4;
	uint32_t fifo_ur                      : 1;
	uint32_t fifo_of                      : 1;
	uint32_t thresh_rch                   : 1;
	uint32_t reserved_19_20               : 2;
	uint32_t sync_late                    : 1;
	uint32_t rfic_ena                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_status_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_status cvmx_bbp_rfif_tx_status_t;

/**
 * cvmx_bbp_rfif_tx_sync_scnt
 */
union cvmx_bbp_rfif_tx_sync_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_sync_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t cnt                          : 20; /**< Sample count at which the TX start of frame reference
                                                         will be modified as described with register 0x930. */
#else
	uint32_t cnt                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_sync_scnt_s   cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_sync_scnt cvmx_bbp_rfif_tx_sync_scnt_t;

/**
 * cvmx_bbp_rfif_tx_sync_value
 */
union cvmx_bbp_rfif_tx_sync_value {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_sync_value_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t val                          : 20; /**< Value added to the RX sample count to obtain the TX
                                                         sample count. It must be a positive value smaller then
                                                         FRAME_L. (Only used for UE, not eNB products.) */
#else
	uint32_t val                          : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_sync_value_s  cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_sync_value cvmx_bbp_rfif_tx_sync_value_t;

/**
 * cvmx_bbp_rfif_tx_th
 */
union cvmx_bbp_rfif_tx_th {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_th_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t thr                          : 12; /**< FIFO level reached before granting a TX DMA request.
                                                         This TX FIFO fill level threshold can be used
                                                         in a few ways:
                                                              1- When the FIFO fill level reaches the threshold,
                                                         there is enough data in the FIFO to start the data
                                                         transfer, so it grants a DMA transfer from the TX FIFO
                                                         to the HAB's memory.
                                                              2- It can also be used to generate an interrupt to
                                                         the DSP when the FIFO threshold is reached.
                                                              3- It can be set to FIFO_DEPTH-1 to permit samples
                                                         transfers as soon as there is room for one sample. */
#else
	uint32_t thr                          : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_th_s          cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_th cvmx_bbp_rfif_tx_th_t;

/**
 * cvmx_bbp_rfif_tx_transfer_size
 */
union cvmx_bbp_rfif_tx_transfer_size {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_transfer_size_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t size                         : 13; /**< Indicates the size of the DMA data transfer via the
                                                         HMI IF to the rf_if TX FIFO. */
#else
	uint32_t size                         : 13;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_transfer_size_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_transfer_size cvmx_bbp_rfif_tx_transfer_size_t;

/**
 * cvmx_bbp_rfif_tx_w_e#
 */
union cvmx_bbp_rfif_tx_w_ex {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_w_ex_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t end_cnt                      : 20; /**< End count for each of the 4 TX windows. The maximum
                                                         value should be FRAME_L, unless the window must stay
                                                         opened for ever. */
#else
	uint32_t end_cnt                      : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_w_ex_s        cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_w_ex cvmx_bbp_rfif_tx_w_ex_t;

/**
 * cvmx_bbp_rfif_tx_w_s#
 */
union cvmx_bbp_rfif_tx_w_sx {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_w_sx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t start_pnt                    : 20; /**< Start points for each of the 4 TX windows
                                                         Some restrictions applies to the start and end values:
                                                         1- The first TX window must always start at the sample
                                                         count 0.
                                                         2- The other start point must be greater than tx_lead
                                                         3- All start point values must be smaller than the
                                                         endpoints in TDD mode.
                                                         4- RX windows have priorities over TX windows in TDD
                                                         mode.
                                                         5- There must be a minimum of 7 samples between
                                                         closing a window and opening a new one. However, it is
                                                         recommended to leave a 10 samples gap. Note that this
                                                         number could increase with different RF ICs used. */
#else
	uint32_t start_pnt                    : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_w_sx_s        cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_w_sx cvmx_bbp_rfif_tx_w_sx_t;

/**
 * cvmx_bbp_rfif_tx_win_en
 */
union cvmx_bbp_rfif_tx_win_en {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_win_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t enable                       : 4;  /**< Transmit windows enable (all enabled by default)
                                                         Bit 0: 1, window 1 enabled; 0, window 1 disabled;
                                                         - ...
                                                         Bit 3: 1, window 3 enabled; 0, window 3 disabled; */
#else
	uint32_t enable                       : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_win_en_s      cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_win_en cvmx_bbp_rfif_tx_win_en_t;

/**
 * cvmx_bbp_rfif_tx_win_upd_scnt
 */
union cvmx_bbp_rfif_tx_win_upd_scnt {
	uint32_t u32;
	struct cvmx_bbp_rfif_tx_win_upd_scnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t scnt                         : 20; /**< TX receive window update sample count. The count
                                                         at which the following registers newly programmed value
                                                         will take effect. TX_WIN_EN(3-0), TX_W_S (19-0),
                                                         TX_W_E(19-0), NUM_TX_WIN(3-0),  FRAME_L(19-0),
                                                         TX_LEAD_LAG(23-0) */
#else
	uint32_t scnt                         : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_rfif_tx_win_upd_scnt_s cnf71xx;
};
typedef union cvmx_bbp_rfif_tx_win_upd_scnt cvmx_bbp_rfif_tx_win_upd_scnt_t;

/**
 * cvmx_bbp_rfif_wr_timer64_lsb
 */
union cvmx_bbp_rfif_wr_timer64_lsb {
	uint32_t u32;
	struct cvmx_bbp_rfif_wr_timer64_lsb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t val                          : 32; /**< 64-bit timer initial value of the 32 LSB. */
#else
	uint32_t val                          : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_wr_timer64_lsb_s cnf71xx;
};
typedef union cvmx_bbp_rfif_wr_timer64_lsb cvmx_bbp_rfif_wr_timer64_lsb_t;

/**
 * cvmx_bbp_rfif_wr_timer64_msb
 */
union cvmx_bbp_rfif_wr_timer64_msb {
	uint32_t u32;
	struct cvmx_bbp_rfif_wr_timer64_msb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t val                          : 32; /**< 64-bit timer initial value of the 32 MSB. */
#else
	uint32_t val                          : 32;
#endif
	} s;
	struct cvmx_bbp_rfif_wr_timer64_msb_s cnf71xx;
};
typedef union cvmx_bbp_rfif_wr_timer64_msb cvmx_bbp_rfif_wr_timer64_msb_t;

/**
 * cvmx_bbp_rstclk_clkenb0_clr
 */
union cvmx_bbp_rstclk_clkenb0_clr {
	uint32_t u32;
	struct cvmx_bbp_rstclk_clkenb0_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t axidma                       : 1;  /**< Clear Clock Enable to AXIDMA */
	uint32_t txseq                        : 1;  /**< Clear Clock Enable to TX Sequencer */
	uint32_t v3genc                       : 1;  /**< Clear Clock Enable to V3GENC */
	uint32_t ifftpapr                     : 1;  /**< Clear Clock Enable to IFFTPAPR */
	uint32_t lteenc                       : 1;  /**< Clear Clock Enable to LTEENC */
	uint32_t vdec                         : 1;  /**< Clear Clock Enable to VDEC */
	uint32_t turbodsp                     : 1;  /**< Clear Clock Enable to Turbo - DSP clock domain; should
                                                         clear with TURBOPHY bit 5 */
	uint32_t turbophy                     : 1;  /**< Clear Clock Enable to Turbo - PHY clock domain */
	uint32_t rx1seq                       : 1;  /**< Clear Clock Enable to RX1 Sequencer */
	uint32_t dftdmap                      : 1;  /**< Clear Clock Enable to DFTDMP */
	uint32_t rx0seq                       : 1;  /**< Clear Clock Enable to RX0 Sequencer */
	uint32_t rachfe                       : 1;  /**< Clear Clock Enable to RACH */
	uint32_t ulfe                         : 1;  /**< Clear Clock Enable to ULFE */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachfe                       : 1;
	uint32_t rx0seq                       : 1;
	uint32_t dftdmap                      : 1;
	uint32_t rx1seq                       : 1;
	uint32_t turbophy                     : 1;
	uint32_t turbodsp                     : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t v3genc                       : 1;
	uint32_t txseq                        : 1;
	uint32_t axidma                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rstclk_clkenb0_clr_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_clkenb0_clr cvmx_bbp_rstclk_clkenb0_clr_t;

/**
 * cvmx_bbp_rstclk_clkenb0_set
 */
union cvmx_bbp_rstclk_clkenb0_set {
	uint32_t u32;
	struct cvmx_bbp_rstclk_clkenb0_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t axidma                       : 1;  /**< Assert Clock Enable to AXIDMA */
	uint32_t txseq                        : 1;  /**< Assert Clock Enable to TX Sequencer */
	uint32_t v3genc                       : 1;  /**< Assert Clock Enable to V3GENC */
	uint32_t ifftpapr                     : 1;  /**< Assert Clock Enable to IFFTPAPR */
	uint32_t lteenc                       : 1;  /**< Assert Clock Enable to LTEENC */
	uint32_t vdec                         : 1;  /**< Assert Clock Enable to VDEC */
	uint32_t turbodsp                     : 1;  /**< Assert Clock Enable to Turbo - DSP clock domain; should
                                                         assert with TURBOPHY bit 5 */
	uint32_t turbophy                     : 1;  /**< Assert Clock Enable to Turbo - PHY clock domain */
	uint32_t rx1seq                       : 1;  /**< Assert Clock Enable to RX1 Sequencer */
	uint32_t dftdmap                      : 1;  /**< Assert Clock Enable to DFTDMP */
	uint32_t rx0seq                       : 1;  /**< Assert Clock Enable to RX0 Sequencer */
	uint32_t rachfe                       : 1;  /**< Assert Clock Enable to RACH */
	uint32_t ulfe                         : 1;  /**< Assert Clock Enable to ULFE */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachfe                       : 1;
	uint32_t rx0seq                       : 1;
	uint32_t dftdmap                      : 1;
	uint32_t rx1seq                       : 1;
	uint32_t turbophy                     : 1;
	uint32_t turbodsp                     : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t v3genc                       : 1;
	uint32_t txseq                        : 1;
	uint32_t axidma                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rstclk_clkenb0_set_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_clkenb0_set cvmx_bbp_rstclk_clkenb0_set_t;

/**
 * cvmx_bbp_rstclk_clkenb0_state
 */
union cvmx_bbp_rstclk_clkenb0_state {
	uint32_t u32;
	struct cvmx_bbp_rstclk_clkenb0_state_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t axidma                       : 1;  /**< AXIDMA Clock Enable status */
	uint32_t txseq                        : 1;  /**< TX Sequencer Clock Enable status */
	uint32_t v3genc                       : 1;  /**< V3GENC Clock Enable status */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR Clock Enable status */
	uint32_t lteenc                       : 1;  /**< LTEENC Clock Enable status */
	uint32_t vdec                         : 1;  /**< VDEC Clock Enable status */
	uint32_t turbodsp                     : 1;  /**< Turbo Clock Enable status - DSP clock domain */
	uint32_t turbophy                     : 1;  /**< Turbo Clock Enable status - PHY clock domain */
	uint32_t rx1seq                       : 1;  /**< RX1 Sequencer Clock Enable status */
	uint32_t dftdmap                      : 1;  /**< DFTDMP Clock Enable status */
	uint32_t rx0seq                       : 1;  /**< RX0 Sequencer Clock Enable status */
	uint32_t rachfe                       : 1;  /**< RACH Clock Enable status */
	uint32_t ulfe                         : 1;  /**< ULFE Clock Enable status */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachfe                       : 1;
	uint32_t rx0seq                       : 1;
	uint32_t dftdmap                      : 1;
	uint32_t rx1seq                       : 1;
	uint32_t turbophy                     : 1;
	uint32_t turbodsp                     : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t v3genc                       : 1;
	uint32_t txseq                        : 1;
	uint32_t axidma                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rstclk_clkenb0_state_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_clkenb0_state cvmx_bbp_rstclk_clkenb0_state_t;

/**
 * cvmx_bbp_rstclk_clkenb1_clr
 */
union cvmx_bbp_rstclk_clkenb1_clr {
	uint32_t u32;
	struct cvmx_bbp_rstclk_clkenb1_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_7_31                : 25;
	uint32_t token                        : 1;  /**< Clear Clock Enable to TOKEN */
	uint32_t reserved_3_5                 : 3;
	uint32_t rfspi                        : 1;  /**< Clear Clock Enable to RFSPI */
	uint32_t rfif_hab                     : 1;  /**< Clear Clock Enable to RFIF - PHY clock domain; should
                                                         clear when RFIF_RF bit 0 is cleared */
	uint32_t rfif_rf                      : 1;  /**< Clear Clock Enable to RFIF - RF clock domain */
#else
	uint32_t rfif_rf                      : 1;
	uint32_t rfif_hab                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t reserved_3_5                 : 3;
	uint32_t token                        : 1;
	uint32_t reserved_7_31                : 25;
#endif
	} s;
	struct cvmx_bbp_rstclk_clkenb1_clr_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_clkenb1_clr cvmx_bbp_rstclk_clkenb1_clr_t;

/**
 * cvmx_bbp_rstclk_clkenb1_set
 */
union cvmx_bbp_rstclk_clkenb1_set {
	uint32_t u32;
	struct cvmx_bbp_rstclk_clkenb1_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_7_31                : 25;
	uint32_t token                        : 1;  /**< Assert Clock Enable to TOKEN */
	uint32_t reserved_3_5                 : 3;
	uint32_t rfspi                        : 1;  /**< Assert Clock Enable to RFSPI */
	uint32_t rfif_hab                     : 1;  /**< Assert Clock Enable to RFIF - PHY clock domain; should
                                                         assert when RFIF_RF bit 0 is asserted */
	uint32_t rfif_rf                      : 1;  /**< Assert Clock Enable to RFIF - RF clock domain */
#else
	uint32_t rfif_rf                      : 1;
	uint32_t rfif_hab                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t reserved_3_5                 : 3;
	uint32_t token                        : 1;
	uint32_t reserved_7_31                : 25;
#endif
	} s;
	struct cvmx_bbp_rstclk_clkenb1_set_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_clkenb1_set cvmx_bbp_rstclk_clkenb1_set_t;

/**
 * cvmx_bbp_rstclk_clkenb1_state
 */
union cvmx_bbp_rstclk_clkenb1_state {
	uint32_t u32;
	struct cvmx_bbp_rstclk_clkenb1_state_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_7_31                : 25;
	uint32_t token                        : 1;  /**< TOKEN Clock Enable status */
	uint32_t reserved_3_5                 : 3;
	uint32_t rfspi                        : 1;  /**< RFSPI Clock Enable status */
	uint32_t rfif_hab                     : 1;  /**< RFIF Clock Enable status - PHY clock domain */
	uint32_t rfif_rf                      : 1;  /**< RFIF Clock Enable status - RF clock domain */
#else
	uint32_t rfif_rf                      : 1;
	uint32_t rfif_hab                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t reserved_3_5                 : 3;
	uint32_t token                        : 1;
	uint32_t reserved_7_31                : 25;
#endif
	} s;
	struct cvmx_bbp_rstclk_clkenb1_state_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_clkenb1_state cvmx_bbp_rstclk_clkenb1_state_t;

/**
 * cvmx_bbp_rstclk_dspstall_clr
 */
union cvmx_bbp_rstclk_dspstall_clr {
	uint32_t u32;
	struct cvmx_bbp_rstclk_dspstall_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_14_31               : 18;
	uint32_t wake_on_int_dis              : 6;  /**< Wake On Interrupt Disable.  Upon a write of 1, the
                                                         wake-on-int feature for the selected DSP will be
                                                         disabled.
                                                         8  - Disable Wake-on-Int for RX0 DSP0
                                                         9  - Disable Wake-on-Int for RX0 DSP1
                                                         10 - Disable Wake-on-Int for RX1 DSP0
                                                         11 - Disable Wake-on-Int for RX1 DSP1
                                                         12 - Disable Wake-on-Int for TX  DSP0
                                                         13 - Disable Wake-on-Int for TX  DSP1 */
	uint32_t reserved_6_7                 : 2;
	uint32_t txdsp1                       : 1;  /**< Clear TX  DSP1 Stall */
	uint32_t txdsp0                       : 1;  /**< Clear TX  DSP0 Stall */
	uint32_t rx1dsp1                      : 1;  /**< Clear RX1 DSP1 Stall */
	uint32_t rx1dsp0                      : 1;  /**< Clear RX1 DSP0 Stall */
	uint32_t rx0dsp1                      : 1;  /**< Clear RX0 DSP1 Stall */
	uint32_t rx0dsp0                      : 1;  /**< Clear RX0 DSP0 Stall */
#else
	uint32_t rx0dsp0                      : 1;
	uint32_t rx0dsp1                      : 1;
	uint32_t rx1dsp0                      : 1;
	uint32_t rx1dsp1                      : 1;
	uint32_t txdsp0                       : 1;
	uint32_t txdsp1                       : 1;
	uint32_t reserved_6_7                 : 2;
	uint32_t wake_on_int_dis              : 6;
	uint32_t reserved_14_31               : 18;
#endif
	} s;
	struct cvmx_bbp_rstclk_dspstall_clr_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_dspstall_clr cvmx_bbp_rstclk_dspstall_clr_t;

/**
 * cvmx_bbp_rstclk_dspstall_set
 */
union cvmx_bbp_rstclk_dspstall_set {
	uint32_t u32;
	struct cvmx_bbp_rstclk_dspstall_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_14_31               : 18;
	uint32_t wake_on_int_en               : 6;  /**< Wake On Interrupt Enable.  When 1, the selected DSP's
                                                         wake-on-int feature will be enabled.
                                                         8  - Enable Wake-on-Int for RX0 DSP0
                                                         9  - Enable Wake-on-Int for RX0 DSP1
                                                         10 - Enable Wake-on-Int for RX1 DSP0
                                                         11 - Enable Wake-on-Int for RX1 DSP1
                                                         12 - Enable Wake-on-Int for TX  DSP0
                                                         13 - Enable Wake-on-Int for TX  DSP1 */
	uint32_t reserved_6_7                 : 2;
	uint32_t txdsp1                       : 1;  /**< Assert TX  DSP1 Stall */
	uint32_t txdsp0                       : 1;  /**< Assert TX  DSP0 Stall */
	uint32_t rx1dsp1                      : 1;  /**< Assert RX1 DSP1 Stall */
	uint32_t rx1dsp0                      : 1;  /**< Assert RX1 DSP0 Stall */
	uint32_t rx0dsp1                      : 1;  /**< Assert RX0 DSP1 Stall */
	uint32_t rx0dsp0                      : 1;  /**< Assert RX0 DSP0 Stall */
#else
	uint32_t rx0dsp0                      : 1;
	uint32_t rx0dsp1                      : 1;
	uint32_t rx1dsp0                      : 1;
	uint32_t rx1dsp1                      : 1;
	uint32_t txdsp0                       : 1;
	uint32_t txdsp1                       : 1;
	uint32_t reserved_6_7                 : 2;
	uint32_t wake_on_int_en               : 6;
	uint32_t reserved_14_31               : 18;
#endif
	} s;
	struct cvmx_bbp_rstclk_dspstall_set_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_dspstall_set cvmx_bbp_rstclk_dspstall_set_t;

/**
 * cvmx_bbp_rstclk_dspstall_state
 */
union cvmx_bbp_rstclk_dspstall_state {
	uint32_t u32;
	struct cvmx_bbp_rstclk_dspstall_state_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_14_31               : 18;
	uint32_t wake_on_int_en               : 6;  /**< Wake On Interrupt Enable.  When 1, the DSP stall will
                                                         be removed upon an interrupt to that DSP.
                                                         8  - Enable Wake-on-Int for RX0 DSP0
                                                         9  - Enable Wake-on-Int for RX0 DSP1
                                                         10 - Enable Wake-on-Int for RX1 DSP0
                                                         11 - Enable Wake-on-Int for RX1 DSP1
                                                         12 - Enable Wake-on-Int for TX  DSP0
                                                         13 - Enable Wake-on-Int for TX  DSP1 */
	uint32_t reserved_6_7                 : 2;
	uint32_t txdsp1                       : 1;  /**< TX DSP1 Stall status */
	uint32_t txdsp0                       : 1;  /**< TX DSP0 Stall status */
	uint32_t rx1dsp1                      : 1;  /**< RX1 DSP1 Stall status */
	uint32_t rx1dsp0                      : 1;  /**< RX1 DSP0 Stall status */
	uint32_t rx0dsp1                      : 1;  /**< RX0 DSP1 Stall status */
	uint32_t rx0dsp0                      : 1;  /**< RX0 DSP0 Stall status; '1' - stall state */
#else
	uint32_t rx0dsp0                      : 1;
	uint32_t rx0dsp1                      : 1;
	uint32_t rx1dsp0                      : 1;
	uint32_t rx1dsp1                      : 1;
	uint32_t txdsp0                       : 1;
	uint32_t txdsp1                       : 1;
	uint32_t reserved_6_7                 : 2;
	uint32_t wake_on_int_en               : 6;
	uint32_t reserved_14_31               : 18;
#endif
	} s;
	struct cvmx_bbp_rstclk_dspstall_state_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_dspstall_state cvmx_bbp_rstclk_dspstall_state_t;

/**
 * cvmx_bbp_rstclk_intr0_clrmask
 */
union cvmx_bbp_rstclk_intr0_clrmask {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr0_clrmask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t clrmask                      : 32; /**< Clears mask bits */
#else
	uint32_t clrmask                      : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr0_clrmask_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr0_clrmask cvmx_bbp_rstclk_intr0_clrmask_t;

/**
 * cvmx_bbp_rstclk_intr0_mask
 */
union cvmx_bbp_rstclk_intr0_mask {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr0_mask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t mask                         : 32; /**< Mask for PHY Interrupt 0 - a '1' enables the SW or HW
                                                         interrupt */
#else
	uint32_t mask                         : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr0_mask_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr0_mask cvmx_bbp_rstclk_intr0_mask_t;

/**
 * cvmx_bbp_rstclk_intr0_setmask
 */
union cvmx_bbp_rstclk_intr0_setmask {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr0_setmask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t setmask                      : 32; /**< Sets mask bits */
#else
	uint32_t setmask                      : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr0_setmask_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr0_setmask cvmx_bbp_rstclk_intr0_setmask_t;

/**
 * cvmx_bbp_rstclk_intr0_status
 */
union cvmx_bbp_rstclk_intr0_status {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t status                       : 32; /**< PHY Interrupt 0 status based on Mask */
#else
	uint32_t status                       : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr0_status_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr0_status cvmx_bbp_rstclk_intr0_status_t;

/**
 * cvmx_bbp_rstclk_intr1_clrmask
 */
union cvmx_bbp_rstclk_intr1_clrmask {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr1_clrmask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t clrmask                      : 32; /**< Clears mask bits */
#else
	uint32_t clrmask                      : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr1_clrmask_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr1_clrmask cvmx_bbp_rstclk_intr1_clrmask_t;

/**
 * cvmx_bbp_rstclk_intr1_mask
 */
union cvmx_bbp_rstclk_intr1_mask {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr1_mask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t mask                         : 32; /**< Mask for PHY Interrupt 1 - a '1' enables the SW or HW
                                                         interrupt */
#else
	uint32_t mask                         : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr1_mask_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr1_mask cvmx_bbp_rstclk_intr1_mask_t;

/**
 * cvmx_bbp_rstclk_intr1_setmask
 */
union cvmx_bbp_rstclk_intr1_setmask {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr1_setmask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t setmask                      : 32; /**< Sets mask bits */
#else
	uint32_t setmask                      : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr1_setmask_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr1_setmask cvmx_bbp_rstclk_intr1_setmask_t;

/**
 * cvmx_bbp_rstclk_intr1_status
 */
union cvmx_bbp_rstclk_intr1_status {
	uint32_t u32;
	struct cvmx_bbp_rstclk_intr1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t status                       : 32; /**< PHY Interrupt 1 status based on Mask */
#else
	uint32_t status                       : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_intr1_status_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_intr1_status cvmx_bbp_rstclk_intr1_status_t;

/**
 * cvmx_bbp_rstclk_phy_config
 */
union cvmx_bbp_rstclk_phy_config {
	uint32_t u32;
	struct cvmx_bbp_rstclk_phy_config_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t tx_gen_perr                  : 1;  /**< TX IMEM Bad Parity Generation Enable */
	uint32_t rx1_gen_perr                 : 1;  /**< RX1 IMEM Bad Parity Generation Enable */
	uint32_t rx0_gen_perr                 : 1;  /**< RX0 IMEM Bad Parity Generation Enable - when '1' will
                                                         force bad parity during IMEM DMA loads; useful to
                                                         mark memory as being illegal until it is loaded with
                                                         real instructions */
	uint32_t tx_ipar_enb                  : 1;  /**< TX DSP Instruction Parity Enable */
	uint32_t rx1_ipar_enb                 : 1;  /**< RX1 DSP Instruction Parity Enable */
	uint32_t rx0_ipar_enb                 : 1;  /**< RX0 DSP Instruction Parity Enable - when '1' will
                                                         enable parity checking for both RX0 DSPs */
	uint32_t txsmem_initenb               : 1;  /**< TX  D/SMEM Initializtion Mode Enable */
	uint32_t tximem_initenb               : 1;  /**< TX  IMEM Initializtion Mode Enable */
	uint32_t rx1smem_initenb              : 1;  /**< RX1 D/SMEM Initializtion Mode Enable */
	uint32_t rx1imem_initenb              : 1;  /**< RX1 IMEM Initializtion Mode Enable */
	uint32_t rx0smem_initenb              : 1;  /**< RX0 D/SMEM Initializtion Mode Enable */
	uint32_t rx0imem_initenb              : 1;  /**< RX0 IMEM Initialization Mode Enable - when '1' will
                                                         enable initialization */
#else
	uint32_t rx0imem_initenb              : 1;
	uint32_t rx0smem_initenb              : 1;
	uint32_t rx1imem_initenb              : 1;
	uint32_t rx1smem_initenb              : 1;
	uint32_t tximem_initenb               : 1;
	uint32_t txsmem_initenb               : 1;
	uint32_t rx0_ipar_enb                 : 1;
	uint32_t rx1_ipar_enb                 : 1;
	uint32_t tx_ipar_enb                  : 1;
	uint32_t rx0_gen_perr                 : 1;
	uint32_t rx1_gen_perr                 : 1;
	uint32_t tx_gen_perr                  : 1;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rstclk_phy_config_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_phy_config cvmx_bbp_rstclk_phy_config_t;

/**
 * cvmx_bbp_rstclk_reset0_clr
 */
union cvmx_bbp_rstclk_reset0_clr {
	uint32_t u32;
	struct cvmx_bbp_rstclk_reset0_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t axidma                       : 1;  /**< Clear reset to AXIDMA */
	uint32_t txseq                        : 1;  /**< Clear reset to TX Sequencer */
	uint32_t v3genc                       : 1;  /**< Clear reset to V3GENC */
	uint32_t vdec                         : 1;  /**< Clear reset to VDEC */
	uint32_t ifftpapr                     : 1;  /**< Clear reset to IFFTPAPR */
	uint32_t lteenc                       : 1;  /**< Clear reset to LTEENC */
	uint32_t turbodsp                     : 1;  /**< Clear reset to Turbo - DSP clock domain; should clear
                                                         with TURBOPHY bit 5 */
	uint32_t turbophy                     : 1;  /**< Clear reset to Turbo - PHY clock domain */
	uint32_t rx1seq                       : 1;  /**< Clear reset to RX1 Sequencer */
	uint32_t dftdmap                      : 1;  /**< Clear reset to DFTDMP */
	uint32_t rx0seq                       : 1;  /**< Clear reset to RX0 Sequencer */
	uint32_t rachfe                       : 1;  /**< Clear reset to RACH */
	uint32_t ulfe                         : 1;  /**< Clear reset to ULFE */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachfe                       : 1;
	uint32_t rx0seq                       : 1;
	uint32_t dftdmap                      : 1;
	uint32_t rx1seq                       : 1;
	uint32_t turbophy                     : 1;
	uint32_t turbodsp                     : 1;
	uint32_t lteenc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t vdec                         : 1;
	uint32_t v3genc                       : 1;
	uint32_t txseq                        : 1;
	uint32_t axidma                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rstclk_reset0_clr_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_reset0_clr cvmx_bbp_rstclk_reset0_clr_t;

/**
 * cvmx_bbp_rstclk_reset0_set
 */
union cvmx_bbp_rstclk_reset0_set {
	uint32_t u32;
	struct cvmx_bbp_rstclk_reset0_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t axidma                       : 1;  /**< Assert reset to AXIDMA */
	uint32_t txseq                        : 1;  /**< Assert reset to TX Sequencer */
	uint32_t v3genc                       : 1;  /**< Assert reset to V3GENC */
	uint32_t vdec                         : 1;  /**< Assert reset to VDEC */
	uint32_t ifftpapr                     : 1;  /**< Assert reset to IFFTPAPR */
	uint32_t lteenc                       : 1;  /**< Assert reset to LTEENC */
	uint32_t turbodsp                     : 1;  /**< Assert reset to Turbo - DSP clock domain; should assert
                                                         with TURBOPHY bit 5 */
	uint32_t turbophy                     : 1;  /**< Assert reset to Turbo - PHY clock domain */
	uint32_t rx1seq                       : 1;  /**< Assert reset to RX1 Sequencer */
	uint32_t dftdmap                      : 1;  /**< Assert reset to DFTDMP */
	uint32_t rx0seq                       : 1;  /**< Assert reset to RX0 Sequencer */
	uint32_t rachfe                       : 1;  /**< Assert reset to RACH */
	uint32_t ulfe                         : 1;  /**< Assert reset to ULFE */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachfe                       : 1;
	uint32_t rx0seq                       : 1;
	uint32_t dftdmap                      : 1;
	uint32_t rx1seq                       : 1;
	uint32_t turbophy                     : 1;
	uint32_t turbodsp                     : 1;
	uint32_t lteenc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t vdec                         : 1;
	uint32_t v3genc                       : 1;
	uint32_t txseq                        : 1;
	uint32_t axidma                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rstclk_reset0_set_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_reset0_set cvmx_bbp_rstclk_reset0_set_t;

/**
 * cvmx_bbp_rstclk_reset0_state
 */
union cvmx_bbp_rstclk_reset0_state {
	uint32_t u32;
	struct cvmx_bbp_rstclk_reset0_state_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_13_31               : 19;
	uint32_t axidma                       : 1;  /**< AXIDMA Reset status */
	uint32_t txseq                        : 1;  /**< TX Sequencer Reset status */
	uint32_t v3genc                       : 1;  /**< V3GENC Reset status */
	uint32_t vdec                         : 1;  /**< VDEC Reset status */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR Reset status */
	uint32_t lteenc                       : 1;  /**< LTEENC Reset status */
	uint32_t turbodsp                     : 1;  /**< Turbo Reset status - DSP clock domain */
	uint32_t turbophy                     : 1;  /**< Turbo Reset status - PHY clock domain */
	uint32_t rx1seq                       : 1;  /**< RX1 Sequencer Reset status */
	uint32_t dftdmap                      : 1;  /**< DFTDMP Reset status */
	uint32_t rx0seq                       : 1;  /**< RX0 Sequencer Reset status */
	uint32_t rachfe                       : 1;  /**< RACH Reset status */
	uint32_t ulfe                         : 1;  /**< ULFE Reset status */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachfe                       : 1;
	uint32_t rx0seq                       : 1;
	uint32_t dftdmap                      : 1;
	uint32_t rx1seq                       : 1;
	uint32_t turbophy                     : 1;
	uint32_t turbodsp                     : 1;
	uint32_t lteenc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t vdec                         : 1;
	uint32_t v3genc                       : 1;
	uint32_t txseq                        : 1;
	uint32_t axidma                       : 1;
	uint32_t reserved_13_31               : 19;
#endif
	} s;
	struct cvmx_bbp_rstclk_reset0_state_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_reset0_state cvmx_bbp_rstclk_reset0_state_t;

/**
 * cvmx_bbp_rstclk_reset1_clr
 */
union cvmx_bbp_rstclk_reset1_clr {
	uint32_t u32;
	struct cvmx_bbp_rstclk_reset1_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t memory                       : 1;  /**< Clear reset to MEMORY */
	uint32_t token                        : 1;  /**< Clear reset to TOKEN */
	uint32_t tx_dsps                      : 1;  /**< Clear reset to TX DSPs */
	uint32_t reserved_4_4                 : 1;
	uint32_t rx0_dsps                     : 1;  /**< Clear reset to RX0 DSPs */
	uint32_t rfspi                        : 1;  /**< Clear reset to RFSPI */
	uint32_t rfif_hab                     : 1;  /**< Clear reset to RFIF - PHY clock domain; should clear
                                                         when RFIF_RF bit 0 is cleared */
	uint32_t rfif_rf                      : 1;  /**< Clear reset to RFIF - RF clock domain */
#else
	uint32_t rfif_rf                      : 1;
	uint32_t rfif_hab                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t rx0_dsps                     : 1;
	uint32_t reserved_4_4                 : 1;
	uint32_t tx_dsps                      : 1;
	uint32_t token                        : 1;
	uint32_t memory                       : 1;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rstclk_reset1_clr_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_reset1_clr cvmx_bbp_rstclk_reset1_clr_t;

/**
 * cvmx_bbp_rstclk_reset1_set
 */
union cvmx_bbp_rstclk_reset1_set {
	uint32_t u32;
	struct cvmx_bbp_rstclk_reset1_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t memory                       : 1;  /**< Assert reset to MEMORY */
	uint32_t token                        : 1;  /**< Assert reset to TOKEN */
	uint32_t tx_dsps                      : 1;  /**< Assert reset to TX DSPs */
	uint32_t reserved_4_4                 : 1;
	uint32_t rx0_dsps                     : 1;  /**< Assert reset to RX0 DSPs */
	uint32_t rfspi                        : 1;  /**< Assert reset to RFSPI */
	uint32_t rfif_hab                     : 1;  /**< Assert reset to RFIF - PHY clock domain; should assert
                                                         when RFIF_RF bit 0 is asserted */
	uint32_t rfif_rf                      : 1;  /**< Assert reset to RFIF - RF clock domain */
#else
	uint32_t rfif_rf                      : 1;
	uint32_t rfif_hab                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t rx0_dsps                     : 1;
	uint32_t reserved_4_4                 : 1;
	uint32_t tx_dsps                      : 1;
	uint32_t token                        : 1;
	uint32_t memory                       : 1;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rstclk_reset1_set_s   cnf71xx;
};
typedef union cvmx_bbp_rstclk_reset1_set cvmx_bbp_rstclk_reset1_set_t;

/**
 * cvmx_bbp_rstclk_reset1_state
 */
union cvmx_bbp_rstclk_reset1_state {
	uint32_t u32;
	struct cvmx_bbp_rstclk_reset1_state_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t memory                       : 1;  /**< Memory Reset status */
	uint32_t token                        : 1;  /**< Token Reset status */
	uint32_t tx_dsps                      : 1;  /**< TX Cluster DSP Reset status (both DSPs) */
	uint32_t reserved_4_4                 : 1;
	uint32_t rx0_dsps                     : 1;  /**< RX0 Cluster DSP Reset status (both DSPs) */
	uint32_t rfspi                        : 1;  /**< RFSPI Reset status */
	uint32_t rfif_hab                     : 1;  /**< RFIF Reset status - PHY clk domain */
	uint32_t rfif_rf                      : 1;  /**< RFIF Reset status - RF clock domain */
#else
	uint32_t rfif_rf                      : 1;
	uint32_t rfif_hab                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t rx0_dsps                     : 1;
	uint32_t reserved_4_4                 : 1;
	uint32_t tx_dsps                      : 1;
	uint32_t token                        : 1;
	uint32_t memory                       : 1;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rstclk_reset1_state_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_reset1_state cvmx_bbp_rstclk_reset1_state_t;

/**
 * cvmx_bbp_rstclk_sw_intr_clr
 */
union cvmx_bbp_rstclk_sw_intr_clr {
	uint32_t u32;
	struct cvmx_bbp_rstclk_sw_intr_clr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t sw_intr                      : 24; /**< Clear SW Interrupt */
#else
	uint32_t sw_intr                      : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rstclk_sw_intr_clr_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_sw_intr_clr cvmx_bbp_rstclk_sw_intr_clr_t;

/**
 * cvmx_bbp_rstclk_sw_intr_set
 */
union cvmx_bbp_rstclk_sw_intr_set {
	uint32_t u32;
	struct cvmx_bbp_rstclk_sw_intr_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t sw_intr                      : 24; /**< Set SW Interrupt */
#else
	uint32_t sw_intr                      : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rstclk_sw_intr_set_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_sw_intr_set cvmx_bbp_rstclk_sw_intr_set_t;

/**
 * cvmx_bbp_rstclk_sw_intr_status
 */
union cvmx_bbp_rstclk_sw_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rstclk_sw_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t timer_intr                   : 8;  /**< PHY Interrupt STatus - HW Timer Interrupts from RFIF */
	uint32_t sw_intr                      : 24; /**< PHY Interrupt Status - SW Interrupts */
#else
	uint32_t sw_intr                      : 24;
	uint32_t timer_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rstclk_sw_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rstclk_sw_intr_status cvmx_bbp_rstclk_sw_intr_status_t;

/**
 * cvmx_bbp_rstclk_timer_ctl
 */
union cvmx_bbp_rstclk_timer_ctl {
	uint32_t u32;
	struct cvmx_bbp_rstclk_timer_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_3_31                : 29;
	uint32_t enb                          : 1;  /**< Enable: '1' - Timer is enabled */
	uint32_t mode                         : 1;  /**< Timer Mode: '1' - Free running mode
                                                         '0' - Clear on frame pulse */
	uint32_t clr                          : 1;  /**< Clear counter when in Free running mode; this bit will
                                                         auto clear after being written to 1 */
#else
	uint32_t clr                          : 1;
	uint32_t mode                         : 1;
	uint32_t enb                          : 1;
	uint32_t reserved_3_31                : 29;
#endif
	} s;
	struct cvmx_bbp_rstclk_timer_ctl_s    cnf71xx;
};
typedef union cvmx_bbp_rstclk_timer_ctl cvmx_bbp_rstclk_timer_ctl_t;

/**
 * cvmx_bbp_rstclk_timer_max
 */
union cvmx_bbp_rstclk_timer_max {
	uint32_t u32;
	struct cvmx_bbp_rstclk_timer_max_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t value                        : 32; /**< Timer max count value - holds the value of the counter
                                                         from the last time it was cleared.  When cleared on
                                                         frame pulse, this value corresponds to the frame
                                                         time count. */
#else
	uint32_t value                        : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_timer_max_s    cnf71xx;
};
typedef union cvmx_bbp_rstclk_timer_max cvmx_bbp_rstclk_timer_max_t;

/**
 * cvmx_bbp_rstclk_timer_value
 */
union cvmx_bbp_rstclk_timer_value {
	uint32_t u32;
	struct cvmx_bbp_rstclk_timer_value_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t value                        : 32; /**< Timer Counter Value */
#else
	uint32_t value                        : 32;
#endif
	} s;
	struct cvmx_bbp_rstclk_timer_value_s  cnf71xx;
};
typedef union cvmx_bbp_rstclk_timer_value cvmx_bbp_rstclk_timer_value_t;

/**
 * cvmx_bbp_rstclk_version
 */
union cvmx_bbp_rstclk_version {
	uint32_t u32;
	struct cvmx_bbp_rstclk_version_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t major                        : 8;  /**< Major revision ID */
	uint32_t minor                        : 8;  /**< Minor revision ID */
#else
	uint32_t minor                        : 8;
	uint32_t major                        : 8;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_rstclk_version_s      cnf71xx;
};
typedef union cvmx_bbp_rstclk_version cvmx_bbp_rstclk_version_t;

/**
 * cvmx_bbp_rx0_bist_status0
 *
 * This is the ending set of registers for the HMM
 * it is the section that holds the individual bist result
 *
 *
 * RX0 Bist Status0  0x833800+0x60
 */
union cvmx_bbp_rx0_bist_status0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_bist_status0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rx0_trace0_bist              : 1;  /**< RX0 DSP0 Trace Ram Bist Result
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t rx0_trace1_bist              : 1;  /**< RX0 DSP1 Trace Ram Bist Result
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t reserved_0_29                : 30;
#else
	uint32_t reserved_0_29                : 30;
	uint32_t rx0_trace1_bist              : 1;
	uint32_t rx0_trace0_bist              : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_bist_status0_s    cnf71xx;
};
typedef union cvmx_bbp_rx0_bist_status0 cvmx_bbp_rx0_bist_status0_t;

/**
 * cvmx_bbp_rx0_bist_status1
 *
 * RX0 Bist Status1  0x833800+0x64
 *
 */
union cvmx_bbp_rx0_bist_status1 {
	uint32_t u32;
	struct cvmx_bbp_rx0_bist_status1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dft_bist                     : 19; /**< DFTDMP Bist Result
                                                         19 rams in DFTDMP
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t ulfe_bist0                   : 13; /**< ULFE Bist Result Set0
                                                         15 rams in ULFE
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t ulfe_bist0                   : 13;
	uint32_t dft_bist                     : 19;
#endif
	} s;
	struct cvmx_bbp_rx0_bist_status1_s    cnf71xx;
};
typedef union cvmx_bbp_rx0_bist_status1 cvmx_bbp_rx0_bist_status1_t;

/**
 * cvmx_bbp_rx0_bist_status2
 *
 * RX0 Bist Status2  0x833800+0x68
 *
 */
union cvmx_bbp_rx0_bist_status2 {
	uint32_t u32;
	struct cvmx_bbp_rx0_bist_status2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ulfe_bist1                   : 3;  /**< ULFE Bist Result Set1
                                                         15 rams in ULFE total
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t rafe_bist                    : 3;  /**< RAFE Bist Result Set1
                                                         3 rams in RAFE total
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t rx0_psm_bist                 : 1;  /**< RX0 PSM Bist Result
                                                         1 ram in RX0 PSM
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t reserved_0_24                : 25;
#else
	uint32_t reserved_0_24                : 25;
	uint32_t rx0_psm_bist                 : 1;
	uint32_t rafe_bist                    : 3;
	uint32_t ulfe_bist1                   : 3;
#endif
	} s;
	struct cvmx_bbp_rx0_bist_status2_s    cnf71xx;
};
typedef union cvmx_bbp_rx0_bist_status2 cvmx_bbp_rx0_bist_status2_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_end_addr0 cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_start_addr0 cvmx_bbp_rx0_dftdmp_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_debug_dat
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_debug_dat cvmx_bbp_rx0_dftdmp_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_debug_sel
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_debug_sel cvmx_bbp_rx0_dftdmp_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_intr_clear
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_intr_clear cvmx_bbp_rx0_dftdmp_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_intr_enb
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_intr_enb cvmx_bbp_rx0_dftdmp_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_intr_rstatus cvmx_bbp_rx0_dftdmp_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_intr_status
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_intr_status cvmx_bbp_rx0_dftdmp_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_intr_test
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_intr_test cvmx_bbp_rx0_dftdmp_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_memclr_data
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_memclr_data cvmx_bbp_rx0_dftdmp_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_mode
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_mode cvmx_bbp_rx0_dftdmp_dma_rd_mode_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_pri_mode
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_pri_mode cvmx_bbp_rx0_dftdmp_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_start_addr0
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_start_addr0 cvmx_bbp_rx0_dftdmp_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_status
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_status cvmx_bbp_rx0_dftdmp_dma_rd_status_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_xfer_mode_count cvmx_bbp_rx0_dftdmp_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_xfer_q_status cvmx_bbp_rx0_dftdmp_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_rd_xfer_start
 */
union cvmx_bbp_rx0_dftdmp_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_rd_xfer_start cvmx_bbp_rx0_dftdmp_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_end_addr0 cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_start_addr0 cvmx_bbp_rx0_dftdmp_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_debug_dat
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_debug_dat cvmx_bbp_rx0_dftdmp_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_debug_sel
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_debug_sel cvmx_bbp_rx0_dftdmp_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_intr_clear
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_intr_clear cvmx_bbp_rx0_dftdmp_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_intr_enb
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_intr_enb cvmx_bbp_rx0_dftdmp_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_intr_rstatus cvmx_bbp_rx0_dftdmp_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_intr_status
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_intr_status cvmx_bbp_rx0_dftdmp_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_intr_test
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_intr_test cvmx_bbp_rx0_dftdmp_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_memclr_data
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_memclr_data cvmx_bbp_rx0_dftdmp_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_mode
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_mode cvmx_bbp_rx0_dftdmp_dma_wr_mode_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_pri_mode
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_pri_mode cvmx_bbp_rx0_dftdmp_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_start_addr0
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_start_addr0 cvmx_bbp_rx0_dftdmp_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_status
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_status cvmx_bbp_rx0_dftdmp_dma_wr_status_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_xfer_mode_count cvmx_bbp_rx0_dftdmp_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_xfer_q_status cvmx_bbp_rx0_dftdmp_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_dftdmp_dma_wr_xfer_start
 */
union cvmx_bbp_rx0_dftdmp_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_dftdmp_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_dftdmp_dma_wr_xfer_start cvmx_bbp_rx0_dftdmp_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx0_ext_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_cbuf_end_addr0 cvmx_bbp_rx0_ext_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx0_ext_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_cbuf_start_addr0 cvmx_bbp_rx0_ext_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_debug_dat
 */
union cvmx_bbp_rx0_ext_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_debug_dat cvmx_bbp_rx0_ext_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_debug_sel
 */
union cvmx_bbp_rx0_ext_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_debug_sel cvmx_bbp_rx0_ext_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_intr_clear
 */
union cvmx_bbp_rx0_ext_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_intr_clear cvmx_bbp_rx0_ext_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_intr_enb
 */
union cvmx_bbp_rx0_ext_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_intr_enb cvmx_bbp_rx0_ext_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx0_ext_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_intr_rstatus cvmx_bbp_rx0_ext_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_intr_status
 */
union cvmx_bbp_rx0_ext_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_intr_status cvmx_bbp_rx0_ext_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_intr_test
 */
union cvmx_bbp_rx0_ext_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_intr_test cvmx_bbp_rx0_ext_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_memclr_data
 */
union cvmx_bbp_rx0_ext_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_memclr_data cvmx_bbp_rx0_ext_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_mode
 */
union cvmx_bbp_rx0_ext_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_mode cvmx_bbp_rx0_ext_dma_rd_mode_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_pri_mode
 */
union cvmx_bbp_rx0_ext_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_pri_mode cvmx_bbp_rx0_ext_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_start_addr0
 */
union cvmx_bbp_rx0_ext_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_start_addr0 cvmx_bbp_rx0_ext_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_status
 */
union cvmx_bbp_rx0_ext_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_status cvmx_bbp_rx0_ext_dma_rd_status_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx0_ext_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_xfer_mode_count cvmx_bbp_rx0_ext_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx0_ext_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_xfer_q_status cvmx_bbp_rx0_ext_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_ext_dma_rd_xfer_start
 */
union cvmx_bbp_rx0_ext_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_rd_xfer_start cvmx_bbp_rx0_ext_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx0_ext_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_cbuf_end_addr0 cvmx_bbp_rx0_ext_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx0_ext_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_cbuf_start_addr0 cvmx_bbp_rx0_ext_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_debug_dat
 */
union cvmx_bbp_rx0_ext_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_debug_dat cvmx_bbp_rx0_ext_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_debug_sel
 */
union cvmx_bbp_rx0_ext_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_debug_sel cvmx_bbp_rx0_ext_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_intr_clear
 */
union cvmx_bbp_rx0_ext_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_intr_clear cvmx_bbp_rx0_ext_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_intr_enb
 */
union cvmx_bbp_rx0_ext_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_intr_enb cvmx_bbp_rx0_ext_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx0_ext_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_intr_rstatus cvmx_bbp_rx0_ext_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_intr_status
 */
union cvmx_bbp_rx0_ext_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_intr_status cvmx_bbp_rx0_ext_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_intr_test
 */
union cvmx_bbp_rx0_ext_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_intr_test cvmx_bbp_rx0_ext_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_memclr_data
 */
union cvmx_bbp_rx0_ext_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_memclr_data cvmx_bbp_rx0_ext_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_mode
 */
union cvmx_bbp_rx0_ext_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_mode cvmx_bbp_rx0_ext_dma_wr_mode_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_pri_mode
 */
union cvmx_bbp_rx0_ext_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_pri_mode cvmx_bbp_rx0_ext_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_start_addr0
 */
union cvmx_bbp_rx0_ext_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_start_addr0 cvmx_bbp_rx0_ext_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_status
 */
union cvmx_bbp_rx0_ext_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_status cvmx_bbp_rx0_ext_dma_wr_status_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx0_ext_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_xfer_mode_count cvmx_bbp_rx0_ext_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx0_ext_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_xfer_q_status cvmx_bbp_rx0_ext_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_ext_dma_wr_xfer_start
 */
union cvmx_bbp_rx0_ext_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_ext_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_ext_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ext_dma_wr_xfer_start cvmx_bbp_rx0_ext_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx0_instr_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_cbuf_end_addr0 cvmx_bbp_rx0_instr_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx0_instr_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_cbuf_start_addr0 cvmx_bbp_rx0_instr_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_debug_dat
 */
union cvmx_bbp_rx0_instr_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_debug_dat cvmx_bbp_rx0_instr_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_debug_sel
 */
union cvmx_bbp_rx0_instr_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_debug_sel cvmx_bbp_rx0_instr_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_intr_clear
 */
union cvmx_bbp_rx0_instr_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_intr_clear cvmx_bbp_rx0_instr_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_intr_enb
 */
union cvmx_bbp_rx0_instr_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_intr_enb cvmx_bbp_rx0_instr_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx0_instr_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_intr_rstatus cvmx_bbp_rx0_instr_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_intr_status
 */
union cvmx_bbp_rx0_instr_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_intr_status cvmx_bbp_rx0_instr_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_intr_test
 */
union cvmx_bbp_rx0_instr_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_intr_test cvmx_bbp_rx0_instr_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_memclr_data
 */
union cvmx_bbp_rx0_instr_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_memclr_data cvmx_bbp_rx0_instr_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_mode
 */
union cvmx_bbp_rx0_instr_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_mode cvmx_bbp_rx0_instr_dma_wr_mode_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_pri_mode
 */
union cvmx_bbp_rx0_instr_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_pri_mode cvmx_bbp_rx0_instr_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_start_addr0
 */
union cvmx_bbp_rx0_instr_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_start_addr0 cvmx_bbp_rx0_instr_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_status
 */
union cvmx_bbp_rx0_instr_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_status cvmx_bbp_rx0_instr_dma_wr_status_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx0_instr_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_xfer_mode_count cvmx_bbp_rx0_instr_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx0_instr_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_xfer_q_status cvmx_bbp_rx0_instr_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_instr_dma_wr_xfer_start
 */
union cvmx_bbp_rx0_instr_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_instr_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_instr_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_instr_dma_wr_xfer_start cvmx_bbp_rx0_instr_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx0_int_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_cbuf_end_addr0 cvmx_bbp_rx0_int_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx0_int_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_cbuf_start_addr0 cvmx_bbp_rx0_int_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_debug_dat
 */
union cvmx_bbp_rx0_int_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_debug_dat cvmx_bbp_rx0_int_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_debug_sel
 */
union cvmx_bbp_rx0_int_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_debug_sel cvmx_bbp_rx0_int_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_intr_clear
 */
union cvmx_bbp_rx0_int_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_intr_clear cvmx_bbp_rx0_int_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_intr_enb
 */
union cvmx_bbp_rx0_int_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_intr_enb cvmx_bbp_rx0_int_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx0_int_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_intr_rstatus cvmx_bbp_rx0_int_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_intr_status
 */
union cvmx_bbp_rx0_int_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_intr_status cvmx_bbp_rx0_int_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_intr_test
 */
union cvmx_bbp_rx0_int_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_intr_test cvmx_bbp_rx0_int_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_memclr_data
 */
union cvmx_bbp_rx0_int_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_memclr_data cvmx_bbp_rx0_int_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_mode
 */
union cvmx_bbp_rx0_int_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_mode cvmx_bbp_rx0_int_dma_rd_mode_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_pri_mode
 */
union cvmx_bbp_rx0_int_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_pri_mode cvmx_bbp_rx0_int_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_start_addr0
 */
union cvmx_bbp_rx0_int_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_start_addr0 cvmx_bbp_rx0_int_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_status
 */
union cvmx_bbp_rx0_int_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_status cvmx_bbp_rx0_int_dma_rd_status_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx0_int_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_xfer_mode_count cvmx_bbp_rx0_int_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx0_int_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_xfer_q_status cvmx_bbp_rx0_int_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_int_dma_rd_xfer_start
 */
union cvmx_bbp_rx0_int_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_rd_xfer_start cvmx_bbp_rx0_int_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx0_int_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_cbuf_end_addr0 cvmx_bbp_rx0_int_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx0_int_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_cbuf_start_addr0 cvmx_bbp_rx0_int_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_debug_dat
 */
union cvmx_bbp_rx0_int_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_debug_dat cvmx_bbp_rx0_int_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_debug_sel
 */
union cvmx_bbp_rx0_int_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_debug_sel cvmx_bbp_rx0_int_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_intr_clear
 */
union cvmx_bbp_rx0_int_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_intr_clear cvmx_bbp_rx0_int_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_intr_enb
 */
union cvmx_bbp_rx0_int_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_intr_enb cvmx_bbp_rx0_int_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx0_int_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_intr_rstatus cvmx_bbp_rx0_int_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_intr_status
 */
union cvmx_bbp_rx0_int_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_intr_status cvmx_bbp_rx0_int_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_intr_test
 */
union cvmx_bbp_rx0_int_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_intr_test cvmx_bbp_rx0_int_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_memclr_data
 */
union cvmx_bbp_rx0_int_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_memclr_data cvmx_bbp_rx0_int_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_mode
 */
union cvmx_bbp_rx0_int_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_mode cvmx_bbp_rx0_int_dma_wr_mode_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_pri_mode
 */
union cvmx_bbp_rx0_int_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_pri_mode cvmx_bbp_rx0_int_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_start_addr0
 */
union cvmx_bbp_rx0_int_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_start_addr0 cvmx_bbp_rx0_int_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_status
 */
union cvmx_bbp_rx0_int_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_status cvmx_bbp_rx0_int_dma_wr_status_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx0_int_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_xfer_mode_count cvmx_bbp_rx0_int_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx0_int_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_xfer_q_status cvmx_bbp_rx0_int_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_int_dma_wr_xfer_start
 */
union cvmx_bbp_rx0_int_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_int_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_int_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_int_dma_wr_xfer_start cvmx_bbp_rx0_int_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx0_rach_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_cbuf_end_addr0 cvmx_bbp_rx0_rach_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx0_rach_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_cbuf_start_addr0 cvmx_bbp_rx0_rach_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_debug_dat
 */
union cvmx_bbp_rx0_rach_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_debug_dat cvmx_bbp_rx0_rach_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_debug_sel
 */
union cvmx_bbp_rx0_rach_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_debug_sel cvmx_bbp_rx0_rach_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_intr_clear
 */
union cvmx_bbp_rx0_rach_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_intr_clear cvmx_bbp_rx0_rach_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_intr_enb
 */
union cvmx_bbp_rx0_rach_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_intr_enb cvmx_bbp_rx0_rach_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx0_rach_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_intr_rstatus cvmx_bbp_rx0_rach_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_intr_status
 */
union cvmx_bbp_rx0_rach_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_intr_status cvmx_bbp_rx0_rach_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_intr_test
 */
union cvmx_bbp_rx0_rach_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_intr_test cvmx_bbp_rx0_rach_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_memclr_data
 */
union cvmx_bbp_rx0_rach_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_memclr_data cvmx_bbp_rx0_rach_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_mode
 */
union cvmx_bbp_rx0_rach_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_mode cvmx_bbp_rx0_rach_dma_rd_mode_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_pri_mode
 */
union cvmx_bbp_rx0_rach_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_pri_mode cvmx_bbp_rx0_rach_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_start_addr0
 */
union cvmx_bbp_rx0_rach_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_start_addr0 cvmx_bbp_rx0_rach_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_status
 */
union cvmx_bbp_rx0_rach_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_status cvmx_bbp_rx0_rach_dma_rd_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx0_rach_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_xfer_mode_count cvmx_bbp_rx0_rach_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx0_rach_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_xfer_q_status cvmx_bbp_rx0_rach_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_rd_xfer_start
 */
union cvmx_bbp_rx0_rach_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_rd_xfer_start cvmx_bbp_rx0_rach_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_cbuf_end_addr0
 */
union cvmx_bbp_rx0_rach_dma_wr_0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_cbuf_end_addr0 cvmx_bbp_rx0_rach_dma_wr_0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_cbuf_start_addr0
 */
union cvmx_bbp_rx0_rach_dma_wr_0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_cbuf_start_addr0 cvmx_bbp_rx0_rach_dma_wr_0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_debug_dat
 */
union cvmx_bbp_rx0_rach_dma_wr_0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_debug_dat cvmx_bbp_rx0_rach_dma_wr_0_debug_dat_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_debug_sel
 */
union cvmx_bbp_rx0_rach_dma_wr_0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_debug_sel cvmx_bbp_rx0_rach_dma_wr_0_debug_sel_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_intr_clear
 */
union cvmx_bbp_rx0_rach_dma_wr_0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_intr_clear cvmx_bbp_rx0_rach_dma_wr_0_intr_clear_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_intr_enb
 */
union cvmx_bbp_rx0_rach_dma_wr_0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_intr_enb cvmx_bbp_rx0_rach_dma_wr_0_intr_enb_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_intr_rstatus
 */
union cvmx_bbp_rx0_rach_dma_wr_0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_intr_rstatus cvmx_bbp_rx0_rach_dma_wr_0_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_intr_status
 */
union cvmx_bbp_rx0_rach_dma_wr_0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_intr_status cvmx_bbp_rx0_rach_dma_wr_0_intr_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_intr_test
 */
union cvmx_bbp_rx0_rach_dma_wr_0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_intr_test cvmx_bbp_rx0_rach_dma_wr_0_intr_test_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_memclr_data
 */
union cvmx_bbp_rx0_rach_dma_wr_0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_memclr_data cvmx_bbp_rx0_rach_dma_wr_0_memclr_data_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_mode
 */
union cvmx_bbp_rx0_rach_dma_wr_0_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_mode cvmx_bbp_rx0_rach_dma_wr_0_mode_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_pri_mode
 */
union cvmx_bbp_rx0_rach_dma_wr_0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_pri_mode cvmx_bbp_rx0_rach_dma_wr_0_pri_mode_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_start_addr0
 */
union cvmx_bbp_rx0_rach_dma_wr_0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_start_addr0 cvmx_bbp_rx0_rach_dma_wr_0_start_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_status
 */
union cvmx_bbp_rx0_rach_dma_wr_0_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_status cvmx_bbp_rx0_rach_dma_wr_0_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_xfer_mode_count
 */
union cvmx_bbp_rx0_rach_dma_wr_0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_xfer_mode_count cvmx_bbp_rx0_rach_dma_wr_0_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_xfer_q_status
 */
union cvmx_bbp_rx0_rach_dma_wr_0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_xfer_q_status cvmx_bbp_rx0_rach_dma_wr_0_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_0_xfer_start
 */
union cvmx_bbp_rx0_rach_dma_wr_0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_0_xfer_start cvmx_bbp_rx0_rach_dma_wr_0_xfer_start_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_cbuf_end_addr0
 */
union cvmx_bbp_rx0_rach_dma_wr_1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_cbuf_end_addr0 cvmx_bbp_rx0_rach_dma_wr_1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_cbuf_start_addr0
 */
union cvmx_bbp_rx0_rach_dma_wr_1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_cbuf_start_addr0 cvmx_bbp_rx0_rach_dma_wr_1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_debug_dat
 */
union cvmx_bbp_rx0_rach_dma_wr_1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_debug_dat cvmx_bbp_rx0_rach_dma_wr_1_debug_dat_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_debug_sel
 */
union cvmx_bbp_rx0_rach_dma_wr_1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_debug_sel cvmx_bbp_rx0_rach_dma_wr_1_debug_sel_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_intr_clear
 */
union cvmx_bbp_rx0_rach_dma_wr_1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_intr_clear cvmx_bbp_rx0_rach_dma_wr_1_intr_clear_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_intr_enb
 */
union cvmx_bbp_rx0_rach_dma_wr_1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_intr_enb cvmx_bbp_rx0_rach_dma_wr_1_intr_enb_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_intr_rstatus
 */
union cvmx_bbp_rx0_rach_dma_wr_1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_intr_rstatus cvmx_bbp_rx0_rach_dma_wr_1_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_intr_status
 */
union cvmx_bbp_rx0_rach_dma_wr_1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_intr_status cvmx_bbp_rx0_rach_dma_wr_1_intr_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_intr_test
 */
union cvmx_bbp_rx0_rach_dma_wr_1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_intr_test cvmx_bbp_rx0_rach_dma_wr_1_intr_test_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_memclr_data
 */
union cvmx_bbp_rx0_rach_dma_wr_1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_memclr_data cvmx_bbp_rx0_rach_dma_wr_1_memclr_data_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_mode
 */
union cvmx_bbp_rx0_rach_dma_wr_1_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_mode cvmx_bbp_rx0_rach_dma_wr_1_mode_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_pri_mode
 */
union cvmx_bbp_rx0_rach_dma_wr_1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_pri_mode cvmx_bbp_rx0_rach_dma_wr_1_pri_mode_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_start_addr0
 */
union cvmx_bbp_rx0_rach_dma_wr_1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_start_addr0 cvmx_bbp_rx0_rach_dma_wr_1_start_addr0_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_status
 */
union cvmx_bbp_rx0_rach_dma_wr_1_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_status cvmx_bbp_rx0_rach_dma_wr_1_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_xfer_mode_count
 */
union cvmx_bbp_rx0_rach_dma_wr_1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_xfer_mode_count cvmx_bbp_rx0_rach_dma_wr_1_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_xfer_q_status
 */
union cvmx_bbp_rx0_rach_dma_wr_1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_xfer_q_status cvmx_bbp_rx0_rach_dma_wr_1_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_rach_dma_wr_1_xfer_start
 */
union cvmx_bbp_rx0_rach_dma_wr_1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_rach_dma_wr_1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_rach_dma_wr_1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rach_dma_wr_1_xfer_start cvmx_bbp_rx0_rach_dma_wr_1_xfer_start_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_end_addr0
 *
 * Circular Buffer End Address 0/1/2/3 (r/w)
 * The Circular Buffer End Address register is a pointer that indicates the upper bound of the circular buffer.
 * If the circular buffer function is enabled and if the read/write address exceeds the Circular Buffer End Address,
 * the HMM resets the address to the Circular Buffer Start Address. This value applies to all entries in the Transfer
 * Queue. The Circular Buffer Start/End Addresses are not queued. Programmers must wait until the HMM finishes all
 * transactions.  The Start Address Setup 0 is used for a single HMM Read/Write Buffer.
 *
 * The 1/2/3 are used for the 4:1 Interleaved Buffer.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_end_addr0 cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_start_addr0
 *
 * $BBP_RX0_RFIF_DMA_WR_0_START_ADDR1 =  0x34+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_START_ADDR1 =  0x34+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_START_ADDR1 =  0x34+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_START_ADDR1 =  0x34+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_START_ADDR1 =  0x34+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_START_ADDR1 =  0x34+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_START_ADDR1 =  0x34+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_START_ADDR1 =  0x34+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_START_ADDR1 =  0x34+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_START_ADDR1 =  0x34+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_START_ADDR1 =  0x34+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_START_ADDR1 =  0x34+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_START_ADDR1 =  0x34+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_START_ADDR1 =  0x34+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_START_ADDR1 =  0x34+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR1 =  0x34+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_START_ADDR1 =  0x34+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR1 =  0x34+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR1 =  0x34+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_START_ADDR1 =  0x34+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_START_ADDR1 =  0x34+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_START_ADDR1 =  0x34+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_START_ADDR1 =  0x34+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR1 =  0x34+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR1 =  0x34+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_START_ADDR1 =  0x34+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_START_ADDR1 =  0x34+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_START_ADDR1 =  0x34+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_START_ADDR1 =  0x34+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_START_ADDR1 =  0x34+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR1 =  0x34+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR1 =  0x34+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR1 =  0x34+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR1 =  0x34+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR1 =  0x34+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR1 =  0x34+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR1 =  0x34+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR1 =  0x34+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR1 =  0x34+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR1 =  0x34+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_START_ADDR1 =  0x34+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_START_ADDR1 =  0x34+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_START_ADDR1 =  0x34+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_START_ADDR1 =  0x34+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_START_ADDR1 =  0x34+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+------------------------------
 *  <23:0>   ADDR             R/W     X      X         Transfer Start Address1                                |  $PR
 *                                                     Specifies the start address of the HMM transfer.  This
 *                                                     address is either the source address or target address
 *                                                     of the transfer depending on the HMM type.
 *                                                     This register is only valid if the HMM port is an
 *                                                     interleaved port.  This register specifies the
 *                                                     starting address of the 2nd data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  -----------------------------------------------------------------------------------------------------------------------------------
 *
 *   $BBP_RX0_RFIF_DMA_WR_0_START_ADDR2 =  0x38+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_START_ADDR2 =  0x38+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_START_ADDR2 =  0x38+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_START_ADDR2 =  0x38+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_START_ADDR2 =  0x38+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_START_ADDR2 =  0x38+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_START_ADDR2 =  0x38+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_START_ADDR2 =  0x38+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_START_ADDR2 =  0x38+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_START_ADDR2 =  0x38+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_START_ADDR2 =  0x38+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_START_ADDR2 =  0x38+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_START_ADDR2 =  0x38+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_START_ADDR2 =  0x38+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_START_ADDR2 =  0x38+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR2 =  0x38+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_START_ADDR2 =  0x38+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR2 =  0x38+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR2 =  0x38+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_START_ADDR2 =  0x38+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_START_ADDR2 =  0x38+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_START_ADDR2 =  0x38+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_START_ADDR2 =  0x38+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR2 =  0x38+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR2 =  0x38+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_START_ADDR2 =  0x38+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_START_ADDR2 =  0x38+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_START_ADDR2 =  0x38+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_START_ADDR2 =  0x38+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_START_ADDR2 =  0x38+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR2 =  0x38+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR2 =  0x38+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR2 =  0x38+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR2 =  0x38+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR2 =  0x38+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR2 =  0x38+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR2 =  0x38+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR2 =  0x38+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR2 =  0x38+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR2 =  0x38+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_START_ADDR2 =  0x38+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_START_ADDR2 =  0x38+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_START_ADDR2 =  0x38+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_START_ADDR2 =  0x38+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_START_ADDR2 =  0x38+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Transfer Start Address2                                |  $PR
 *                                                     Specifies the start address of the HMM transfer.  This
 *                                                     address is either the source address or target address
 *                                                     of the transfer depending on the HMM type.
 *                                                     This register is only valid if the HMM port is an
 *                                                     interleaved port.  This register specifies the
 *                                                     starting address of the 3rd data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   $BBP_RX0_RFIF_DMA_WR_0_START_ADDR3 =  0x3c+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_START_ADDR3 =  0x3c+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_START_ADDR3 =  0x3c+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_START_ADDR3 =  0x3c+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_START_ADDR3 =  0x3c+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_START_ADDR3 =  0x3c+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_START_ADDR3 =  0x3c+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_START_ADDR3 =  0x3c+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_START_ADDR3 =  0x3c+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_START_ADDR3 =  0x3c+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_START_ADDR3 =  0x3c+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_START_ADDR3 =  0x3c+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_START_ADDR3 =  0x3c+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_START_ADDR3 =  0x3c+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_START_ADDR3 =  0x3c+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_START_ADDR3 =  0x3c+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_START_ADDR3 =  0x3c+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_START_ADDR3 =  0x3c+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_START_ADDR3 =  0x3c+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_START_ADDR3 =  0x3c+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_START_ADDR3 =  0x3c+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_START_ADDR3 =  0x3c+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_START_ADDR3 =  0x3c+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_START_ADDR3 =  0x3c+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_START_ADDR3 =  0x3c+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_START_ADDR3 =  0x3c+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_START_ADDR3 =  0x3c+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_START_ADDR3 =  0x3c+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_START_ADDR3 =  0x3c+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_START_ADDR3 =  0x3c+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_START_ADDR3 =  0x3c+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_START_ADDR3 =  0x3c+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_START_ADDR3 =  0x3c+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_START_ADDR3 =  0x3c+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_START_ADDR3 =  0x3c+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_START_ADDR3 =  0x3c+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_START_ADDR3 =  0x3c+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_START_ADDR3 =  0x3c+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_START_ADDR3 =  0x3c+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_START_ADDR3 =  0x3c+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_START_ADDR3 =  0x3c+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_START_ADDR3 =  0x3c+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_START_ADDR3 =  0x3c+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_START_ADDR3 =  0x3c+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_START_ADDR3 =  0x3c+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Transfer Start Address3                                |  $PR
 *                                                     Specifies the start address of the HMM transfer.  This
 *                                                     address is either the source address or target address
 *                                                     of the transfer depending on the HMM type.
 *                                                     This register is only valid if the HMM port is an
 *                                                     interleaved port.  This register specifies the
 *                                                     starting address of the 4th data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 * Circular Buffer Start Address 0/1/2/3 (r/w)
 * The Circular Buffer Start Address register is a pointer that indicates the lower bound of the circular buffer.
 * If circular buffer function is enabled and if the address exceeds the Circular Buffer End Address, the HMM
 * resets the address for either DMA Reads or DMA Writes to this value. This value applies to all entries in
 * the Transfer Queue. The Circular Buffer Start/End Addresses are not queued. Programmers must wait until
 * the HMM finishes all transactions before changing this register.
 *
 * The Circular Buffer Start Address Setup 0 is used for a single HMM Read/Write Buffer. The 1/2/3 are used
 * for the 4:1 Interleaved Buffer
 *
 * Note:  There are no Interleaved HMM ports in Endor.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_start_addr0 cvmx_bbp_rx0_rfif_dma_wr_0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_debug_dat
 *
 * Debug Data
 * When enabled, this register returns the value of internal HMM signals.  This register is enabled and is selected
 * by the Debug Mode Select Register
 * The value in this register depend on the value of the Debug Select field and the type of HMM port.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_debug_dat cvmx_bbp_rx0_rfif_dma_wr_0_debug_dat_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_debug_sel
 *
 * Debug Mode Select
 * This register enables and selects the HMM debug mux.  The HMM debug mux selects a subset of signals
 * that can be read from the HMM Debug Data register.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_debug_sel cvmx_bbp_rx0_rfif_dma_wr_0_debug_sel_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_intr_clear
 *
 * HMM Interrupt Clear
 * Write 1 to clear an interrupt.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_intr_clear cvmx_bbp_rx0_rfif_dma_wr_0_intr_clear_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_intr_enb
 *
 * HMM Interrupt Enable/Mask
 * Enables the interrupts to the system.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_intr_enb cvmx_bbp_rx0_rfif_dma_wr_0_intr_enb_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_intr_rstatus
 *
 * HMM Interrupt Raw Status
 * Indicates the raw interrupt status before the mask/enable.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_intr_rstatus cvmx_bbp_rx0_rfif_dma_wr_0_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_intr_status
 *
 * HMM Interrupt Status
 * Indicates the interrupt status after the interrupt enable/mask.  When both the specific interrupt raw status and interrupt mask
 * is set, an interrupt is asserted.  This register represents the interrupt signal sento the controller.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_intr_status cvmx_bbp_rx0_rfif_dma_wr_0_intr_status_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_intr_test
 *
 * HMM Interrupt Test
 * Sets the HMM interrupt for testing.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_intr_test cvmx_bbp_rx0_rfif_dma_wr_0_intr_test_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_memclr_data
 *
 * *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR1 =  0x58+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR1 =  0x58+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR1 =  0x58+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR1 =  0x58+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR1 =  0x58+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR1 =  0x58+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR1 =  0x58+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR1 =  0x58+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR1 =  0x58+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR1 =  0x58+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR1 =  0x58+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_START_ADDR1 =  0x58+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_START_ADDR1 =  0x58+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR1 =  0x58+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR1 =  0x58+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR1 =  0x58+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR1 =  0x58+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR1 =  0x58+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR1 =  0x58+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR1 =  0x58+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR1 =  0x58+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR1 =  0x58+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR1 =  0x58+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR1 =  0x58+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR1 =  0x58+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_START_ADDR1 =  0x58+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_START_ADDR1 =  0x58+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR1 =  0x58+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR1 =  0x58+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR1 =  0x58+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR1 =  0x58+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR1 =  0x58+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR1 =  0x58+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR1 =  0x58+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR1 =  0x58+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR1 =  0x58+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR1 =  0x58+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR1 =  0x58+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR1 =  0x58+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR1 =  0x58+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_START_ADDR1 =  0x58+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_START_ADDR1 =  0x58+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_START_ADDR1 =  0x58+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_START_ADDR1 =  0x58+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR1 =  0x58+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer Start Address1                         |  $PR
 *                                                     The Circular Buffer Start Address register indicates
 *                                                     the start of the circular buffer.   If the circular
 *                                                     buffer feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 2nd data stream.
 *                                                     This register is only valid if the HMM port is an
 *                                                     interleaved port.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR1 =  0x5c+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR1 =  0x5c+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR1 =  0x5c+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR1 =  0x5c+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR1 =  0x5c+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR1 =  0x5c+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR1 =  0x5c+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR1 =  0x5c+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR1 =  0x5c+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR1 =  0x5c+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR1 =  0x5c+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR1 =  0x5c+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR1 =  0x5c+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR1 =  0x5c+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR1 =  0x5c+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR1 =  0x5c+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR1 =  0x5c+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR1 =  0x5c+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR1 =  0x5c+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_END_ADDR1 =  0x5c+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR1 =  0x5c+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer End Address1                           |  $PR
 *                                                     The Circular Buffer End Address register indicates the
 *                                                     end of the circular buffer.  If the circular buffer
 *                                                     feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 2nd data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR2 =  0x60+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR2 =  0x60+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR2 =  0x60+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR2 =  0x60+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR2 =  0x60+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR2 =  0x60+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR2 =  0x60+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR2 =  0x60+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR2 =  0x60+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR2 =  0x60+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR2 =  0x60+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_START_ADDR2 =  0x60+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_START_ADDR2 =  0x60+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR2 =  0x60+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR2 =  0x60+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR2 =  0x60+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR2 =  0x60+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR2 =  0x60+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR2 =  0x60+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR2 =  0x60+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR2 =  0x60+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR2 =  0x60+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR2 =  0x60+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR2 =  0x60+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR2 =  0x60+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_START_ADDR2 =  0x60+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_START_ADDR2 =  0x60+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR2 =  0x60+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR2 =  0x60+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR2 =  0x60+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR2 =  0x60+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR2 =  0x60+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR2 =  0x60+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR2 =  0x60+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR2 =  0x60+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR2 =  0x60+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR2 =  0x60+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR2 =  0x60+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR2 =  0x60+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR2 =  0x60+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_START_ADDR2 =  0x60+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_START_ADDR2 =  0x60+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_START_ADDR2 =  0x60+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_START_ADDR2 =  0x60+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR2 =  0x60+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer Start Address2                         |  $PR
 *                                                     The Circular Buffer Start Address register indicates
 *                                                     the start of the circular buffer.   If the circular
 *                                                     buffer feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 3rd data stream.
 *                                                     This register is only valid if the HMM port is an
 *                                                     interleaved port.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR2 =  0x64+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR2 =  0x64+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR2 =  0x64+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR2 =  0x64+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR2 =  0x64+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR2 =  0x64+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR2 =  0x64+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR2 =  0x64+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR2 =  0x64+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR2 =  0x64+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR2 =  0x64+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_END_ADDR2 =  0x64+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_END_ADDR2 =  0x64+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR2 =  0x64+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR2 =  0x64+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR2 =  0x64+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR2 =  0x64+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR2 =  0x64+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR2 =  0x64+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR2 =  0x64+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR2 =  0x64+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR2 =  0x64+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR2 =  0x64+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR2 =  0x64+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR2 =  0x64+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_END_ADDR2 =  0x64+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_END_ADDR2 =  0x64+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR2 =  0x64+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR2 =  0x64+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR2 =  0x64+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR2 =  0x64+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR2 =  0x64+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR2 =  0x64+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR2 =  0x64+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR2 =  0x64+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR2 =  0x64+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR2 =  0x64+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR2 =  0x64+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR2 =  0x64+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR2 =  0x64+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_END_ADDR2 =  0x64+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_END_ADDR2 =  0x64+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_END_ADDR2 =  0x64+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_END_ADDR2 =  0x64+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR2 =  0x64+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer End Address2                           |  $PR
 *                                                     The Circular Buffer End Address register indicates the
 *                                                     end of the circular buffer.  If the circular buffer
 *                                                     feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 3rd data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_START_ADDR3 =  0x68+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_START_ADDR3 =  0x68+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_START_ADDR3 =  0x68+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_START_ADDR3 =  0x68+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_START_ADDR3 =  0x68+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_START_ADDR3 =  0x68+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_START_ADDR3 =  0x68+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_START_ADDR3 =  0x68+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_START_ADDR3 =  0x68+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_START_ADDR3 =  0x68+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_START_ADDR3 =  0x68+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_START_ADDR3 =  0x68+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_START_ADDR3 =  0x68+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_START_ADDR3 =  0x68+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_START_ADDR3 =  0x68+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_START_ADDR3 =  0x68+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_START_ADDR3 =  0x68+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_START_ADDR3 =  0x68+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_START_ADDR3 =  0x68+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_START_ADDR3 =  0x68+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_START_ADDR3 =  0x68+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_START_ADDR3 =  0x68+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_START_ADDR3 =  0x68+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_START_ADDR3 =  0x68+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_START_ADDR3 =  0x68+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_START_ADDR3 =  0x68+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_START_ADDR3 =  0x68+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_START_ADDR3 =  0x68+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_START_ADDR3 =  0x68+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_START_ADDR3 =  0x68+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_START_ADDR3 =  0x68+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_START_ADDR3 =  0x68+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_START_ADDR3 =  0x68+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_START_ADDR3 =  0x68+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_START_ADDR3 =  0x68+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_START_ADDR3 =  0x68+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_START_ADDR3 =  0x68+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_START_ADDR3 =  0x68+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_START_ADDR3 =  0x68+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_START_ADDR3 =  0x68+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_START_ADDR3 =  0x68+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_START_ADDR3 =  0x68+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_START_ADDR3 =  0x68+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_START_ADDR3 =  0x68+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_START_ADDR3 =  0x68+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer Start Address3                         |  $PR
 *                                                     The Circular Buffer Start Address register indicates
 *                                                     the start of the circular buffer.   If the circular
 *                                                     buffer feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 4th data stream.
 *                                                     This register is only valid if the HMM port is an
 *                                                     interleaved port.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR3 =  0x6c+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR3 =  0x6c+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR3 =  0x6c+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR3 =  0x6c+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR3 =  0x6c+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR3 =  0x6c+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR3 =  0x6c+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR3 =  0x6c+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR3 =  0x6c+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR3 =  0x6c+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR3 =  0x6c+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR3 =  0x6c+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR3 =  0x6c+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR3 =  0x6c+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR3 =  0x6c+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR3 =  0x6c+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR3 =  0x6c+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR3 =  0x6c+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR3 =  0x6c+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer End Address3                           |  $PR
 *                                                     The Circular Buffer End Address register indicates the
 *                                                     end of the circular buffer.  If the circular buffer
 *                                                     feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 4th data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 *   *
 *
 *   $BBP_RX0_RFIF_DMA_WR_0_CBUF_END_ADDR3 =  0x6c+0x830000 RegType=(NCB32b)
 *   $BBP_RX0_RFIF_DMA_WR_1_CBUF_END_ADDR3 =  0x6c+0x830400 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x830800 RegType=(NCB32b)
 *   $BBP_RX0_ULFE_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x830c00 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x831000 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_0_CBUF_END_ADDR3 =  0x6c+0x831400 RegType=(NCB32b)
 *   $BBP_RX0_RACH_DMA_WR_1_CBUF_END_ADDR3 =  0x6c+0x831800 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x831C00 RegType=(NCB32b)
 *   $BBP_RX0_DFTDMP_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x832000 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x832400 RegType=(NCB32b)
 *   $BBP_RX0_EXT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x832800 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x832C00 RegType=(NCB32b)
 *   $BBP_RX0_INT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x833000 RegType=(NCB32b)
 *   $BBP_RX0_INSTR_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x833400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x850000 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_RD_HQ_CBUF_END_ADDR3 =  0x6c+0x850400 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x850800 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_SB_CBUF_END_ADDR3 =  0x6c+0x850C00 RegType=(NCB32b)
 *   $BBP_RX1_TURBODEC_DMA_WR_HQ_CBUF_END_ADDR3 =  0x6c+0x851000 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x851400 RegType=(NCB32b)
 *   $BBP_RX1_VDEC_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x851800 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x851C00 RegType=(NCB32b)
 *   $BBP_RX1_EXT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x852000 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x852400 RegType=(NCB32b)
 *   $BBP_RX1_HARQ_DMA_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x852800 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x852C00 RegType=(NCB32b)
 *   $BBP_RX1_INT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x853000 RegType=(NCB32b)
 *   $BBP_RX1_INSTR_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x853400 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_0_CBUF_END_ADDR3 =  0x6c+0x870000 RegType=(NCB32b)
 *   $BBP_TX_RFIF_DMA_RD_1_CBUF_END_ADDR3 =  0x6c+0x870400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB0_CBUF_END_ADDR3 =  0x6c+0x870800 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_RD_TB1_CBUF_END_ADDR3 =  0x6c+0x870C00 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB0_CBUF_END_ADDR3 =  0x6c+0x871000 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_TB1_CBUF_END_ADDR3 =  0x6c+0x871400 RegType=(NCB32b)
 *   $BBP_TX_LTEENC_DMA_WR_CCH_CBUF_END_ADDR3 =  0x6c+0x871800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_0_CBUF_END_ADDR3 =  0x6c+0x871C00 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_1_CBUF_END_ADDR3 =  0x6c+0x872000 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_RD_RM_CBUF_END_ADDR3 =  0x6c+0x872400 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_0_CBUF_END_ADDR3 =  0x6c+0x872800 RegType=(NCB32b)
 *   $BBP_TX_IFFTPAPR_DMA_WR_1_CBUF_END_ADDR3 =  0x6c+0x872C00 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x873000 RegType=(NCB32b)
 *   $BBP_TX_EXT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x873400 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_RD_CBUF_END_ADDR3 =  0x6c+0x873800 RegType=(NCB32b)
 *   $BBP_TX_INT_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x873C00 RegType=(NCB32b)
 *   $BBP_TX_INSTR_DMA_WR_CBUF_END_ADDR3 =  0x6c+0x874000 RegType=(NCB32b)
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *   Bit     Field            Field   Reset  Typical   Field                                                     Verif
 *   Pos     Name             Type    Value  Value     Description                                               Type
 *  ----------------------------------------------------------------------------------------------------------+---------------------------
 *  <23:0>   ADDR             R/W     X      X         Circular Buffer End Address3                           |  $PR
 *                                                     The Circular Buffer End Address register indicates the
 *                                                     end of the circular buffer.  If the circular buffer
 *                                                     feature is enable, when the transfer exceeds the
 *                                                     Circular Buffer End Address, the HMM wraps the transfer
 *                                                     address to the Circular Buffer Start address.
 *                                                     This register is for the 4th data stream.
 *  <31:24>  RSVD             RAZ     0      0         reserved.                                              |  $PR
 *  --------------------------------------------------------------------------------------------------------------------------------------
 *
 * Memory Clear Data
 * This is the 32-bit write data used in the Memory Clear Mode.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_memclr_data cvmx_bbp_rx0_rfif_dma_wr_0_memclr_data_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_mode
 *
 * HMM Mode
 * The Mode register enables/disables features of each buffer.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_mode cvmx_bbp_rx0_rfif_dma_wr_0_mode_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_pri_mode
 *
 * HMM Priority Mode
 * This register enables and sets the parameters with the HMM's priority request feature.  When enabled, the particular HMM
 * will count the number of consecutive failed memory requests.  When the count exceeds the PRIORITY_CNT value of this register,
 * the hmm channel will assert the higher priority request.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_pri_mode cvmx_bbp_rx0_rfif_dma_wr_0_pri_mode_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_start_addr0
 *
 * HMM Start Address
 * Programmers program a 24-bit address to specify the start address of the transfer. The address is byte addressed but programmers are
 * required to use block-aligned addresses. IE the lower 2 bits are ignored and should be set to zero for 32-bit HMM transfers. However,
 * transfer count are specified via block sizes.  For the native HMM ports, the block size is 64-bit data and the address should be
 * specified on 64-bit boundaries.
 * The value in this register, along with the Mode/Transfer Count, is stored to the Transfer Queue when the programmer starts a transfer
 * via store to the Transfer Start register.  The Start Address Setup 0 is used for a single HMM Read/Write Buffer.
 *
 * The 1/2/3 are used for the 4:1 Interleaved Buffer.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_start_addr0 cvmx_bbp_rx0_rfif_dma_wr_0_start_addr0_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_status
 *
 * HMM Registers
 *
 * Module Name:  RX0_RFIF_DMA_WR_0
 * Address Base: 0x830000
 * Acronym:      RX0_RFIF_DMA_WR_0
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_RFIF_DMA_WR_1
 * Address Base: 0x830400
 * Acronym:      RX0_RFIF_DMA_WR_1
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_ULFE_DMA_RD
 * Address Base: 0x830800
 * Acronym:      RX0_ULFE_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX0_ULFE_DMA_WR
 * Address Base: 0x830c00
 * Acronym:      RX0_ULFE_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_RACH_DMA_RD
 * Address Base: 0x831000
 * Acronym:      RX0_RACH_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX0_RACH_DMA_WR_0
 * Address Base: 0x831400
 * Acronym:      RX0_RACH_DMA_WR_0
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_RACH_DMA_WR_1
 * Address Base: 0x831800
 * Acronym:      RX0_RACH_DMA_WR_1
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_DFTDMP_DMA_RD
 * Address Base: 0x831C00
 * Acronym:      RX0_DFTDMP_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX0_DFTDMP_DMA_WR
 * Address Base: 0x832000
 * Acronym:      RX0_DFTDMP_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_EXT_DMA_RD
 * Address Base: 0x832400
 * Acronym:      RX0_EXT_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX0_EXT_DMA_WR
 * Address Base: 0x832800
 * Acronym:      RX0_EXT_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_INT_DMA_RD
 * Address Base: 0x832C00
 * Acronym:      RX0_INT_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX0_INT_DMA_WR
 * Address Base: 0x833000
 * Acronym:      RX0_INT_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX0_INSTR_DMA_WR
 * Address Base: 0x833400
 * Acronym:      RX0_INSTR_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_TURBODEC_DMA_RD
 * Address Base: 0x850000
 * Acronym:      RX1_TURBODEC_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX1_TURBODEC_DMA_RD_HQ
 * Address Base: 0x850400
 * Acronym:      RX1_TURBODEC_DMA_RD_HQ
 * HMM TYPE:     Read
 *
 * Module Name:  RX1_TURBODEC_DMA_WR
 * Address Base: 0x850800
 * Acronym:      RX1_TURBODEC_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_TURBODEC_DMA_WR_SB
 * Address Base: 0x850C00
 * Acronym:      RX1_TURBODEC_DMA_WR_SB
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_TURBODEC_DMA_WR_HQ
 * Address Base: 0x851000
 * Acronym:      RX1_TURBODEC_DMA_WR_HQ
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_VDEC_DMA_RD
 * Address Base: 0x851400
 * Acronym:      RX1_VDEC_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX1_VDEC_DMA_WR
 * Address Base: 0x851800
 * Acronym:      RX1_VDEC_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_EXT_DMA_RD
 * Address Base: 0x851C00
 * Acronym:      RX1_EXT_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX1_EXT_DMA_WR
 * Address Base: 0x852000
 * Acronym:      RX1_EXT_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_HARQ_DMA_DMA_RD
 * Address Base: 0x852400
 * Acronym:      RX1_HARQ_DMA_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX1_HARQ_DMA_DMA_WR
 * Address Base: 0x852800
 * Acronym:      RX1_HARQ_DMA_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_INT_DMA_RD
 * Address Base: 0x852C00
 * Acronym:      RX1_INT_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  RX1_INT_DMA_WR
 * Address Base: 0x853000
 * Acronym:      RX1_INT_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  RX1_INSTR_DMA_WR
 * Address Base: 0x853400
 * Acronym:      RX1_INSTR_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  TX_RFIF_DMA_RD_0
 * Address Base: 0x870000
 * Acronym:      TX_RFIF_DMA_RD_0
 * HMM TYPE:     Read
 *
 * Module Name:  TX_RFIF_DMA_RD_1
 * Address Base: 0x870400
 * Acronym:      TX_RFIF_DMA_RD_1
 * HMM TYPE:     Read
 *
 * Module Name:  TX_LTEENC_DMA_RD_TB0
 * Address Base: 0x870800
 * Acronym:      TX_LTEENC_DMA_RD_TB0
 * HMM TYPE:     Read
 *
 * Module Name:  TX_LTEENC_DMA_RD_TB1
 * Address Base: 0x870C00
 * Acronym:      TX_LTEENC_DMA_RD_TB1
 * HMM TYPE:     Read
 *
 * Module Name:  TX_LTEENC_DMA_WR_TB0
 * Address Base: 0x871000
 * Acronym:      TX_LTEENC_DMA_WR_TB0
 * HMM TYPE:     Write
 *
 * Module Name:  TX_LTEENC_DMA_WR_TB1
 * Address Base: 0x871400
 * Acronym:      TX_LTEENC_DMA_WR_TB1
 * HMM TYPE:     Write
 *
 * Module Name:  TX_LTEENC_DMA_WR_CCH
 * Address Base: 0x871800
 * Acronym:      TX_LTEENC_DMA_WR_CCH
 * HMM TYPE:     Write
 *
 * Module Name:  TX_IFFTPAPR_DMA_RD_0
 * Address Base: 0x871C00
 * Acronym:      TX_IFFTPAPR_DMA_RD_0
 * HMM TYPE:     Read
 *
 * Module Name:  TX_IFFTPAPR_DMA_RD_1
 * Address Base: 0x872000
 * Acronym:      TX_IFFTPAPR_DMA_RD_1
 * HMM TYPE:     Read
 *
 * Module Name:  TX_IFFTPAPR_DMA_RD_RM
 * Address Base: 0x872400
 * Acronym:      TX_IFFTPAPR_DMA_RD_RM
 * HMM TYPE:     Read
 *
 * Module Name:  TX_IFFTPAPR_DMA_WR_0
 * Address Base: 0x872800
 * Acronym:      TX_IFFTPAPR_DMA_WR_0
 * HMM TYPE:     Write
 *
 * Module Name:  TX_IFFTPAPR_DMA_WR_1
 * Address Base: 0x872C00
 * Acronym:      TX_IFFTPAPR_DMA_WR_1
 * HMM TYPE:     Write
 *
 * Module Name:  TX_EXT_DMA_RD
 * Address Base: 0x873000
 * Acronym:      TX_EXT_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  TX_EXT_DMA_WR
 * Address Base: 0x873400
 * Acronym:      TX_EXT_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  TX_INT_DMA_RD
 * Address Base: 0x873800
 * Acronym:      TX_INT_DMA_RD
 * HMM TYPE:     Read
 *
 * Module Name:  TX_INT_DMA_WR
 * Address Base: 0x873C00
 * Acronym:      TX_INT_DMA_WR
 * HMM TYPE:     Write
 *
 * Module Name:  TX_INSTR_DMA_WR
 * Address Base: 0x874000
 * Acronym:      TX_INSTR_DMA_WR
 * HMM TYPE:     Write
 *
 *
 * HMM Status Register
 * The Status register is a read only register that returns status information about the particular HMM buffer.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_status cvmx_bbp_rx0_rfif_dma_wr_0_status_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_xfer_mode_count
 *
 * HMM Transfer Mode and Count
 * Programmers set the following info per transfer:
 *   Transfer Done Interrupt
 *   Slice Mode
 *   Circular Buffer Mode
 *   Transfer Count
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_xfer_mode_count cvmx_bbp_rx0_rfif_dma_wr_0_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_xfer_q_status
 *
 * HMM Transfer Queue Status
 * Indicates the number of free spaces in the transfer queue.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_xfer_q_status cvmx_bbp_rx0_rfif_dma_wr_0_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_0_xfer_start
 *
 * HMM Transfer Start
 * After setting up the Start Address and Mode/Transfer Count Setup registers, programmers store 1 to this addres to push the
 * address/count pair onto the transfer queue.  If there is space in the queue, the HMM starts the transfer.  If there is no space,
 * the transfer is lost.
 */
union cvmx_bbp_rx0_rfif_dma_wr_0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_0_xfer_start cvmx_bbp_rx0_rfif_dma_wr_0_xfer_start_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_end_addr0
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_end_addr0 cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_start_addr0
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_start_addr0 cvmx_bbp_rx0_rfif_dma_wr_1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_debug_dat
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_debug_dat cvmx_bbp_rx0_rfif_dma_wr_1_debug_dat_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_debug_sel
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_debug_sel cvmx_bbp_rx0_rfif_dma_wr_1_debug_sel_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_intr_clear
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_intr_clear cvmx_bbp_rx0_rfif_dma_wr_1_intr_clear_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_intr_enb
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_intr_enb cvmx_bbp_rx0_rfif_dma_wr_1_intr_enb_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_intr_rstatus
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_intr_rstatus cvmx_bbp_rx0_rfif_dma_wr_1_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_intr_status
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_intr_status cvmx_bbp_rx0_rfif_dma_wr_1_intr_status_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_intr_test
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_intr_test cvmx_bbp_rx0_rfif_dma_wr_1_intr_test_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_memclr_data
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_memclr_data cvmx_bbp_rx0_rfif_dma_wr_1_memclr_data_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_mode
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_mode cvmx_bbp_rx0_rfif_dma_wr_1_mode_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_pri_mode
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_pri_mode cvmx_bbp_rx0_rfif_dma_wr_1_pri_mode_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_start_addr0
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_start_addr0 cvmx_bbp_rx0_rfif_dma_wr_1_start_addr0_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_status
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_status cvmx_bbp_rx0_rfif_dma_wr_1_status_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_xfer_mode_count
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_xfer_mode_count cvmx_bbp_rx0_rfif_dma_wr_1_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_xfer_q_status
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_xfer_q_status cvmx_bbp_rx0_rfif_dma_wr_1_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_rfif_dma_wr_1_xfer_start
 */
union cvmx_bbp_rx0_rfif_dma_wr_1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_rfif_dma_wr_1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_rfif_dma_wr_1_xfer_start cvmx_bbp_rx0_rfif_dma_wr_1_xfer_start_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx0_ulfe_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_cbuf_end_addr0 cvmx_bbp_rx0_ulfe_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx0_ulfe_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_cbuf_start_addr0 cvmx_bbp_rx0_ulfe_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_debug_dat
 */
union cvmx_bbp_rx0_ulfe_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_debug_dat cvmx_bbp_rx0_ulfe_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_debug_sel
 */
union cvmx_bbp_rx0_ulfe_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_debug_sel cvmx_bbp_rx0_ulfe_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_intr_clear
 */
union cvmx_bbp_rx0_ulfe_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_intr_clear cvmx_bbp_rx0_ulfe_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_intr_enb
 */
union cvmx_bbp_rx0_ulfe_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_intr_enb cvmx_bbp_rx0_ulfe_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx0_ulfe_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_intr_rstatus cvmx_bbp_rx0_ulfe_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_intr_status
 */
union cvmx_bbp_rx0_ulfe_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_intr_status cvmx_bbp_rx0_ulfe_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_intr_test
 */
union cvmx_bbp_rx0_ulfe_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_intr_test cvmx_bbp_rx0_ulfe_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_memclr_data
 */
union cvmx_bbp_rx0_ulfe_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_memclr_data cvmx_bbp_rx0_ulfe_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_mode
 */
union cvmx_bbp_rx0_ulfe_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_mode cvmx_bbp_rx0_ulfe_dma_rd_mode_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_pri_mode
 */
union cvmx_bbp_rx0_ulfe_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_pri_mode cvmx_bbp_rx0_ulfe_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_start_addr0
 */
union cvmx_bbp_rx0_ulfe_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_start_addr0 cvmx_bbp_rx0_ulfe_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_status
 */
union cvmx_bbp_rx0_ulfe_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_status cvmx_bbp_rx0_ulfe_dma_rd_status_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx0_ulfe_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_xfer_mode_count cvmx_bbp_rx0_ulfe_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx0_ulfe_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_xfer_q_status cvmx_bbp_rx0_ulfe_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_rd_xfer_start
 */
union cvmx_bbp_rx0_ulfe_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_rd_xfer_start cvmx_bbp_rx0_ulfe_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx0_ulfe_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_cbuf_end_addr0 cvmx_bbp_rx0_ulfe_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx0_ulfe_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_cbuf_start_addr0 cvmx_bbp_rx0_ulfe_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_debug_dat
 */
union cvmx_bbp_rx0_ulfe_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_debug_dat cvmx_bbp_rx0_ulfe_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_debug_sel
 */
union cvmx_bbp_rx0_ulfe_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_debug_sel cvmx_bbp_rx0_ulfe_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_intr_clear
 */
union cvmx_bbp_rx0_ulfe_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_intr_clear cvmx_bbp_rx0_ulfe_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_intr_enb
 */
union cvmx_bbp_rx0_ulfe_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_intr_enb cvmx_bbp_rx0_ulfe_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx0_ulfe_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_intr_rstatus cvmx_bbp_rx0_ulfe_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_intr_status
 */
union cvmx_bbp_rx0_ulfe_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_intr_status cvmx_bbp_rx0_ulfe_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_intr_test
 */
union cvmx_bbp_rx0_ulfe_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_intr_test cvmx_bbp_rx0_ulfe_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_memclr_data
 */
union cvmx_bbp_rx0_ulfe_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_memclr_data cvmx_bbp_rx0_ulfe_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_mode
 */
union cvmx_bbp_rx0_ulfe_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_mode cvmx_bbp_rx0_ulfe_dma_wr_mode_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_pri_mode
 */
union cvmx_bbp_rx0_ulfe_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_pri_mode cvmx_bbp_rx0_ulfe_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_start_addr0
 */
union cvmx_bbp_rx0_ulfe_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_start_addr0 cvmx_bbp_rx0_ulfe_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_status
 */
union cvmx_bbp_rx0_ulfe_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_status cvmx_bbp_rx0_ulfe_dma_wr_status_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx0_ulfe_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_xfer_mode_count cvmx_bbp_rx0_ulfe_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx0_ulfe_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_xfer_q_status cvmx_bbp_rx0_ulfe_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx0_ulfe_dma_wr_xfer_start
 */
union cvmx_bbp_rx0_ulfe_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx0_ulfe_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0_ulfe_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx0_ulfe_dma_wr_xfer_start cvmx_bbp_rx0_ulfe_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx0int_cntl_hi#
 *
 * RX0INT_CNTL_HI - Interrupt Enable HI
 *
 */
union cvmx_bbp_rx0int_cntl_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_cntl_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enab                         : 1;  /**< Interrupt Enable */
#else
	uint32_t enab                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0int_cntl_hix_s     cnf71xx;
};
typedef union cvmx_bbp_rx0int_cntl_hix cvmx_bbp_rx0int_cntl_hix_t;

/**
 * cvmx_bbp_rx0int_cntl_lo#
 *
 * RX0INT_CNTL_LO - Interrupt Enable LO
 *
 */
union cvmx_bbp_rx0int_cntl_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_cntl_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enab                         : 1;  /**< Interrupt Enable */
#else
	uint32_t enab                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0int_cntl_lox_s     cnf71xx;
};
typedef union cvmx_bbp_rx0int_cntl_lox cvmx_bbp_rx0int_cntl_lox_t;

/**
 * cvmx_bbp_rx0int_index_hi#
 *
 * RX0INT_INDEX_HI - Overall Index HI
 *
 */
union cvmx_bbp_rx0int_index_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_index_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t index                        : 9;  /**< Overall Interrup Index */
#else
	uint32_t index                        : 9;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rx0int_index_hix_s    cnf71xx;
};
typedef union cvmx_bbp_rx0int_index_hix cvmx_bbp_rx0int_index_hix_t;

/**
 * cvmx_bbp_rx0int_index_lo#
 *
 * RX0INT_INDEX_LO - Overall Index LO
 *
 */
union cvmx_bbp_rx0int_index_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_index_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t index                        : 9;  /**< Overall Interrup Index */
#else
	uint32_t index                        : 9;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rx0int_index_lox_s    cnf71xx;
};
typedef union cvmx_bbp_rx0int_index_lox cvmx_bbp_rx0int_index_lox_t;

/**
 * cvmx_bbp_rx0int_misc_idx_hi#
 *
 * RX0INT_MISC_IDX_HI - Misc Group Index HI
 *
 */
union cvmx_bbp_rx0int_misc_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Misc Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_idx_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_idx_hix cvmx_bbp_rx0int_misc_idx_hix_t;

/**
 * cvmx_bbp_rx0int_misc_idx_lo#
 *
 * RX0INT_MISC_IDX_LO - Misc Group Index LO
 *
 */
union cvmx_bbp_rx0int_misc_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Misc Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_idx_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_idx_lox cvmx_bbp_rx0int_misc_idx_lox_t;

/**
 * cvmx_bbp_rx0int_misc_mask_hi#
 *
 * RX0INT_MISC_MASK_HI = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx0int_misc_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_mask_hix cvmx_bbp_rx0int_misc_mask_hix_t;

/**
 * cvmx_bbp_rx0int_misc_mask_lo#
 *
 * RX0INT_MISC_MASK_LO = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx0int_misc_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_mask_lox cvmx_bbp_rx0int_misc_mask_lox_t;

/**
 * cvmx_bbp_rx0int_misc_rint
 *
 * RX0INT_MISC_RINT - MISC Raw Interrupt Status
 *
 */
union cvmx_bbp_rx0int_misc_rint {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_rint_s    cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_rint cvmx_bbp_rx0int_misc_rint_t;

/**
 * cvmx_bbp_rx0int_misc_status_hi#
 *
 * RX0INT_MISC_STATUS_HI = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx0int_misc_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_status_hix cvmx_bbp_rx0int_misc_status_hix_t;

/**
 * cvmx_bbp_rx0int_misc_status_lo#
 *
 * RX0INT_MISC_STATUS_LO = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx0int_misc_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_misc_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx0int_misc_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_misc_status_lox cvmx_bbp_rx0int_misc_status_lox_t;

/**
 * cvmx_bbp_rx0int_rd_idx_hi#
 *
 * RX0INT_RD_IDX_HI - Read Done Group Index HI
 *
 */
union cvmx_bbp_rx0int_rd_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_idx_hix cvmx_bbp_rx0int_rd_idx_hix_t;

/**
 * cvmx_bbp_rx0int_rd_idx_lo#
 *
 * RX0INT_RD_IDX_LO - Read Done Group Index LO
 *
 */
union cvmx_bbp_rx0int_rd_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_idx_lox cvmx_bbp_rx0int_rd_idx_lox_t;

/**
 * cvmx_bbp_rx0int_rd_mask_hi#
 *
 * RX0INT_RD_MASK_HI = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx0int_rd_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX0 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_mask_hix cvmx_bbp_rx0int_rd_mask_hix_t;

/**
 * cvmx_bbp_rx0int_rd_mask_lo#
 *
 * RX0INT_RD_MASK_LO = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx0int_rd_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX0 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_mask_lox cvmx_bbp_rx0int_rd_mask_lox_t;

/**
 * cvmx_bbp_rx0int_rd_rint
 *
 * RX0INT_RD_RINT - Read Done Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx0int_rd_rint {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_rint_s      cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_rint cvmx_bbp_rx0int_rd_rint_t;

/**
 * cvmx_bbp_rx0int_rd_status_hi#
 *
 * RX0INT_RD_STATUS_HI = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx0int_rd_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX0 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_status_hix cvmx_bbp_rx0int_rd_status_hix_t;

/**
 * cvmx_bbp_rx0int_rd_status_lo#
 *
 * RX0INT_RD_STATUS_LO = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx0int_rd_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rd_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX0 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx0int_rd_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_rd_status_lox cvmx_bbp_rx0int_rd_status_lox_t;

/**
 * cvmx_bbp_rx0int_rdq_idx_hi#
 *
 * RX0INT_RDQ_IDX_HI - Read Queue Empty Group Index HI
 *
 */
union cvmx_bbp_rx0int_rdq_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_idx_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_idx_hix cvmx_bbp_rx0int_rdq_idx_hix_t;

/**
 * cvmx_bbp_rx0int_rdq_idx_lo#
 *
 * RX0INT_RDQ_IDX_LO - Read Queue Empty Group Index LO
 *
 */
union cvmx_bbp_rx0int_rdq_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_idx_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_idx_lox cvmx_bbp_rx0int_rdq_idx_lox_t;

/**
 * cvmx_bbp_rx0int_rdq_mask_hi#
 *
 * RX0INT_RDQ_MASK_HI = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_rdq_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_mask_hix cvmx_bbp_rx0int_rdq_mask_hix_t;

/**
 * cvmx_bbp_rx0int_rdq_mask_lo#
 *
 * RX0INT_RDQ_MASK_LO = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_rdq_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_mask_lox cvmx_bbp_rx0int_rdq_mask_lox_t;

/**
 * cvmx_bbp_rx0int_rdq_rint
 *
 * RX0INT_RDQ_RINT - Read Queue Empty Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx0int_rdq_rint {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_rint_s     cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_rint cvmx_bbp_rx0int_rdq_rint_t;

/**
 * cvmx_bbp_rx0int_rdq_status_hi#
 *
 * RX0INT_RDQ_STATUS_HI = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_rdq_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_status_hix cvmx_bbp_rx0int_rdq_status_hix_t;

/**
 * cvmx_bbp_rx0int_rdq_status_lo#
 *
 * RX0INT_RDQ_STATUS_LO = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_rdq_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_rdq_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx0int_rdq_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_rdq_status_lox cvmx_bbp_rx0int_rdq_status_lox_t;

/**
 * cvmx_bbp_rx0int_stat_hi#
 *
 * RX0INT_STAT_HI - Grouped Interrupt Status HI
 *
 */
union cvmx_bbp_rx0int_stat_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_stat_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t misc                         : 1;  /**< Misc Group Interrupt */
	uint32_t sw                           : 1;  /**< SW Group Interrupt */
	uint32_t wrqdone                      : 1;  /**< Write Queue Empty Group Interrupt */
	uint32_t rdqdone                      : 1;  /**< Read  Queue Empty Group Interrupt */
	uint32_t rddone                       : 1;  /**< Read  Done Group Interrupt */
	uint32_t wrdone                       : 1;  /**< Write Done Group Interrupt */
#else
	uint32_t wrdone                       : 1;
	uint32_t rddone                       : 1;
	uint32_t rdqdone                      : 1;
	uint32_t wrqdone                      : 1;
	uint32_t sw                           : 1;
	uint32_t misc                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_stat_hix_s     cnf71xx;
};
typedef union cvmx_bbp_rx0int_stat_hix cvmx_bbp_rx0int_stat_hix_t;

/**
 * cvmx_bbp_rx0int_stat_lo#
 *
 * RX0INT_STAT_LO - Grouped Interrupt Status LO
 *
 */
union cvmx_bbp_rx0int_stat_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_stat_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t misc                         : 1;  /**< Misc Group Interrupt */
	uint32_t sw                           : 1;  /**< SW Group Interrupt */
	uint32_t wrqdone                      : 1;  /**< Write Queue Empty Group Interrupt */
	uint32_t rdqdone                      : 1;  /**< Read  Queue Empty Group Interrupt */
	uint32_t rddone                       : 1;  /**< Read  Done Group Interrupt */
	uint32_t wrdone                       : 1;  /**< Write Done Group Interrupt */
#else
	uint32_t wrdone                       : 1;
	uint32_t rddone                       : 1;
	uint32_t rdqdone                      : 1;
	uint32_t wrqdone                      : 1;
	uint32_t sw                           : 1;
	uint32_t misc                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_stat_lox_s     cnf71xx;
};
typedef union cvmx_bbp_rx0int_stat_lox cvmx_bbp_rx0int_stat_lox_t;

/**
 * cvmx_bbp_rx0int_sw_idx_hi#
 *
 * RX0INT_SW_IDX_HI - SW Group Index HI
 *
 */
union cvmx_bbp_rx0int_sw_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< SW Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_idx_hix cvmx_bbp_rx0int_sw_idx_hix_t;

/**
 * cvmx_bbp_rx0int_sw_idx_lo#
 *
 * RX0INT_SW_IDX_LO - SW Group Index LO
 *
 */
union cvmx_bbp_rx0int_sw_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< SW Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_idx_lox cvmx_bbp_rx0int_sw_idx_lox_t;

/**
 * cvmx_bbp_rx0int_sw_mask_hi#
 *
 * RX0INT_SW_MASK_HI = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx0int_sw_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< Software Interrupt Mask */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_mask_hix cvmx_bbp_rx0int_sw_mask_hix_t;

/**
 * cvmx_bbp_rx0int_sw_mask_lo#
 *
 * RX0INT_SW_MASK_LO = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx0int_sw_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< Software Interrupt Mask */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_mask_lox cvmx_bbp_rx0int_sw_mask_lox_t;

/**
 * cvmx_bbp_rx0int_sw_rint
 *
 * RX0INT_SW_RINT - SW Raw Interrupt Status
 *
 */
union cvmx_bbp_rx0int_sw_rint {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_rint_s      cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_rint cvmx_bbp_rx0int_sw_rint_t;

/**
 * cvmx_bbp_rx0int_sw_status_hi#
 *
 * RX0INT_SW_STATUS_HI = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx0int_sw_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_status_hix cvmx_bbp_rx0int_sw_status_hix_t;

/**
 * cvmx_bbp_rx0int_sw_status_lo#
 *
 * RX0INT_SW_STATUS_LO = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx0int_sw_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_sw_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_sw_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_sw_status_lox cvmx_bbp_rx0int_sw_status_lox_t;

/**
 * cvmx_bbp_rx0int_swclr
 *
 * RX0INT_SWCLR- SW Interrupt Clear
 *
 */
union cvmx_bbp_rx0int_swclr {
	uint32_t u32;
	struct cvmx_bbp_rx0int_swclr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t clr                          : 32; /**< Clear SW Interrupt bit */
#else
	uint32_t clr                          : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_swclr_s        cnf71xx;
};
typedef union cvmx_bbp_rx0int_swclr cvmx_bbp_rx0int_swclr_t;

/**
 * cvmx_bbp_rx0int_swset
 *
 * RX0INT_SWSET - SW Interrupt Set
 *
 */
union cvmx_bbp_rx0int_swset {
	uint32_t u32;
	struct cvmx_bbp_rx0int_swset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t set                          : 32; /**< Set SW Interrupt bit */
#else
	uint32_t set                          : 32;
#endif
	} s;
	struct cvmx_bbp_rx0int_swset_s        cnf71xx;
};
typedef union cvmx_bbp_rx0int_swset cvmx_bbp_rx0int_swset_t;

/**
 * cvmx_bbp_rx0int_wr_idx_hi#
 *
 * RX0INT_WR_IDX_HI - Write Done Group Index HI
 *
 */
union cvmx_bbp_rx0int_wr_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_idx_hix cvmx_bbp_rx0int_wr_idx_hix_t;

/**
 * cvmx_bbp_rx0int_wr_idx_lo#
 *
 * RX0INT_WR_IDX_LO - Write Done Group Index LO
 *
 */
union cvmx_bbp_rx0int_wr_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_idx_lox cvmx_bbp_rx0int_wr_idx_lox_t;

/**
 * cvmx_bbp_rx0int_wr_mask_hi#
 *
 * RX0INT_WR_MASK_HI = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_rx0int_wr_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_mask_hix cvmx_bbp_rx0int_wr_mask_hix_t;

/**
 * cvmx_bbp_rx0int_wr_mask_lo#
 *
 * &BBP_DID_ID         = 0x6F007F820000
 *
 * RX0INT_WR_MASK_LO = Interrupt Write Done Group Mask
 */
union cvmx_bbp_rx0int_wr_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_mask_lox cvmx_bbp_rx0int_wr_mask_lox_t;

/**
 * cvmx_bbp_rx0int_wr_rint
 *
 * RX0INT_WR_RINT - Write Done Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx0int_wr_rint {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_rint_s      cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_rint cvmx_bbp_rx0int_wr_rint_t;

/**
 * cvmx_bbp_rx0int_wr_status_hi#
 *
 * RX0INT_WR_STATUS_HI = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_rx0int_wr_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_status_hix cvmx_bbp_rx0int_wr_status_hix_t;

/**
 * cvmx_bbp_rx0int_wr_status_lo#
 *
 * RX0INT_WR_STATUS_LO = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_rx0int_wr_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wr_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx0int_wr_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_wr_status_lox cvmx_bbp_rx0int_wr_status_lox_t;

/**
 * cvmx_bbp_rx0int_wrq_idx_hi#
 *
 * RX0INT_WRQ_IDX_HI - Write Queue Empty Group Index HI
 *
 */
union cvmx_bbp_rx0int_wrq_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_idx_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_idx_hix cvmx_bbp_rx0int_wrq_idx_hix_t;

/**
 * cvmx_bbp_rx0int_wrq_idx_lo#
 *
 * RX0INT_WRQ_IDX_LO - Write Queue Empty Group Index LO
 *
 */
union cvmx_bbp_rx0int_wrq_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_idx_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_idx_lox cvmx_bbp_rx0int_wrq_idx_lox_t;

/**
 * cvmx_bbp_rx0int_wrq_mask_hi#
 *
 * RX0INT_WRQ_MASK_HI = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_wrq_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_mask_hix cvmx_bbp_rx0int_wrq_mask_hix_t;

/**
 * cvmx_bbp_rx0int_wrq_mask_lo#
 *
 * RX0INT_WRQ_MASK_LO = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_wrq_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_mask_lox cvmx_bbp_rx0int_wrq_mask_lox_t;

/**
 * cvmx_bbp_rx0int_wrq_rint
 *
 * RX0INT_WRQ_RINT - Write Queue Empty Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx0int_wrq_rint {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_rint_s     cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_rint cvmx_bbp_rx0int_wrq_rint_t;

/**
 * cvmx_bbp_rx0int_wrq_status_hi#
 *
 * RX0INT_WRQ_STATUS_HI = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_wrq_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_status_hix cvmx_bbp_rx0int_wrq_status_hix_t;

/**
 * cvmx_bbp_rx0int_wrq_status_lo#
 *
 * RX0INT_WRQ_STATUS_LO = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx0int_wrq_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx0int_wrq_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx0int_wrq_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx0int_wrq_status_lox cvmx_bbp_rx0int_wrq_status_lox_t;

/**
 * cvmx_bbp_rx0seq_autogate
 */
union cvmx_bbp_rx0seq_autogate {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_autogate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t auto_gate                    : 1;  /**< 1==enable auto-clock-gating */
#else
	uint32_t auto_gate                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx0seq_autogate_s     cnf71xx;
};
typedef union cvmx_bbp_rx0seq_autogate cvmx_bbp_rx0seq_autogate_t;

/**
 * cvmx_bbp_rx0seq_gpi_rd00
 */
union cvmx_bbp_rx0seq_gpi_rd00 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_gpi_rd00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dftdm_wr_done                : 1;  /**< DFTDM WR done int */
	uint32_t rafe_wr1_done                : 1;  /**< RAFE WR1 done int */
	uint32_t rafe_wr0_done                : 1;  /**< RAFE WR0 done int */
	uint32_t ulfe_wr_done                 : 1;  /**< ULFE WR done int */
	uint32_t reserved_27_27               : 1;
	uint32_t edma_wr0_done                : 1;  /**< EDMA WR0 done int */
	uint32_t intdma_rd_done               : 1;  /**< INTDMA RD done int */
	uint32_t extdma_rd_done               : 1;  /**< EXTDMA RD done int */
	uint32_t dftdm_rd_done                : 1;  /**< DFTDM RD done int */
	uint32_t rafe_rd_done                 : 1;  /**< RAFE RD done int */
	uint32_t ulfe_rd_done                 : 1;  /**< ULFE RD done int */
	uint32_t rfif_spi_int                 : 1;  /**< RFIF SPI int */
	uint32_t rfif_rx_ints                 : 12; /**< RFIF RX ints */
	uint32_t tti_timer                    : 8;  /**< TTI Timer ints from RFIF */
#else
	uint32_t tti_timer                    : 8;
	uint32_t rfif_rx_ints                 : 12;
	uint32_t rfif_spi_int                 : 1;
	uint32_t ulfe_rd_done                 : 1;
	uint32_t rafe_rd_done                 : 1;
	uint32_t dftdm_rd_done                : 1;
	uint32_t extdma_rd_done               : 1;
	uint32_t intdma_rd_done               : 1;
	uint32_t edma_wr0_done                : 1;
	uint32_t reserved_27_27               : 1;
	uint32_t ulfe_wr_done                 : 1;
	uint32_t rafe_wr0_done                : 1;
	uint32_t rafe_wr1_done                : 1;
	uint32_t dftdm_wr_done                : 1;
#endif
	} s;
	struct cvmx_bbp_rx0seq_gpi_rd00_s     cnf71xx;
};
typedef union cvmx_bbp_rx0seq_gpi_rd00 cvmx_bbp_rx0seq_gpi_rd00_t;

/**
 * cvmx_bbp_rx0seq_gpi_rd01
 */
union cvmx_bbp_rx0seq_gpi_rd01 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_gpi_rd01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 23; /**< SEQ loopbacks from GPO. */
	uint32_t rafe_done                    : 1;  /**< RAFE DONE int from HAB */
	uint32_t dftdm_done                   : 1;  /**< DFTDM DONE int from HAB */
	uint32_t ulfe_done                    : 1;  /**< ULFE DONE int from HAB */
	uint32_t ulfe_wr_empty                : 1;  /**< ULFE WR queue empty int */
	uint32_t rafe_wr1_empty               : 1;  /**< RAFE WR1 queue empty int */
	uint32_t rafe_wr0_empty               : 1;  /**< RAFE WR0 queue empty int */
	uint32_t reserved_2_2                 : 1;
	uint32_t intdma_wr_done               : 1;  /**< EXTDMA WR done int */
	uint32_t extdma_wr_done               : 1;  /**< EXTDMA WR done int */
#else
	uint32_t extdma_wr_done               : 1;
	uint32_t intdma_wr_done               : 1;
	uint32_t reserved_2_2                 : 1;
	uint32_t rafe_wr0_empty               : 1;
	uint32_t rafe_wr1_empty               : 1;
	uint32_t ulfe_wr_empty                : 1;
	uint32_t ulfe_done                    : 1;
	uint32_t dftdm_done                   : 1;
	uint32_t rafe_done                    : 1;
	uint32_t gpi_loopback                 : 23;
#endif
	} s;
	struct cvmx_bbp_rx0seq_gpi_rd01_s     cnf71xx;
};
typedef union cvmx_bbp_rx0seq_gpi_rd01 cvmx_bbp_rx0seq_gpi_rd01_t;

/**
 * cvmx_bbp_rx0seq_gpo_clr00
 */
union cvmx_bbp_rx0seq_gpo_clr00 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_gpo_clr00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t rafe_inputsel                : 1;  /**< RAFE input select.  0=RFIF, 1=HMM.  Write 1 to clear, 0 to leave alone */
	uint32_t ulfe_inputsel                : 1;  /**< ULFE input select.  0=RFIF, 1=HMM.  Write 1 to clear, 0 to leave alone */
	uint32_t t1seq_intr                   : 8;  /**< SEQ interrupt outputs.  Write 1 to clear, 0 to leave alone */
#else
	uint32_t t1seq_intr                   : 8;
	uint32_t ulfe_inputsel                : 1;
	uint32_t rafe_inputsel                : 1;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_rx0seq_gpo_clr00_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_gpo_clr00 cvmx_bbp_rx0seq_gpo_clr00_t;

/**
 * cvmx_bbp_rx0seq_gpo_clr01
 */
union cvmx_bbp_rx0seq_gpo_clr01 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_gpo_clr01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 23; /**< SEQ loopbacks to GPI.   Write 1 to clear, 0 to leave alone */
	uint32_t reserved_0_8                 : 9;
#else
	uint32_t reserved_0_8                 : 9;
	uint32_t gpi_loopback                 : 23;
#endif
	} s;
	struct cvmx_bbp_rx0seq_gpo_clr01_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_gpo_clr01 cvmx_bbp_rx0seq_gpo_clr01_t;

/**
 * cvmx_bbp_rx0seq_gpo_set00
 */
union cvmx_bbp_rx0seq_gpo_set00 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_gpo_set00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t rafe_inputsel                : 1;  /**< RAFE input select.  0=RFIF, 1=HMM.  Write 1 to set, 0 to leave alone */
	uint32_t ulfe_inputsel                : 1;  /**< ULFE input select.  0=RFIF, 1=HMM.  Write 1 to set, 0 to leave alone */
	uint32_t t1seq_intr                   : 8;  /**< SEQ interrupt outputs.  Write 1 to set, 0 to leave alone */
#else
	uint32_t t1seq_intr                   : 8;
	uint32_t ulfe_inputsel                : 1;
	uint32_t rafe_inputsel                : 1;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_rx0seq_gpo_set00_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_gpo_set00 cvmx_bbp_rx0seq_gpo_set00_t;

/**
 * cvmx_bbp_rx0seq_gpo_set01
 */
union cvmx_bbp_rx0seq_gpo_set01 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_gpo_set01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 23; /**< SEQ loopbacks to GPI.   Write 1 to set, 0 to leave alone */
	uint32_t reserved_0_8                 : 9;
#else
	uint32_t reserved_0_8                 : 9;
	uint32_t gpi_loopback                 : 23;
#endif
	} s;
	struct cvmx_bbp_rx0seq_gpo_set01_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_gpo_set01 cvmx_bbp_rx0seq_gpo_set01_t;

/**
 * cvmx_bbp_rx0seq_param0
 */
union cvmx_bbp_rx0seq_param0 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_param0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_25_31               : 7;
	uint32_t autorun                      : 1;  /**< Autorun parameter value */
	uint32_t reserved_17_23               : 7;
	uint32_t seq_base_addr                : 17; /**< Base address parameter value */
#else
	uint32_t seq_base_addr                : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t autorun                      : 1;
	uint32_t reserved_25_31               : 7;
#endif
	} s;
	struct cvmx_bbp_rx0seq_param0_s       cnf71xx;
};
typedef union cvmx_bbp_rx0seq_param0 cvmx_bbp_rx0seq_param0_t;

/**
 * cvmx_bbp_rx0seq_param1
 */
union cvmx_bbp_rx0seq_param1 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_param1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_21_31               : 11;
	uint32_t thrd_max                     : 5;  /**< Thread max parameter value */
	uint32_t gpio_out_max                 : 8;  /**< GPIO out max parameter value */
	uint32_t gpio_in_max                  : 8;  /**< GPIO in max parameter value */
#else
	uint32_t gpio_in_max                  : 8;
	uint32_t gpio_out_max                 : 8;
	uint32_t thrd_max                     : 5;
	uint32_t reserved_21_31               : 11;
#endif
	} s;
	struct cvmx_bbp_rx0seq_param1_s       cnf71xx;
};
typedef union cvmx_bbp_rx0seq_param1 cvmx_bbp_rx0seq_param1_t;

/**
 * cvmx_bbp_rx0seq_ramacc
 */
union cvmx_bbp_rx0seq_ramacc {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_ramacc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t ram_read_addr                : 14; /**< Command RAM read address -- when reading from Command
                                                         RAM, write this register with the Command Address and
                                                         read back this register until the read value returns
                                                         the requested address.  Then the read data is ready in
                                                         the RAMRD_LSW and RAMRD_MSW registers (following). */
	uint32_t reserved_0_2                 : 3;
#else
	uint32_t reserved_0_2                 : 3;
	uint32_t ram_read_addr                : 14;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_rx0seq_ramacc_s       cnf71xx;
};
typedef union cvmx_bbp_rx0seq_ramacc cvmx_bbp_rx0seq_ramacc_t;

/**
 * cvmx_bbp_rx0seq_ramrd_lsw
 */
union cvmx_bbp_rx0seq_ramrd_lsw {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_ramrd_lsw_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t cmd_ram_lsw                  : 12; /**< LSW of data read from command RAM */
#else
	uint32_t cmd_ram_lsw                  : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rx0seq_ramrd_lsw_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_ramrd_lsw cvmx_bbp_rx0seq_ramrd_lsw_t;

/**
 * cvmx_bbp_rx0seq_ramrd_msw
 */
union cvmx_bbp_rx0seq_ramrd_msw {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_ramrd_msw_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t cmd_ram_msw                  : 32; /**< MSW of data read from command RAM */
#else
	uint32_t cmd_ram_msw                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx0seq_ramrd_msw_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_ramrd_msw cvmx_bbp_rx0seq_ramrd_msw_t;

/**
 * cvmx_bbp_rx0seq_status
 */
union cvmx_bbp_rx0seq_status {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_21_31               : 11;
	uint32_t curthrd                      : 5;  /**< Currently active thread */
	uint32_t reserved_1_15                : 15;
	uint32_t seq_status                   : 1;  /**< 1==SEQ is not idle */
#else
	uint32_t seq_status                   : 1;
	uint32_t reserved_1_15                : 15;
	uint32_t curthrd                      : 5;
	uint32_t reserved_21_31               : 11;
#endif
	} s;
	struct cvmx_bbp_rx0seq_status_s       cnf71xx;
};
typedef union cvmx_bbp_rx0seq_status cvmx_bbp_rx0seq_status_t;

/**
 * cvmx_bbp_rx0seq_thrd#_cfg
 */
union cvmx_bbp_rx0seq_thrdx_cfg {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_thrdx_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_26_31               : 6;
	uint32_t thrd_wait_sts                : 2;  /**< Thread X wait status
                                                         0==not waiting
                                                         1==waiting for timer
                                                         2==waiting for GPIO low
                                                         3==waiting for GPIO high */
	uint32_t thrd_gpiowait                : 8;  /**< Thread X GPIO used as trigger */
	uint32_t reserved_2_15                : 14;
	uint32_t thrd_stat                    : 2;  /**< Thread X status
                                                         0==done
                                                         1==ready
                                                         2==active
                                                         3==wait */
#else
	uint32_t thrd_stat                    : 2;
	uint32_t reserved_2_15                : 14;
	uint32_t thrd_gpiowait                : 8;
	uint32_t thrd_wait_sts                : 2;
	uint32_t reserved_26_31               : 6;
#endif
	} s;
	struct cvmx_bbp_rx0seq_thrdx_cfg_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_thrdx_cfg cvmx_bbp_rx0seq_thrdx_cfg_t;

/**
 * cvmx_bbp_rx0seq_thrd#_pc
 */
union cvmx_bbp_rx0seq_thrdx_pc {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_thrdx_pc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t thrd_pc                      : 13; /**< Thread X PC (Program Counter) */
	uint32_t reserved_0_2                 : 3;
#else
	uint32_t reserved_0_2                 : 3;
	uint32_t thrd_pc                      : 13;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_rx0seq_thrdx_pc_s     cnf71xx;
};
typedef union cvmx_bbp_rx0seq_thrdx_pc cvmx_bbp_rx0seq_thrdx_pc_t;

/**
 * cvmx_bbp_rx0seq_thrdstat0
 */
union cvmx_bbp_rx0seq_thrdstat0 {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_thrdstat0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t thrd15_stat                  : 2;  /**< Thread 15 status */
	uint32_t thrd14_stat                  : 2;  /**< Thread 14 status */
	uint32_t thrd13_stat                  : 2;  /**< Thread 13 status */
	uint32_t thrd12_stat                  : 2;  /**< Thread 12 status */
	uint32_t thrd11_stat                  : 2;  /**< Thread 11 status */
	uint32_t thrd10_stat                  : 2;  /**< Thread 10 status */
	uint32_t thrd09_stat                  : 2;  /**< Thread 9 status */
	uint32_t thrd08_stat                  : 2;  /**< Thread 8 status */
	uint32_t thrd07_stat                  : 2;  /**< Thread 7 status */
	uint32_t thrd06_stat                  : 2;  /**< Thread 6 status */
	uint32_t thrd05_stat                  : 2;  /**< Thread 5 status */
	uint32_t thrd04_stat                  : 2;  /**< Thread 4 status */
	uint32_t thrd03_stat                  : 2;  /**< Thread 3 status */
	uint32_t thrd02_stat                  : 2;  /**< Thread 2 status */
	uint32_t thrd01_stat                  : 2;  /**< Thread 1 status */
	uint32_t thrd00_stat                  : 2;  /**< Thread 0 status
                                                         0==done
                                                         1==ready
                                                         2==active
                                                         3==wait */
#else
	uint32_t thrd00_stat                  : 2;
	uint32_t thrd01_stat                  : 2;
	uint32_t thrd02_stat                  : 2;
	uint32_t thrd03_stat                  : 2;
	uint32_t thrd04_stat                  : 2;
	uint32_t thrd05_stat                  : 2;
	uint32_t thrd06_stat                  : 2;
	uint32_t thrd07_stat                  : 2;
	uint32_t thrd08_stat                  : 2;
	uint32_t thrd09_stat                  : 2;
	uint32_t thrd10_stat                  : 2;
	uint32_t thrd11_stat                  : 2;
	uint32_t thrd12_stat                  : 2;
	uint32_t thrd13_stat                  : 2;
	uint32_t thrd14_stat                  : 2;
	uint32_t thrd15_stat                  : 2;
#endif
	} s;
	struct cvmx_bbp_rx0seq_thrdstat0_s    cnf71xx;
};
typedef union cvmx_bbp_rx0seq_thrdstat0 cvmx_bbp_rx0seq_thrdstat0_t;

/**
 * cvmx_bbp_rx0seq_timer
 */
union cvmx_bbp_rx0seq_timer {
	uint32_t u32;
	struct cvmx_bbp_rx0seq_timer_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t seq_timer                    : 32; /**< SEQ timer value - Normally set to a value specified by
                                                         the Wait for Timer command.  Will start counting down
                                                         until it hits 0 or until another Wait for Timer cmd is
                                                         issued.  Can be read to read current value or written to
                                                         overwrite count down value - but not a normal usage. */
#else
	uint32_t seq_timer                    : 32;
#endif
	} s;
	struct cvmx_bbp_rx0seq_timer_s        cnf71xx;
};
typedef union cvmx_bbp_rx0seq_timer cvmx_bbp_rx0seq_timer_t;

/**
 * cvmx_bbp_rx1_bist_status0
 *
 * RX1 Bist Status0  0x853800+0x60
 *
 */
union cvmx_bbp_rx1_bist_status0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_bist_status0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rx1_trace0_bist              : 1;  /**< RX1 DSP0 Trace Ram Bist Result
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t rx1_trace1_bist              : 1;  /**< RX1 DSP1 Trace Ram Bist Result
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t mem_array_bist               : 1;  /**< BBP Memory Array Bist Result
                                                         A value of 1 indicates BIST fail for the entire BBP srams. */
	uint32_t reserved_0_28                : 29;
#else
	uint32_t reserved_0_28                : 29;
	uint32_t mem_array_bist               : 1;
	uint32_t rx1_trace1_bist              : 1;
	uint32_t rx1_trace0_bist              : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_bist_status0_s    cnf71xx;
};
typedef union cvmx_bbp_rx1_bist_status0 cvmx_bbp_rx1_bist_status0_t;

/**
 * cvmx_bbp_rx1_bist_status1
 *
 * RX1 Bist Status1  0x853800+0x64
 *
 */
union cvmx_bbp_rx1_bist_status1 {
	uint32_t u32;
	struct cvmx_bbp_rx1_bist_status1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t adma_bist                    : 8;  /**< ADMA Bist Result
                                                         8 rams in ADMA
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t rx1_psm_bist                 : 1;  /**< RX1 PSM Bist Result
                                                         1 ram in RX1 PSM
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t vitb_bist                    : 5;  /**< Viterbi Decoder Bist Result
                                                         5 rams in Vitb
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t reserved_0_17                : 18;
#else
	uint32_t reserved_0_17                : 18;
	uint32_t vitb_bist                    : 5;
	uint32_t rx1_psm_bist                 : 1;
	uint32_t adma_bist                    : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_bist_status1_s    cnf71xx;
};
typedef union cvmx_bbp_rx1_bist_status1 cvmx_bbp_rx1_bist_status1_t;

/**
 * cvmx_bbp_rx1_bist_status2
 *
 * RX1 Bist Status2  0x853800+0x68
 *
 */
union cvmx_bbp_rx1_bist_status2 {
	uint32_t u32;
	struct cvmx_bbp_rx1_bist_status2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t turbo_bist0                  : 32; /**< Turbo Decoder Bist Result Set0
                                                         80 rams in Turbo Decoder
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t turbo_bist0                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_bist_status2_s    cnf71xx;
};
typedef union cvmx_bbp_rx1_bist_status2 cvmx_bbp_rx1_bist_status2_t;

/**
 * cvmx_bbp_rx1_bist_status3
 *
 * RX1 Bist Status3  0x853800+0x6c
 *
 */
union cvmx_bbp_rx1_bist_status3 {
	uint32_t u32;
	struct cvmx_bbp_rx1_bist_status3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t turbo_bist1                  : 32; /**< Turbo Decoder Bist Result Set1
                                                         80 rams in Turbo Decoder
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t turbo_bist1                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_bist_status3_s    cnf71xx;
};
typedef union cvmx_bbp_rx1_bist_status3 cvmx_bbp_rx1_bist_status3_t;

/**
 * cvmx_bbp_rx1_bist_status4
 *
 * RX1 Bist Status4  0x853800+0x70
 *
 */
union cvmx_bbp_rx1_bist_status4 {
	uint32_t u32;
	struct cvmx_bbp_rx1_bist_status4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t turbo_bist2                  : 16; /**< Turbo Decoder Bist Result Set2
                                                         80 rams in Turbo Decoder
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t reserved_0_15                : 16;
#else
	uint32_t reserved_0_15                : 16;
	uint32_t turbo_bist2                  : 16;
#endif
	} s;
	struct cvmx_bbp_rx1_bist_status4_s    cnf71xx;
};
typedef union cvmx_bbp_rx1_bist_status4 cvmx_bbp_rx1_bist_status4_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx1_ext_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_cbuf_end_addr0 cvmx_bbp_rx1_ext_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx1_ext_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_cbuf_start_addr0 cvmx_bbp_rx1_ext_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_debug_dat
 */
union cvmx_bbp_rx1_ext_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_debug_dat cvmx_bbp_rx1_ext_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_debug_sel
 */
union cvmx_bbp_rx1_ext_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_debug_sel cvmx_bbp_rx1_ext_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_intr_clear
 */
union cvmx_bbp_rx1_ext_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_intr_clear cvmx_bbp_rx1_ext_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_intr_enb
 */
union cvmx_bbp_rx1_ext_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_intr_enb cvmx_bbp_rx1_ext_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx1_ext_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_intr_rstatus cvmx_bbp_rx1_ext_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_intr_status
 */
union cvmx_bbp_rx1_ext_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_intr_status cvmx_bbp_rx1_ext_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_intr_test
 */
union cvmx_bbp_rx1_ext_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_intr_test cvmx_bbp_rx1_ext_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_memclr_data
 */
union cvmx_bbp_rx1_ext_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_memclr_data cvmx_bbp_rx1_ext_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_mode
 */
union cvmx_bbp_rx1_ext_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_mode cvmx_bbp_rx1_ext_dma_rd_mode_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_pri_mode
 */
union cvmx_bbp_rx1_ext_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_pri_mode cvmx_bbp_rx1_ext_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_start_addr0
 */
union cvmx_bbp_rx1_ext_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_start_addr0 cvmx_bbp_rx1_ext_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_status
 */
union cvmx_bbp_rx1_ext_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_status cvmx_bbp_rx1_ext_dma_rd_status_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx1_ext_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_xfer_mode_count cvmx_bbp_rx1_ext_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx1_ext_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_xfer_q_status cvmx_bbp_rx1_ext_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_ext_dma_rd_xfer_start
 */
union cvmx_bbp_rx1_ext_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_rd_xfer_start cvmx_bbp_rx1_ext_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx1_ext_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_cbuf_end_addr0 cvmx_bbp_rx1_ext_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx1_ext_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_cbuf_start_addr0 cvmx_bbp_rx1_ext_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_debug_dat
 */
union cvmx_bbp_rx1_ext_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_debug_dat cvmx_bbp_rx1_ext_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_debug_sel
 */
union cvmx_bbp_rx1_ext_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_debug_sel cvmx_bbp_rx1_ext_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_intr_clear
 */
union cvmx_bbp_rx1_ext_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_intr_clear cvmx_bbp_rx1_ext_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_intr_enb
 */
union cvmx_bbp_rx1_ext_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_intr_enb cvmx_bbp_rx1_ext_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx1_ext_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_intr_rstatus cvmx_bbp_rx1_ext_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_intr_status
 */
union cvmx_bbp_rx1_ext_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_intr_status cvmx_bbp_rx1_ext_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_intr_test
 */
union cvmx_bbp_rx1_ext_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_intr_test cvmx_bbp_rx1_ext_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_memclr_data
 */
union cvmx_bbp_rx1_ext_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_memclr_data cvmx_bbp_rx1_ext_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_mode
 */
union cvmx_bbp_rx1_ext_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_mode cvmx_bbp_rx1_ext_dma_wr_mode_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_pri_mode
 */
union cvmx_bbp_rx1_ext_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_pri_mode cvmx_bbp_rx1_ext_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_start_addr0
 */
union cvmx_bbp_rx1_ext_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_start_addr0 cvmx_bbp_rx1_ext_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_status
 */
union cvmx_bbp_rx1_ext_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_status cvmx_bbp_rx1_ext_dma_wr_status_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx1_ext_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_xfer_mode_count cvmx_bbp_rx1_ext_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx1_ext_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_xfer_q_status cvmx_bbp_rx1_ext_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_ext_dma_wr_xfer_start
 */
union cvmx_bbp_rx1_ext_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_ext_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_ext_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_ext_dma_wr_xfer_start cvmx_bbp_rx1_ext_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_end_addr0 cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_start_addr0 cvmx_bbp_rx1_harq_dma_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_debug_dat
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_debug_dat cvmx_bbp_rx1_harq_dma_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_debug_sel
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_debug_sel cvmx_bbp_rx1_harq_dma_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_intr_clear
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_intr_clear cvmx_bbp_rx1_harq_dma_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_intr_enb
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_intr_enb cvmx_bbp_rx1_harq_dma_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_intr_rstatus cvmx_bbp_rx1_harq_dma_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_intr_status
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_intr_status cvmx_bbp_rx1_harq_dma_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_intr_test
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_intr_test cvmx_bbp_rx1_harq_dma_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_memclr_data
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_memclr_data cvmx_bbp_rx1_harq_dma_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_mode
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_mode cvmx_bbp_rx1_harq_dma_dma_rd_mode_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_pri_mode
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_pri_mode cvmx_bbp_rx1_harq_dma_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_start_addr0
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_start_addr0 cvmx_bbp_rx1_harq_dma_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_status
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_status cvmx_bbp_rx1_harq_dma_dma_rd_status_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_xfer_mode_count cvmx_bbp_rx1_harq_dma_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_xfer_q_status cvmx_bbp_rx1_harq_dma_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_rd_xfer_start
 */
union cvmx_bbp_rx1_harq_dma_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_rd_xfer_start cvmx_bbp_rx1_harq_dma_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_end_addr0 cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_start_addr0 cvmx_bbp_rx1_harq_dma_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_debug_dat
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_debug_dat cvmx_bbp_rx1_harq_dma_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_debug_sel
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_debug_sel cvmx_bbp_rx1_harq_dma_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_intr_clear
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_intr_clear cvmx_bbp_rx1_harq_dma_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_intr_enb
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_intr_enb cvmx_bbp_rx1_harq_dma_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_intr_rstatus cvmx_bbp_rx1_harq_dma_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_intr_status
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_intr_status cvmx_bbp_rx1_harq_dma_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_intr_test
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_intr_test cvmx_bbp_rx1_harq_dma_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_memclr_data
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_memclr_data cvmx_bbp_rx1_harq_dma_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_mode
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_mode cvmx_bbp_rx1_harq_dma_dma_wr_mode_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_pri_mode
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_pri_mode cvmx_bbp_rx1_harq_dma_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_start_addr0
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_start_addr0 cvmx_bbp_rx1_harq_dma_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_status
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_status cvmx_bbp_rx1_harq_dma_dma_wr_status_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_xfer_mode_count cvmx_bbp_rx1_harq_dma_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_xfer_q_status cvmx_bbp_rx1_harq_dma_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_harq_dma_dma_wr_xfer_start
 */
union cvmx_bbp_rx1_harq_dma_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_harq_dma_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_harq_dma_dma_wr_xfer_start cvmx_bbp_rx1_harq_dma_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx1_instr_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_cbuf_end_addr0 cvmx_bbp_rx1_instr_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx1_instr_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_cbuf_start_addr0 cvmx_bbp_rx1_instr_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_debug_dat
 */
union cvmx_bbp_rx1_instr_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_debug_dat cvmx_bbp_rx1_instr_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_debug_sel
 */
union cvmx_bbp_rx1_instr_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_debug_sel cvmx_bbp_rx1_instr_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_intr_clear
 */
union cvmx_bbp_rx1_instr_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_intr_clear cvmx_bbp_rx1_instr_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_intr_enb
 */
union cvmx_bbp_rx1_instr_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_intr_enb cvmx_bbp_rx1_instr_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx1_instr_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_intr_rstatus cvmx_bbp_rx1_instr_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_intr_status
 */
union cvmx_bbp_rx1_instr_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_intr_status cvmx_bbp_rx1_instr_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_intr_test
 */
union cvmx_bbp_rx1_instr_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_intr_test cvmx_bbp_rx1_instr_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_memclr_data
 */
union cvmx_bbp_rx1_instr_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_memclr_data cvmx_bbp_rx1_instr_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_mode
 */
union cvmx_bbp_rx1_instr_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_mode cvmx_bbp_rx1_instr_dma_wr_mode_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_pri_mode
 */
union cvmx_bbp_rx1_instr_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_pri_mode cvmx_bbp_rx1_instr_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_start_addr0
 */
union cvmx_bbp_rx1_instr_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_start_addr0 cvmx_bbp_rx1_instr_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_status
 */
union cvmx_bbp_rx1_instr_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_status cvmx_bbp_rx1_instr_dma_wr_status_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx1_instr_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_xfer_mode_count cvmx_bbp_rx1_instr_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx1_instr_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_xfer_q_status cvmx_bbp_rx1_instr_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_instr_dma_wr_xfer_start
 */
union cvmx_bbp_rx1_instr_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_instr_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_instr_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_instr_dma_wr_xfer_start cvmx_bbp_rx1_instr_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx1_int_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_cbuf_end_addr0 cvmx_bbp_rx1_int_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx1_int_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_cbuf_start_addr0 cvmx_bbp_rx1_int_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_debug_dat
 */
union cvmx_bbp_rx1_int_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_debug_dat cvmx_bbp_rx1_int_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_debug_sel
 */
union cvmx_bbp_rx1_int_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_debug_sel cvmx_bbp_rx1_int_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_intr_clear
 */
union cvmx_bbp_rx1_int_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_intr_clear cvmx_bbp_rx1_int_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_intr_enb
 */
union cvmx_bbp_rx1_int_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_intr_enb cvmx_bbp_rx1_int_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx1_int_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_intr_rstatus cvmx_bbp_rx1_int_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_intr_status
 */
union cvmx_bbp_rx1_int_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_intr_status cvmx_bbp_rx1_int_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_intr_test
 */
union cvmx_bbp_rx1_int_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_intr_test cvmx_bbp_rx1_int_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_memclr_data
 */
union cvmx_bbp_rx1_int_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_memclr_data cvmx_bbp_rx1_int_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_mode
 */
union cvmx_bbp_rx1_int_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_mode cvmx_bbp_rx1_int_dma_rd_mode_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_pri_mode
 */
union cvmx_bbp_rx1_int_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_pri_mode cvmx_bbp_rx1_int_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_start_addr0
 */
union cvmx_bbp_rx1_int_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_start_addr0 cvmx_bbp_rx1_int_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_status
 */
union cvmx_bbp_rx1_int_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_status cvmx_bbp_rx1_int_dma_rd_status_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx1_int_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_xfer_mode_count cvmx_bbp_rx1_int_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx1_int_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_xfer_q_status cvmx_bbp_rx1_int_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_int_dma_rd_xfer_start
 */
union cvmx_bbp_rx1_int_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_rd_xfer_start cvmx_bbp_rx1_int_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx1_int_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_cbuf_end_addr0 cvmx_bbp_rx1_int_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx1_int_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_cbuf_start_addr0 cvmx_bbp_rx1_int_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_debug_dat
 */
union cvmx_bbp_rx1_int_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_debug_dat cvmx_bbp_rx1_int_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_debug_sel
 */
union cvmx_bbp_rx1_int_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_debug_sel cvmx_bbp_rx1_int_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_intr_clear
 */
union cvmx_bbp_rx1_int_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_intr_clear cvmx_bbp_rx1_int_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_intr_enb
 */
union cvmx_bbp_rx1_int_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_intr_enb cvmx_bbp_rx1_int_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx1_int_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_intr_rstatus cvmx_bbp_rx1_int_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_intr_status
 */
union cvmx_bbp_rx1_int_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_intr_status cvmx_bbp_rx1_int_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_intr_test
 */
union cvmx_bbp_rx1_int_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_intr_test cvmx_bbp_rx1_int_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_memclr_data
 */
union cvmx_bbp_rx1_int_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_memclr_data cvmx_bbp_rx1_int_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_mode
 */
union cvmx_bbp_rx1_int_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_mode cvmx_bbp_rx1_int_dma_wr_mode_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_pri_mode
 */
union cvmx_bbp_rx1_int_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_pri_mode cvmx_bbp_rx1_int_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_start_addr0
 */
union cvmx_bbp_rx1_int_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_start_addr0 cvmx_bbp_rx1_int_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_status
 */
union cvmx_bbp_rx1_int_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_status cvmx_bbp_rx1_int_dma_wr_status_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx1_int_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_xfer_mode_count cvmx_bbp_rx1_int_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx1_int_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_xfer_q_status cvmx_bbp_rx1_int_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_int_dma_wr_xfer_start
 */
union cvmx_bbp_rx1_int_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_int_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_int_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_int_dma_wr_xfer_start cvmx_bbp_rx1_int_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_cbuf_end_addr0 cvmx_bbp_rx1_turbodec_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_cbuf_start_addr0 cvmx_bbp_rx1_turbodec_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_debug_dat
 */
union cvmx_bbp_rx1_turbodec_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_debug_dat cvmx_bbp_rx1_turbodec_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_debug_sel
 */
union cvmx_bbp_rx1_turbodec_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_debug_sel cvmx_bbp_rx1_turbodec_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_end_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_end_addr0 cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_start_addr0 cvmx_bbp_rx1_turbodec_dma_rd_hq_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_dat
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_dat cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_dat_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_sel
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_sel cvmx_bbp_rx1_turbodec_dma_rd_hq_debug_sel_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_clear
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_clear cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_clear_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_enb
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_enb cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_enb_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_rstatus
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_rstatus cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_status
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_status cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_test
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_test cvmx_bbp_rx1_turbodec_dma_rd_hq_intr_test_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_memclr_data
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_memclr_data cvmx_bbp_rx1_turbodec_dma_rd_hq_memclr_data_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_mode
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_mode cvmx_bbp_rx1_turbodec_dma_rd_hq_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_pri_mode
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_pri_mode cvmx_bbp_rx1_turbodec_dma_rd_hq_pri_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_start_addr0 cvmx_bbp_rx1_turbodec_dma_rd_hq_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_status
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_status cvmx_bbp_rx1_turbodec_dma_rd_hq_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_mode_count
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_mode_count cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_q_status
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_q_status cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_start
 */
union cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_start cvmx_bbp_rx1_turbodec_dma_rd_hq_xfer_start_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_intr_clear
 */
union cvmx_bbp_rx1_turbodec_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_intr_clear cvmx_bbp_rx1_turbodec_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_intr_enb
 */
union cvmx_bbp_rx1_turbodec_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_intr_enb cvmx_bbp_rx1_turbodec_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx1_turbodec_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_intr_rstatus cvmx_bbp_rx1_turbodec_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_intr_status
 */
union cvmx_bbp_rx1_turbodec_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_intr_status cvmx_bbp_rx1_turbodec_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_intr_test
 */
union cvmx_bbp_rx1_turbodec_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_intr_test cvmx_bbp_rx1_turbodec_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_memclr_data
 */
union cvmx_bbp_rx1_turbodec_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_memclr_data cvmx_bbp_rx1_turbodec_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_mode
 */
union cvmx_bbp_rx1_turbodec_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_mode cvmx_bbp_rx1_turbodec_dma_rd_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_pri_mode
 */
union cvmx_bbp_rx1_turbodec_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_pri_mode cvmx_bbp_rx1_turbodec_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_start_addr0 cvmx_bbp_rx1_turbodec_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_status
 */
union cvmx_bbp_rx1_turbodec_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_status cvmx_bbp_rx1_turbodec_dma_rd_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx1_turbodec_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_xfer_mode_count cvmx_bbp_rx1_turbodec_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx1_turbodec_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_xfer_q_status cvmx_bbp_rx1_turbodec_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_rd_xfer_start
 */
union cvmx_bbp_rx1_turbodec_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_rd_xfer_start cvmx_bbp_rx1_turbodec_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_cbuf_end_addr0 cvmx_bbp_rx1_turbodec_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_cbuf_start_addr0 cvmx_bbp_rx1_turbodec_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_debug_dat
 */
union cvmx_bbp_rx1_turbodec_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_debug_dat cvmx_bbp_rx1_turbodec_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_debug_sel
 */
union cvmx_bbp_rx1_turbodec_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_debug_sel cvmx_bbp_rx1_turbodec_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_end_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_end_addr0 cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_start_addr0 cvmx_bbp_rx1_turbodec_dma_wr_hq_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_dat
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_dat cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_dat_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_sel
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_sel cvmx_bbp_rx1_turbodec_dma_wr_hq_debug_sel_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_clear
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_clear cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_clear_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_enb
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_enb cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_enb_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_rstatus
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_rstatus cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_status cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_test
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_test cvmx_bbp_rx1_turbodec_dma_wr_hq_intr_test_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_memclr_data
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_memclr_data cvmx_bbp_rx1_turbodec_dma_wr_hq_memclr_data_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_mode
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_mode cvmx_bbp_rx1_turbodec_dma_wr_hq_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_pri_mode
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_pri_mode cvmx_bbp_rx1_turbodec_dma_wr_hq_pri_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_start_addr0 cvmx_bbp_rx1_turbodec_dma_wr_hq_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_status cvmx_bbp_rx1_turbodec_dma_wr_hq_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_mode_count
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_mode_count cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_q_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_q_status cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_start
 */
union cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_start cvmx_bbp_rx1_turbodec_dma_wr_hq_xfer_start_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_intr_clear
 */
union cvmx_bbp_rx1_turbodec_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_intr_clear cvmx_bbp_rx1_turbodec_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_intr_enb
 */
union cvmx_bbp_rx1_turbodec_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_intr_enb cvmx_bbp_rx1_turbodec_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx1_turbodec_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_intr_rstatus cvmx_bbp_rx1_turbodec_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_intr_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_intr_status cvmx_bbp_rx1_turbodec_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_intr_test
 */
union cvmx_bbp_rx1_turbodec_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_intr_test cvmx_bbp_rx1_turbodec_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_memclr_data
 */
union cvmx_bbp_rx1_turbodec_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_memclr_data cvmx_bbp_rx1_turbodec_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_mode
 */
union cvmx_bbp_rx1_turbodec_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_mode cvmx_bbp_rx1_turbodec_dma_wr_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_pri_mode
 */
union cvmx_bbp_rx1_turbodec_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_pri_mode cvmx_bbp_rx1_turbodec_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_end_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_end_addr0 cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_start_addr0 cvmx_bbp_rx1_turbodec_dma_wr_sb_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_dat
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_dat cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_dat_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_sel
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_sel cvmx_bbp_rx1_turbodec_dma_wr_sb_debug_sel_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_clear
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_clear cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_clear_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_enb
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_enb cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_enb_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_rstatus
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_rstatus cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_status cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_test
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_test cvmx_bbp_rx1_turbodec_dma_wr_sb_intr_test_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_memclr_data
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_memclr_data cvmx_bbp_rx1_turbodec_dma_wr_sb_memclr_data_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_mode
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_mode cvmx_bbp_rx1_turbodec_dma_wr_sb_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_pri_mode
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_pri_mode cvmx_bbp_rx1_turbodec_dma_wr_sb_pri_mode_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_start_addr0 cvmx_bbp_rx1_turbodec_dma_wr_sb_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_status cvmx_bbp_rx1_turbodec_dma_wr_sb_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_mode_count
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_mode_count cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_q_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_q_status cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_start
 */
union cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_start cvmx_bbp_rx1_turbodec_dma_wr_sb_xfer_start_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_start_addr0
 */
union cvmx_bbp_rx1_turbodec_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_start_addr0 cvmx_bbp_rx1_turbodec_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_status cvmx_bbp_rx1_turbodec_dma_wr_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx1_turbodec_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_xfer_mode_count cvmx_bbp_rx1_turbodec_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx1_turbodec_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_xfer_q_status cvmx_bbp_rx1_turbodec_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_turbodec_dma_wr_xfer_start
 */
union cvmx_bbp_rx1_turbodec_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_turbodec_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_turbodec_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_turbodec_dma_wr_xfer_start cvmx_bbp_rx1_turbodec_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_rx1_vdec_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_cbuf_end_addr0 cvmx_bbp_rx1_vdec_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_rx1_vdec_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_cbuf_start_addr0 cvmx_bbp_rx1_vdec_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_debug_dat
 */
union cvmx_bbp_rx1_vdec_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_debug_dat cvmx_bbp_rx1_vdec_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_debug_sel
 */
union cvmx_bbp_rx1_vdec_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_debug_sel cvmx_bbp_rx1_vdec_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_intr_clear
 */
union cvmx_bbp_rx1_vdec_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_intr_clear cvmx_bbp_rx1_vdec_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_intr_enb
 */
union cvmx_bbp_rx1_vdec_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_intr_enb cvmx_bbp_rx1_vdec_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_intr_rstatus
 */
union cvmx_bbp_rx1_vdec_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_intr_rstatus cvmx_bbp_rx1_vdec_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_intr_status
 */
union cvmx_bbp_rx1_vdec_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_intr_status cvmx_bbp_rx1_vdec_dma_rd_intr_status_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_intr_test
 */
union cvmx_bbp_rx1_vdec_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_intr_test cvmx_bbp_rx1_vdec_dma_rd_intr_test_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_memclr_data
 */
union cvmx_bbp_rx1_vdec_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_memclr_data cvmx_bbp_rx1_vdec_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_mode
 */
union cvmx_bbp_rx1_vdec_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_mode cvmx_bbp_rx1_vdec_dma_rd_mode_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_pri_mode
 */
union cvmx_bbp_rx1_vdec_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_pri_mode cvmx_bbp_rx1_vdec_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_start_addr0
 */
union cvmx_bbp_rx1_vdec_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_start_addr0 cvmx_bbp_rx1_vdec_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_status
 */
union cvmx_bbp_rx1_vdec_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_status cvmx_bbp_rx1_vdec_dma_rd_status_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_xfer_mode_count
 */
union cvmx_bbp_rx1_vdec_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_xfer_mode_count cvmx_bbp_rx1_vdec_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_xfer_q_status
 */
union cvmx_bbp_rx1_vdec_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_xfer_q_status cvmx_bbp_rx1_vdec_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_vdec_dma_rd_xfer_start
 */
union cvmx_bbp_rx1_vdec_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_rd_xfer_start cvmx_bbp_rx1_vdec_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_rx1_vdec_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_cbuf_end_addr0 cvmx_bbp_rx1_vdec_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_rx1_vdec_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_cbuf_start_addr0 cvmx_bbp_rx1_vdec_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_debug_dat
 */
union cvmx_bbp_rx1_vdec_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_debug_dat cvmx_bbp_rx1_vdec_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_debug_sel
 */
union cvmx_bbp_rx1_vdec_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_debug_sel cvmx_bbp_rx1_vdec_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_intr_clear
 */
union cvmx_bbp_rx1_vdec_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_intr_clear cvmx_bbp_rx1_vdec_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_intr_enb
 */
union cvmx_bbp_rx1_vdec_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_intr_enb cvmx_bbp_rx1_vdec_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_intr_rstatus
 */
union cvmx_bbp_rx1_vdec_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_intr_rstatus cvmx_bbp_rx1_vdec_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_intr_status
 */
union cvmx_bbp_rx1_vdec_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_intr_status cvmx_bbp_rx1_vdec_dma_wr_intr_status_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_intr_test
 */
union cvmx_bbp_rx1_vdec_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_intr_test cvmx_bbp_rx1_vdec_dma_wr_intr_test_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_memclr_data
 */
union cvmx_bbp_rx1_vdec_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_memclr_data cvmx_bbp_rx1_vdec_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_mode
 */
union cvmx_bbp_rx1_vdec_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_mode cvmx_bbp_rx1_vdec_dma_wr_mode_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_pri_mode
 */
union cvmx_bbp_rx1_vdec_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_pri_mode cvmx_bbp_rx1_vdec_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_start_addr0
 */
union cvmx_bbp_rx1_vdec_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_start_addr0 cvmx_bbp_rx1_vdec_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_status
 */
union cvmx_bbp_rx1_vdec_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_status cvmx_bbp_rx1_vdec_dma_wr_status_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_xfer_mode_count
 */
union cvmx_bbp_rx1_vdec_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_xfer_mode_count cvmx_bbp_rx1_vdec_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_xfer_q_status
 */
union cvmx_bbp_rx1_vdec_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_xfer_q_status cvmx_bbp_rx1_vdec_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_rx1_vdec_dma_wr_xfer_start
 */
union cvmx_bbp_rx1_vdec_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_rx1_vdec_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1_vdec_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_rx1_vdec_dma_wr_xfer_start cvmx_bbp_rx1_vdec_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_rx1int_cntl_hi#
 *
 * RX1INT_CNTL_HI - Interrupt Enable HI
 *
 */
union cvmx_bbp_rx1int_cntl_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_cntl_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enab                         : 1;  /**< Interrupt Enable */
#else
	uint32_t enab                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1int_cntl_hix_s     cnf71xx;
};
typedef union cvmx_bbp_rx1int_cntl_hix cvmx_bbp_rx1int_cntl_hix_t;

/**
 * cvmx_bbp_rx1int_cntl_lo#
 *
 * RX1INT_CNTL_LO - Interrupt Enable LO
 *
 */
union cvmx_bbp_rx1int_cntl_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_cntl_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enab                         : 1;  /**< Interrupt Enable */
#else
	uint32_t enab                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1int_cntl_lox_s     cnf71xx;
};
typedef union cvmx_bbp_rx1int_cntl_lox cvmx_bbp_rx1int_cntl_lox_t;

/**
 * cvmx_bbp_rx1int_index_hi#
 *
 * RX1INT_INDEX_HI - Overall Index HI
 *
 */
union cvmx_bbp_rx1int_index_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_index_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t index                        : 9;  /**< Overall Interrup Index */
#else
	uint32_t index                        : 9;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rx1int_index_hix_s    cnf71xx;
};
typedef union cvmx_bbp_rx1int_index_hix cvmx_bbp_rx1int_index_hix_t;

/**
 * cvmx_bbp_rx1int_index_lo#
 *
 * RX1INT_INDEX_LO - Overall Index LO
 *
 */
union cvmx_bbp_rx1int_index_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_index_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t index                        : 9;  /**< Overall Interrup Index */
#else
	uint32_t index                        : 9;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_rx1int_index_lox_s    cnf71xx;
};
typedef union cvmx_bbp_rx1int_index_lox cvmx_bbp_rx1int_index_lox_t;

/**
 * cvmx_bbp_rx1int_misc_idx_hi#
 *
 * RX1INT_MISC_IDX_HI - Misc Group Index HI
 *
 */
union cvmx_bbp_rx1int_misc_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Misc Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_idx_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_idx_hix cvmx_bbp_rx1int_misc_idx_hix_t;

/**
 * cvmx_bbp_rx1int_misc_idx_lo#
 *
 * RX1INT_MISC_IDX_LO - Misc Group Index LO
 *
 */
union cvmx_bbp_rx1int_misc_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Misc Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_idx_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_idx_lox cvmx_bbp_rx1int_misc_idx_lox_t;

/**
 * cvmx_bbp_rx1int_misc_mask_hi#
 *
 * RX1INT_MISC_MASK_HI = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx1int_misc_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_mask_hix cvmx_bbp_rx1int_misc_mask_hix_t;

/**
 * cvmx_bbp_rx1int_misc_mask_lo#
 *
 * RX1INT_MISC_MASK_LO = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx1int_misc_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_mask_lox cvmx_bbp_rx1int_misc_mask_lox_t;

/**
 * cvmx_bbp_rx1int_misc_rint
 *
 * RX1INT_MISC_RINT - MISC Raw Interrupt Status
 *
 */
union cvmx_bbp_rx1int_misc_rint {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_rint_s    cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_rint cvmx_bbp_rx1int_misc_rint_t;

/**
 * cvmx_bbp_rx1int_misc_status_hi#
 *
 * RX1INT_MISC_STATUS_HI = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx1int_misc_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_status_hix cvmx_bbp_rx1int_misc_status_hix_t;

/**
 * cvmx_bbp_rx1int_misc_status_lo#
 *
 * RX1INT_MISC_STATUS_LO = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_rx1int_misc_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_misc_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_rx_ppssync                : 1;  /**< RX PPS Sync Done */
	uint32_t rf_rx_spiskip                : 1;  /**< RX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_rx_strx                   : 1;  /**< RX Start RX */
	uint32_t rf_rx_stframe                : 1;  /**< RX Start Frame */
	uint32_t rf_rxd_ffflag                : 1;  /**< RX DIV FIFO flags asserted */
	uint32_t rf_rxd_ffthresh              : 1;  /**< RX DIV FIFO Threshhold reached */
	uint32_t rf_rx_ffflag                 : 1;  /**< RX FIFO flags asserted */
	uint32_t rf_rx_ffthresh               : 1;  /**< RX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_rx_ffthresh               : 1;
	uint32_t rf_rx_ffflag                 : 1;
	uint32_t rf_rxd_ffthresh              : 1;
	uint32_t rf_rxd_ffflag                : 1;
	uint32_t rf_rx_stframe                : 1;
	uint32_t rf_rx_strx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_rx_spiskip                : 1;
	uint32_t rf_rx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_rx1int_misc_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_misc_status_lox cvmx_bbp_rx1int_misc_status_lox_t;

/**
 * cvmx_bbp_rx1int_rd_idx_hi#
 *
 * RX1INT_RD_IDX_HI - Read Done Group Index HI
 *
 */
union cvmx_bbp_rx1int_rd_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_idx_hix cvmx_bbp_rx1int_rd_idx_hix_t;

/**
 * cvmx_bbp_rx1int_rd_idx_lo#
 *
 * RX1INT_RD_IDX_LO - Read Done Group Index LO
 *
 */
union cvmx_bbp_rx1int_rd_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_idx_lox cvmx_bbp_rx1int_rd_idx_lox_t;

/**
 * cvmx_bbp_rx1int_rd_mask_hi#
 *
 * RX1INT_RD_MASK_HI = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx1int_rd_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX1 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_mask_hix cvmx_bbp_rx1int_rd_mask_hix_t;

/**
 * cvmx_bbp_rx1int_rd_mask_lo#
 *
 * RX1INT_RD_MASK_LO = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx1int_rd_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX1 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_mask_lox cvmx_bbp_rx1int_rd_mask_lox_t;

/**
 * cvmx_bbp_rx1int_rd_rint
 *
 * RX1INT_RD_RINT - Read Done Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx1int_rd_rint {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX1 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_rint_s      cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_rint cvmx_bbp_rx1int_rd_rint_t;

/**
 * cvmx_bbp_rx1int_rd_status_hi#
 *
 * RX1INT_RD_STATUS_HI = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx1int_rd_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX1 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_status_hix cvmx_bbp_rx1int_rd_status_hix_t;

/**
 * cvmx_bbp_rx1int_rd_status_lo#
 *
 * RX1INT_RD_STATUS_LO = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_rx1int_rd_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rd_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t1seq_intr                   : 8;  /**< RX1 Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t1seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_rx1int_rd_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_rd_status_lox cvmx_bbp_rx1int_rd_status_lox_t;

/**
 * cvmx_bbp_rx1int_rdq_idx_hi#
 *
 * RX1INT_RDQ_IDX_HI - Read Queue Empty Group Index HI
 *
 */
union cvmx_bbp_rx1int_rdq_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_idx_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_idx_hix cvmx_bbp_rx1int_rdq_idx_hix_t;

/**
 * cvmx_bbp_rx1int_rdq_idx_lo#
 *
 * RX1INT_RDQ_IDX_LO - Read Queue Empty Group Index LO
 *
 */
union cvmx_bbp_rx1int_rdq_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_idx_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_idx_lox cvmx_bbp_rx1int_rdq_idx_lox_t;

/**
 * cvmx_bbp_rx1int_rdq_mask_hi#
 *
 * RX1INT_RDQ_MASK_HI = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_rdq_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_mask_hix cvmx_bbp_rx1int_rdq_mask_hix_t;

/**
 * cvmx_bbp_rx1int_rdq_mask_lo#
 *
 * RX1INT_RDQ_MASK_LO = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_rdq_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_mask_lox cvmx_bbp_rx1int_rdq_mask_lox_t;

/**
 * cvmx_bbp_rx1int_rdq_rint
 *
 * RX1INT_RDQ_RINT - Read Queue Empty Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx1int_rdq_rint {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty Raw */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty Raw */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty Raw */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty Raw */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty Raw */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty Raw */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty Raw */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty Raw */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty Raw */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty Raw */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty Raw */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty Raw */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty Raw */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty Raw */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty Raw */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty Raw */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty Raw */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty Raw */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_rint_s     cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_rint cvmx_bbp_rx1int_rdq_rint_t;

/**
 * cvmx_bbp_rx1int_rdq_status_hi#
 *
 * RX1INT_RDQ_STATUS_HI = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_rdq_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_status_hix cvmx_bbp_rx1int_rdq_status_hix_t;

/**
 * cvmx_bbp_rx1int_rdq_status_lo#
 *
 * RX1INT_RDQ_STATUS_LO = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_rdq_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_rdq_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_rx1int_rdq_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_rdq_status_lox cvmx_bbp_rx1int_rdq_status_lox_t;

/**
 * cvmx_bbp_rx1int_stat_hi#
 *
 * RX1INT_STAT_HI - Grouped Interrupt Status HI
 *
 */
union cvmx_bbp_rx1int_stat_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_stat_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t misc                         : 1;  /**< Misc Group Interrupt */
	uint32_t sw                           : 1;  /**< SW Group Interrupt */
	uint32_t wrqdone                      : 1;  /**< Write Queue Empty Group Interrupt */
	uint32_t rdqdone                      : 1;  /**< Read  Queue Empty Group Interrupt */
	uint32_t rddone                       : 1;  /**< Read  Done Group Interrupt */
	uint32_t wrdone                       : 1;  /**< Write Done Group Interrupt */
#else
	uint32_t wrdone                       : 1;
	uint32_t rddone                       : 1;
	uint32_t rdqdone                      : 1;
	uint32_t wrqdone                      : 1;
	uint32_t sw                           : 1;
	uint32_t misc                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_stat_hix_s     cnf71xx;
};
typedef union cvmx_bbp_rx1int_stat_hix cvmx_bbp_rx1int_stat_hix_t;

/**
 * cvmx_bbp_rx1int_stat_lo#
 *
 * RX1INT_STAT_LO - Grouped Interrupt Status LO
 *
 */
union cvmx_bbp_rx1int_stat_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_stat_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t misc                         : 1;  /**< Misc Group Interrupt */
	uint32_t sw                           : 1;  /**< SW Group Interrupt */
	uint32_t wrqdone                      : 1;  /**< Write Queue Empty Group Interrupt */
	uint32_t rdqdone                      : 1;  /**< Read  Queue Empty Group Interrupt */
	uint32_t rddone                       : 1;  /**< Read  Done Group Interrupt */
	uint32_t wrdone                       : 1;  /**< Write Done Group Interrupt */
#else
	uint32_t wrdone                       : 1;
	uint32_t rddone                       : 1;
	uint32_t rdqdone                      : 1;
	uint32_t wrqdone                      : 1;
	uint32_t sw                           : 1;
	uint32_t misc                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_stat_lox_s     cnf71xx;
};
typedef union cvmx_bbp_rx1int_stat_lox cvmx_bbp_rx1int_stat_lox_t;

/**
 * cvmx_bbp_rx1int_sw_idx_hi#
 *
 * RX1INT_SW_IDX_HI - SW Group Index HI
 *
 */
union cvmx_bbp_rx1int_sw_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< SW Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_idx_hix cvmx_bbp_rx1int_sw_idx_hix_t;

/**
 * cvmx_bbp_rx1int_sw_idx_lo#
 *
 * RX1INT_SW_IDX_LO - SW Group Index LO
 *
 */
union cvmx_bbp_rx1int_sw_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< SW Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_idx_lox cvmx_bbp_rx1int_sw_idx_lox_t;

/**
 * cvmx_bbp_rx1int_sw_mask_hi#
 *
 * RX1INT_SW_MASK_HI = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx1int_sw_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_mask_hix cvmx_bbp_rx1int_sw_mask_hix_t;

/**
 * cvmx_bbp_rx1int_sw_mask_lo#
 *
 * RX1INT_SW_MASK_LO = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx1int_sw_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_mask_lox cvmx_bbp_rx1int_sw_mask_lox_t;

/**
 * cvmx_bbp_rx1int_sw_rint
 *
 * RX1INT_SW_RINT - SW Raw Interrupt Status
 *
 */
union cvmx_bbp_rx1int_sw_rint {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_rint_s      cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_rint cvmx_bbp_rx1int_sw_rint_t;

/**
 * cvmx_bbp_rx1int_sw_status_hi#
 *
 * RX1INT_SW_STATUS_HI = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx1int_sw_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_status_hix cvmx_bbp_rx1int_sw_status_hix_t;

/**
 * cvmx_bbp_rx1int_sw_status_lo#
 *
 * RX1INT_SW_STATUS_LO = Interrupt SW Mask
 *
 */
union cvmx_bbp_rx1int_sw_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_sw_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_sw_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_sw_status_lox cvmx_bbp_rx1int_sw_status_lox_t;

/**
 * cvmx_bbp_rx1int_swclr
 *
 * RX1INT_SWCLR- SW Interrupt Clear
 *
 */
union cvmx_bbp_rx1int_swclr {
	uint32_t u32;
	struct cvmx_bbp_rx1int_swclr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t clr                          : 32; /**< Clear SW Interrupt bit */
#else
	uint32_t clr                          : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_swclr_s        cnf71xx;
};
typedef union cvmx_bbp_rx1int_swclr cvmx_bbp_rx1int_swclr_t;

/**
 * cvmx_bbp_rx1int_swset
 *
 * RX1INT_SWSET - SW Interrupt Set
 *
 */
union cvmx_bbp_rx1int_swset {
	uint32_t u32;
	struct cvmx_bbp_rx1int_swset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t set                          : 32; /**< Set SW Interrupt bit */
#else
	uint32_t set                          : 32;
#endif
	} s;
	struct cvmx_bbp_rx1int_swset_s        cnf71xx;
};
typedef union cvmx_bbp_rx1int_swset cvmx_bbp_rx1int_swset_t;

/**
 * cvmx_bbp_rx1int_wr_idx_hi#
 *
 * RX1INT_WR_IDX_HI - Write Done Group Index HI
 *
 */
union cvmx_bbp_rx1int_wr_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_idx_hix cvmx_bbp_rx1int_wr_idx_hix_t;

/**
 * cvmx_bbp_rx1int_wr_idx_lo#
 *
 * RX1INT_WR_IDX_LO - Write Done Group Index LO
 *
 */
union cvmx_bbp_rx1int_wr_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_idx_lox cvmx_bbp_rx1int_wr_idx_lox_t;

/**
 * cvmx_bbp_rx1int_wr_mask_hi#
 *
 * RX1INT_WR_MASK_HI = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_rx1int_wr_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_mask_hix cvmx_bbp_rx1int_wr_mask_hix_t;

/**
 * cvmx_bbp_rx1int_wr_mask_lo#
 *
 * &BBP_DID_ID         = 0x6F007F840000
 *
 * RX1INT_WR_MASK_LO = Interrupt Write Done Group Mask
 */
union cvmx_bbp_rx1int_wr_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_mask_lox cvmx_bbp_rx1int_wr_mask_lox_t;

/**
 * cvmx_bbp_rx1int_wr_rint
 *
 * RX1INT_WR_RINT - Write Done Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx1int_wr_rint {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_rint_s      cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_rint cvmx_bbp_rx1int_wr_rint_t;

/**
 * cvmx_bbp_rx1int_wr_status_hi#
 *
 * RX1INT_WR_STATUS_HI = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_rx1int_wr_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_status_hix cvmx_bbp_rx1int_wr_status_hix_t;

/**
 * cvmx_bbp_rx1int_wr_status_lo#
 *
 * RX1INT_WR_STATUS_LO = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_rx1int_wr_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wr_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_rx1int_wr_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_wr_status_lox cvmx_bbp_rx1int_wr_status_lox_t;

/**
 * cvmx_bbp_rx1int_wrq_idx_hi#
 *
 * RX1INT_WRQ_IDX_HI - Write Queue Empty Group Index HI
 *
 */
union cvmx_bbp_rx1int_wrq_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_idx_hix_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_idx_hix cvmx_bbp_rx1int_wrq_idx_hix_t;

/**
 * cvmx_bbp_rx1int_wrq_idx_lo#
 *
 * RX1INT_WRQ_IDX_LO - Write Queue Empty Group Index LO
 *
 */
union cvmx_bbp_rx1int_wrq_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_idx_lox_s  cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_idx_lox cvmx_bbp_rx1int_wrq_idx_lox_t;

/**
 * cvmx_bbp_rx1int_wrq_mask_hi#
 *
 * RX1INT_WRQ_MASK_HI = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_wrq_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_mask_hix cvmx_bbp_rx1int_wrq_mask_hix_t;

/**
 * cvmx_bbp_rx1int_wrq_mask_lo#
 *
 * RX1INT_WRQ_MASK_LO = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_wrq_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_mask_lox cvmx_bbp_rx1int_wrq_mask_lox_t;

/**
 * cvmx_bbp_rx1int_wrq_rint
 *
 * RX1INT_WRQ_RINT - Write Queue Empty Group Raw Interrupt Status
 *
 */
union cvmx_bbp_rx1int_wrq_rint {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty Raw */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty Raw */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty Raw */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty Raw */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty Raw */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty Raw */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty Raw */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty Raw */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty Raw */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty Raw */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty Raw */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty Raw */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty Raw */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty Raw */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty Raw */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty Raw */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty Raw */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty Raw */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty Raw */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty Raw */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty Raw */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty Raw */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty Raw */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_rint_s     cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_rint cvmx_bbp_rx1int_wrq_rint_t;

/**
 * cvmx_bbp_rx1int_wrq_status_hi#
 *
 * RX1INT_WRQ_STATUS_HI = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_wrq_status_hix {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_status_hix cvmx_bbp_rx1int_wrq_status_hix_t;

/**
 * cvmx_bbp_rx1int_wrq_status_lo#
 *
 * RX1INT_WRQ_STATUS_LO = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_rx1int_wrq_status_lox {
	uint32_t u32;
	struct cvmx_bbp_rx1int_wrq_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_rx1int_wrq_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_rx1int_wrq_status_lox cvmx_bbp_rx1int_wrq_status_lox_t;

/**
 * cvmx_bbp_rx1seq_autogate
 */
union cvmx_bbp_rx1seq_autogate {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_autogate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t auto_gate                    : 1;  /**< 1==enable auto-clock-gating */
#else
	uint32_t auto_gate                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_rx1seq_autogate_s     cnf71xx;
};
typedef union cvmx_bbp_rx1seq_autogate cvmx_bbp_rx1seq_autogate_t;

/**
 * cvmx_bbp_rx1seq_gpi_rd00
 */
union cvmx_bbp_rx1seq_gpi_rd00 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_gpi_rd00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t harqdma_wr_done              : 1;  /**< HARQDMA WR done int */
	uint32_t extdma_wr_done               : 1;  /**< EXTDMA WR done int */
	uint32_t turbo_hq_wr_done             : 1;  /**< Turbo HARQ WR done int */
	uint32_t turbo_sb_wr_done             : 1;  /**< Turbo Soft Bits WR done int */
	uint32_t turbo_wr_done                : 1;  /**< Turbo WR done int */
	uint32_t edma_wr2_done                : 1;  /**< EDMA WR2 done int */
	uint32_t intdma_rd_done               : 1;  /**< INTDMA RD done int */
	uint32_t harqdma_rd_done              : 1;  /**< HARQDMA RD done int */
	uint32_t extdma_rd_done               : 1;  /**< EXTDMA RD done int */
	uint32_t turbo_hq_rd_done             : 1;  /**< Turbo HARQ RD done int */
	uint32_t turbo_rd_done                : 1;  /**< Turbo RD done int */
	uint32_t rfif_spi_int                 : 1;  /**< RFIF SPI int */
	uint32_t rfif_rx_ints                 : 12; /**< RFIF RX ints */
	uint32_t tti_timer                    : 8;  /**< TTI Timer ints from RFIF */
#else
	uint32_t tti_timer                    : 8;
	uint32_t rfif_rx_ints                 : 12;
	uint32_t rfif_spi_int                 : 1;
	uint32_t turbo_rd_done                : 1;
	uint32_t turbo_hq_rd_done             : 1;
	uint32_t extdma_rd_done               : 1;
	uint32_t harqdma_rd_done              : 1;
	uint32_t intdma_rd_done               : 1;
	uint32_t edma_wr2_done                : 1;
	uint32_t turbo_wr_done                : 1;
	uint32_t turbo_sb_wr_done             : 1;
	uint32_t turbo_hq_wr_done             : 1;
	uint32_t extdma_wr_done               : 1;
	uint32_t harqdma_wr_done              : 1;
#endif
	} s;
	struct cvmx_bbp_rx1seq_gpi_rd00_s     cnf71xx;
};
typedef union cvmx_bbp_rx1seq_gpi_rd00 cvmx_bbp_rx1seq_gpi_rd00_t;

/**
 * cvmx_bbp_rx1seq_gpi_rd01
 */
union cvmx_bbp_rx1seq_gpi_rd01 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_gpi_rd01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 25; /**< SEQ loopbacks from GPO. */
	uint32_t vdec_done                    : 1;  /**< Viterbi DONE int, from HAB */
	uint32_t turbo_rdy_new_blk            : 1;  /**< Turbo ready for next block int, from HAB */
	uint32_t turbo_done_int               : 1;  /**< Turbo DONE int, from HAB */
	uint32_t turbo_wr_empty               : 1;  /**< Turbo WR done int */
	uint32_t edma_wr6_done                : 1;  /**< EDMA WR6 done int */
	uint32_t reserved_1_1                 : 1;
	uint32_t intdma_wr_done               : 1;  /**< INTDMA WR done int */
#else
	uint32_t intdma_wr_done               : 1;
	uint32_t reserved_1_1                 : 1;
	uint32_t edma_wr6_done                : 1;
	uint32_t turbo_wr_empty               : 1;
	uint32_t turbo_done_int               : 1;
	uint32_t turbo_rdy_new_blk            : 1;
	uint32_t vdec_done                    : 1;
	uint32_t gpi_loopback                 : 25;
#endif
	} s;
	struct cvmx_bbp_rx1seq_gpi_rd01_s     cnf71xx;
};
typedef union cvmx_bbp_rx1seq_gpi_rd01 cvmx_bbp_rx1seq_gpi_rd01_t;

/**
 * cvmx_bbp_rx1seq_gpo_clr00
 */
union cvmx_bbp_rx1seq_gpo_clr00 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_gpo_clr00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t t2seq_intr                   : 8;  /**< SEQ interrupt outputs.  Write 1 to clear, 0 to leave alone */
#else
	uint32_t t2seq_intr                   : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1seq_gpo_clr00_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_gpo_clr00 cvmx_bbp_rx1seq_gpo_clr00_t;

/**
 * cvmx_bbp_rx1seq_gpo_clr01
 */
union cvmx_bbp_rx1seq_gpo_clr01 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_gpo_clr01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 25; /**< SEQ loopbacks to GPI.   Write 1 to clear, 0 to leave alone */
	uint32_t reserved_0_6                 : 7;
#else
	uint32_t reserved_0_6                 : 7;
	uint32_t gpi_loopback                 : 25;
#endif
	} s;
	struct cvmx_bbp_rx1seq_gpo_clr01_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_gpo_clr01 cvmx_bbp_rx1seq_gpo_clr01_t;

/**
 * cvmx_bbp_rx1seq_gpo_set00
 */
union cvmx_bbp_rx1seq_gpo_set00 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_gpo_set00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t t2seq_intr                   : 8;  /**< SEQ interrupt outputs.  Write 1 to set, 0 to leave alone */
#else
	uint32_t t2seq_intr                   : 8;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_rx1seq_gpo_set00_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_gpo_set00 cvmx_bbp_rx1seq_gpo_set00_t;

/**
 * cvmx_bbp_rx1seq_gpo_set01
 */
union cvmx_bbp_rx1seq_gpo_set01 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_gpo_set01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 25; /**< SEQ loopbacks to GPI.   Write 1 to set, 0 to leave alone */
	uint32_t reserved_0_6                 : 7;
#else
	uint32_t reserved_0_6                 : 7;
	uint32_t gpi_loopback                 : 25;
#endif
	} s;
	struct cvmx_bbp_rx1seq_gpo_set01_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_gpo_set01 cvmx_bbp_rx1seq_gpo_set01_t;

/**
 * cvmx_bbp_rx1seq_param0
 */
union cvmx_bbp_rx1seq_param0 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_param0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_25_31               : 7;
	uint32_t autorun                      : 1;  /**< Autorun parameter value */
	uint32_t reserved_17_23               : 7;
	uint32_t seq_base_addr                : 17; /**< Base address parameter value */
#else
	uint32_t seq_base_addr                : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t autorun                      : 1;
	uint32_t reserved_25_31               : 7;
#endif
	} s;
	struct cvmx_bbp_rx1seq_param0_s       cnf71xx;
};
typedef union cvmx_bbp_rx1seq_param0 cvmx_bbp_rx1seq_param0_t;

/**
 * cvmx_bbp_rx1seq_param1
 */
union cvmx_bbp_rx1seq_param1 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_param1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_21_31               : 11;
	uint32_t thrd_max                     : 5;  /**< Thread max parameter value */
	uint32_t gpio_out_max                 : 8;  /**< GPIO out max parameter value */
	uint32_t gpio_in_max                  : 8;  /**< GPIO in max parameter value */
#else
	uint32_t gpio_in_max                  : 8;
	uint32_t gpio_out_max                 : 8;
	uint32_t thrd_max                     : 5;
	uint32_t reserved_21_31               : 11;
#endif
	} s;
	struct cvmx_bbp_rx1seq_param1_s       cnf71xx;
};
typedef union cvmx_bbp_rx1seq_param1 cvmx_bbp_rx1seq_param1_t;

/**
 * cvmx_bbp_rx1seq_ramacc
 */
union cvmx_bbp_rx1seq_ramacc {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_ramacc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t ram_read_addr                : 14; /**< Command RAM read address -- when reading from Command
                                                         RAM, write this register with the Command Address and
                                                         read back this register until the read value returns
                                                         the requested address.  Then the read data is ready in
                                                         the RAMRD_LSW and RAMRD_MSW registers (following). */
	uint32_t reserved_0_2                 : 3;
#else
	uint32_t reserved_0_2                 : 3;
	uint32_t ram_read_addr                : 14;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_rx1seq_ramacc_s       cnf71xx;
};
typedef union cvmx_bbp_rx1seq_ramacc cvmx_bbp_rx1seq_ramacc_t;

/**
 * cvmx_bbp_rx1seq_ramrd_lsw
 */
union cvmx_bbp_rx1seq_ramrd_lsw {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_ramrd_lsw_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t cmd_ram_lsw                  : 12; /**< LSW of data read from command RAM */
#else
	uint32_t cmd_ram_lsw                  : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_rx1seq_ramrd_lsw_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_ramrd_lsw cvmx_bbp_rx1seq_ramrd_lsw_t;

/**
 * cvmx_bbp_rx1seq_ramrd_msw
 */
union cvmx_bbp_rx1seq_ramrd_msw {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_ramrd_msw_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t cmd_ram_msw                  : 32; /**< MSW of data read from command RAM */
#else
	uint32_t cmd_ram_msw                  : 32;
#endif
	} s;
	struct cvmx_bbp_rx1seq_ramrd_msw_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_ramrd_msw cvmx_bbp_rx1seq_ramrd_msw_t;

/**
 * cvmx_bbp_rx1seq_status
 */
union cvmx_bbp_rx1seq_status {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_21_31               : 11;
	uint32_t curthrd                      : 5;  /**< Currently active thread */
	uint32_t reserved_1_15                : 15;
	uint32_t seq_status                   : 1;  /**< 1==SEQ is not idle */
#else
	uint32_t seq_status                   : 1;
	uint32_t reserved_1_15                : 15;
	uint32_t curthrd                      : 5;
	uint32_t reserved_21_31               : 11;
#endif
	} s;
	struct cvmx_bbp_rx1seq_status_s       cnf71xx;
};
typedef union cvmx_bbp_rx1seq_status cvmx_bbp_rx1seq_status_t;

/**
 * cvmx_bbp_rx1seq_thrd#_cfg
 */
union cvmx_bbp_rx1seq_thrdx_cfg {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_thrdx_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_26_31               : 6;
	uint32_t thrd_wait_sts                : 2;  /**< Thread X wait status
                                                         0==not waiting
                                                         1==waiting for timer
                                                         2==waiting for GPIO low
                                                         3==waiting for GPIO high */
	uint32_t thrd_gpiowait                : 8;  /**< Thread X GPIO used as trigger */
	uint32_t reserved_2_15                : 14;
	uint32_t thrd_stat                    : 2;  /**< Thread X status
                                                         0==done
                                                         1==ready
                                                         2==active
                                                         3==wait */
#else
	uint32_t thrd_stat                    : 2;
	uint32_t reserved_2_15                : 14;
	uint32_t thrd_gpiowait                : 8;
	uint32_t thrd_wait_sts                : 2;
	uint32_t reserved_26_31               : 6;
#endif
	} s;
	struct cvmx_bbp_rx1seq_thrdx_cfg_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_thrdx_cfg cvmx_bbp_rx1seq_thrdx_cfg_t;

/**
 * cvmx_bbp_rx1seq_thrd#_pc
 */
union cvmx_bbp_rx1seq_thrdx_pc {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_thrdx_pc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t thrd_pc                      : 13; /**< Thread X PC (Program Counter) */
	uint32_t reserved_0_2                 : 3;
#else
	uint32_t reserved_0_2                 : 3;
	uint32_t thrd_pc                      : 13;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_rx1seq_thrdx_pc_s     cnf71xx;
};
typedef union cvmx_bbp_rx1seq_thrdx_pc cvmx_bbp_rx1seq_thrdx_pc_t;

/**
 * cvmx_bbp_rx1seq_thrdstat0
 */
union cvmx_bbp_rx1seq_thrdstat0 {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_thrdstat0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t thrd15_stat                  : 2;  /**< Thread 15 status */
	uint32_t thrd14_stat                  : 2;  /**< Thread 14 status */
	uint32_t thrd13_stat                  : 2;  /**< Thread 13 status */
	uint32_t thrd12_stat                  : 2;  /**< Thread 12 status */
	uint32_t thrd11_stat                  : 2;  /**< Thread 11 status */
	uint32_t thrd10_stat                  : 2;  /**< Thread 10 status */
	uint32_t thrd09_stat                  : 2;  /**< Thread 9 status */
	uint32_t thrd08_stat                  : 2;  /**< Thread 8 status */
	uint32_t thrd07_stat                  : 2;  /**< Thread 7 status */
	uint32_t thrd06_stat                  : 2;  /**< Thread 6 status */
	uint32_t thrd05_stat                  : 2;  /**< Thread 5 status */
	uint32_t thrd04_stat                  : 2;  /**< Thread 4 status */
	uint32_t thrd03_stat                  : 2;  /**< Thread 3 status */
	uint32_t thrd02_stat                  : 2;  /**< Thread 2 status */
	uint32_t thrd01_stat                  : 2;  /**< Thread 1 status */
	uint32_t thrd00_stat                  : 2;  /**< Thread 0 status
                                                         0==done
                                                         1==ready
                                                         2==active
                                                         3==wait */
#else
	uint32_t thrd00_stat                  : 2;
	uint32_t thrd01_stat                  : 2;
	uint32_t thrd02_stat                  : 2;
	uint32_t thrd03_stat                  : 2;
	uint32_t thrd04_stat                  : 2;
	uint32_t thrd05_stat                  : 2;
	uint32_t thrd06_stat                  : 2;
	uint32_t thrd07_stat                  : 2;
	uint32_t thrd08_stat                  : 2;
	uint32_t thrd09_stat                  : 2;
	uint32_t thrd10_stat                  : 2;
	uint32_t thrd11_stat                  : 2;
	uint32_t thrd12_stat                  : 2;
	uint32_t thrd13_stat                  : 2;
	uint32_t thrd14_stat                  : 2;
	uint32_t thrd15_stat                  : 2;
#endif
	} s;
	struct cvmx_bbp_rx1seq_thrdstat0_s    cnf71xx;
};
typedef union cvmx_bbp_rx1seq_thrdstat0 cvmx_bbp_rx1seq_thrdstat0_t;

/**
 * cvmx_bbp_rx1seq_timer
 */
union cvmx_bbp_rx1seq_timer {
	uint32_t u32;
	struct cvmx_bbp_rx1seq_timer_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t seq_timer                    : 32; /**< SEQ timer value - Normally set to a value specified by
                                                         the Wait for Timer command.  Will start counting down
                                                         until it hits 0 or until another Wait for Timer cmd is
                                                         issued.  Can be read to read current value or written to
                                                         overwrite count down value - but not a normal usage. */
#else
	uint32_t seq_timer                    : 32;
#endif
	} s;
	struct cvmx_bbp_rx1seq_timer_s        cnf71xx;
};
typedef union cvmx_bbp_rx1seq_timer cvmx_bbp_rx1seq_timer_t;

/**
 * cvmx_bbp_token_#
 */
union cvmx_bbp_token_x {
	uint32_t u32;
	struct cvmx_bbp_token_x_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t token_user                   : 4;  /**< reads: Proc_ID --> TOKEN_USER
                                                         writes: TOKEN_USER -> Proc_ID only if token available
                                                                 or Proc_ID match addr[11:8] */
#else
	uint32_t token_user                   : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_token_x_s             cnf71xx;
};
typedef union cvmx_bbp_token_x cvmx_bbp_token_x_t;

/**
 * cvmx_bbp_token_free_all
 */
union cvmx_bbp_token_free_all {
	uint32_t u32;
	struct cvmx_bbp_token_free_all_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_4_31                : 28;
	uint32_t token_user                   : 4;  /**< Resets ***ALL*** tokens to "Free" state. */
#else
	uint32_t token_user                   : 4;
	uint32_t reserved_4_31                : 28;
#endif
	} s;
	struct cvmx_bbp_token_free_all_s      cnf71xx;
};
typedef union cvmx_bbp_token_free_all cvmx_bbp_token_free_all_t;

/**
 * cvmx_bbp_turbo_core_status
 */
union cvmx_bbp_turbo_core_status {
	uint32_t u32;
	struct cvmx_bbp_turbo_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_31_31               : 1;
	uint32_t out_so_buffer_lvl            : 7;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t out_hd_buffer_lvl            : 7;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t in_hac_buffer_lvl            : 7;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t shi_out_fsm_status           : 2;  /**< 0: IDLE; 1: INPROCESS;2: WAIT_HD; 3: WAIT_SO */
	uint32_t core_out_fsm_status          : 2;  /**< 0: INPROCESS; 1: WAIT_HD; 2: WAIT_SO */
	uint32_t core_drdy_status             : 2;  /**< 0: IDLE; 1: WAIT_FOR_LAST; 2: CHECK_DRDY */
	uint32_t input_fsm_status             : 2;  /**< 0: IDLE; 1: HAC_RD; 2: HARQ_RD */
	uint32_t turbo_inprocess              : 1;  /**< 1: HAB is non-idle */
	uint32_t turbo_busy                   : 1;  /**< 1: HAB is busy; cannot accept a new configuration set */
#else
	uint32_t turbo_busy                   : 1;
	uint32_t turbo_inprocess              : 1;
	uint32_t input_fsm_status             : 2;
	uint32_t core_drdy_status             : 2;
	uint32_t core_out_fsm_status          : 2;
	uint32_t shi_out_fsm_status           : 2;
	uint32_t in_hac_buffer_lvl            : 7;
	uint32_t out_hd_buffer_lvl            : 7;
	uint32_t out_so_buffer_lvl            : 7;
	uint32_t reserved_31_31               : 1;
#endif
	} s;
	struct cvmx_bbp_turbo_core_status_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_core_status cvmx_bbp_turbo_core_status_t;

/**
 * cvmx_bbp_turbo_intr_msk
 */
union cvmx_bbp_turbo_intr_msk {
	uint32_t u32;
	struct cvmx_bbp_turbo_intr_msk_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t turbo_intr_msk               : 10; /**< turbo interrupt mask */
#else
	uint32_t turbo_intr_msk               : 10;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_turbo_intr_msk_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_intr_msk cvmx_bbp_turbo_intr_msk_t;

/**
 * cvmx_bbp_turbo_intr_src
 */
union cvmx_bbp_turbo_intr_src {
	uint32_t u32;
	struct cvmx_bbp_turbo_intr_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t tr_start_error               : 1;  /**< 1: error signal in the core TR_START flag */
	uint32_t hcin_error                   : 1;  /**< 1: error signal in the core HCin flag (only HSPA) */
	uint32_t input_overflow               : 1;  /**< 1: overflow in the core input FIFO (only in HSPA) */
	uint32_t hspa_new_blk_rdy             : 1;  /**< 1: core is ready for a new block (only in HSPA) */
	uint32_t output_watchdog              : 1;  /**< 1: watchdog timeout for the core output unit */
	uint32_t dec_watchdog                 : 1;  /**< 1: watchdog timeout for the core decoder unit */
	uint32_t input_watchdog               : 1;  /**< 1: watchdog timeout for the core input unit */
	uint32_t ctc_core_error               : 1;  /**< 1: turbo core error */
	uint32_t turbo_hab_done               : 1;  /**< 1: HAB is idle */
	uint32_t rdy_for_new_blk              : 1;  /**< 1: HAB can receive a new block */
#else
	uint32_t rdy_for_new_blk              : 1;
	uint32_t turbo_hab_done               : 1;
	uint32_t ctc_core_error               : 1;
	uint32_t input_watchdog               : 1;
	uint32_t dec_watchdog                 : 1;
	uint32_t output_watchdog              : 1;
	uint32_t hspa_new_blk_rdy             : 1;
	uint32_t input_overflow               : 1;
	uint32_t hcin_error                   : 1;
	uint32_t tr_start_error               : 1;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_turbo_intr_src_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_intr_src cvmx_bbp_turbo_intr_src_t;

/**
 * cvmx_bbp_turbo_module_ctrl
 */
union cvmx_bbp_turbo_module_ctrl {
	uint32_t u32;
	struct cvmx_bbp_turbo_module_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t turbo_start                  : 1;  /**< 1: start */
#else
	uint32_t turbo_start                  : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_turbo_module_ctrl_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_module_ctrl cvmx_bbp_turbo_module_ctrl_t;

/**
 * cvmx_bbp_turbo_module_status
 *
 * &BBP_DID_ID = 0x6F007F84A000
 * TURBO_CSR_VERSION = v1.0  // hab_source_version
 */
union cvmx_bbp_turbo_module_status {
	uint32_t u32;
	struct cvmx_bbp_turbo_module_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t status                       : 1;  /**< turbo input stage status: 0: can accept a new input
                                                         configuration.  1: busy, cannot accept new input. */
#else
	uint32_t status                       : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_turbo_module_status_s cnf71xx;
};
typedef union cvmx_bbp_turbo_module_status cvmx_bbp_turbo_module_status_t;

/**
 * cvmx_bbp_turbo_statistics0
 */
union cvmx_bbp_turbo_statistics0 {
	uint32_t u32;
	struct cvmx_bbp_turbo_statistics0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t crc_error                    : 1;  /**< Log CTRL = 0: Code block CRC error */
	uint32_t halfitdone                   : 6;  /**< Log CTRL = 0: Core HalfIT Done */
	uint32_t reserved_13_15               : 3;
	uint32_t ber                          : 13; /**< Log CTRL = 0: Core BER */
#else
	uint32_t ber                          : 13;
	uint32_t reserved_13_15               : 3;
	uint32_t halfitdone                   : 6;
	uint32_t crc_error                    : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_turbo_statistics0_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_statistics0 cvmx_bbp_turbo_statistics0_t;

/**
 * cvmx_bbp_turbo_statistics1
 */
union cvmx_bbp_turbo_statistics1 {
	uint32_t u32;
	struct cvmx_bbp_turbo_statistics1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t crc_error                    : 1;  /**< Log CTRL = 1: Code block CRC error */
	uint32_t halfitdone                   : 6;  /**< Log CTRL = 1: Core HalfIT Done */
	uint32_t reserved_13_15               : 3;
	uint32_t ber                          : 13; /**< Log CTRL = 1: Core BER */
#else
	uint32_t ber                          : 13;
	uint32_t reserved_13_15               : 3;
	uint32_t halfitdone                   : 6;
	uint32_t crc_error                    : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_turbo_statistics1_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_statistics1 cvmx_bbp_turbo_statistics1_t;

/**
 * cvmx_bbp_turbo_statistics2
 */
union cvmx_bbp_turbo_statistics2 {
	uint32_t u32;
	struct cvmx_bbp_turbo_statistics2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_25_31               : 7;
	uint32_t core_idle2                   : 1;  /**< 1: Core idle state */
	uint32_t reserved_23_23               : 1;
	uint32_t harq_idle                    : 1;  /**< 1: HARQ & EDCH processing unit is idle */
	uint32_t harq_empty                   : 1;  /**< 1: HARQ & EDCH processing unit idle & TR buffer empty */
	uint32_t core_dblk_error              : 1;  /**< 1: Error signal on DBLK; wrong TR_START timing */
	uint32_t core_hcin_error              : 1;  /**< 1: Error signal in HCIN flag */
	uint32_t core_overflow                : 1;  /**< 1: Errof signal; an overflow occurred in input FIFO */
	uint32_t core_rdy                     : 1;  /**< 1: Core is ready to received a new TB */
	uint32_t core_hcin_flag               : 1;  /**< 0: core waiting for HCin; 1: core waiting for Rx */
	uint32_t output_watchdog              : 1;  /**< 1: Watchdog timeout for the core output unit */
	uint32_t dec_watchdog                 : 1;  /**< 1: Watchdog timeout for the core decoder unit */
	uint32_t input_watchdog               : 1;  /**< 1: Watchdog timeout for the core input unit */
	uint32_t reserved_12_12               : 1;
	uint32_t core_so_congestion           : 1;  /**< 1: Soft output buffer full */
	uint32_t core_so_empty                : 1;  /**< 1: Soft output buffer empty */
	uint32_t core_illegal_dlast           : 1;  /**< 1: DLAST too late; not asserted in HSPA mode */
	uint32_t core_illegal_dblk            : 1;  /**< 1: illegal DBLK */
	uint32_t core_error                   : 1;  /**< 1: DLAST too early or wrong K or wrong N;block aborted */
	uint32_t output_congestion            : 1;  /**< 1: Congestion at the output of the core */
	uint32_t core_obuf_full               : 1;  /**< 1: Core output buffers are both full */
	uint32_t core_obuf_empty              : 1;  /**< 1: Core output buffers are both empty */
	uint32_t core_ibuf_full               : 1;  /**< 1: Core input buffers are both full */
	uint32_t core_ibuf_empty              : 1;  /**< 1: Core input buffers are both empty */
	uint32_t core_dec_unit_idle           : 1;  /**< 1: Decoder unit of the core is idle */
	uint32_t core_idle                    : 1;  /**< 1: Core is idle */
#else
	uint32_t core_idle                    : 1;
	uint32_t core_dec_unit_idle           : 1;
	uint32_t core_ibuf_empty              : 1;
	uint32_t core_ibuf_full               : 1;
	uint32_t core_obuf_empty              : 1;
	uint32_t core_obuf_full               : 1;
	uint32_t output_congestion            : 1;
	uint32_t core_error                   : 1;
	uint32_t core_illegal_dblk            : 1;
	uint32_t core_illegal_dlast           : 1;
	uint32_t core_so_empty                : 1;
	uint32_t core_so_congestion           : 1;
	uint32_t reserved_12_12               : 1;
	uint32_t input_watchdog               : 1;
	uint32_t dec_watchdog                 : 1;
	uint32_t output_watchdog              : 1;
	uint32_t core_hcin_flag               : 1;
	uint32_t core_rdy                     : 1;
	uint32_t core_overflow                : 1;
	uint32_t core_hcin_error              : 1;
	uint32_t core_dblk_error              : 1;
	uint32_t harq_empty                   : 1;
	uint32_t harq_idle                    : 1;
	uint32_t reserved_23_23               : 1;
	uint32_t core_idle2                   : 1;
	uint32_t reserved_25_31               : 7;
#endif
	} s;
	struct cvmx_bbp_turbo_statistics2_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_statistics2 cvmx_bbp_turbo_statistics2_t;

/**
 * cvmx_bbp_turbo_statistics3
 */
union cvmx_bbp_turbo_statistics3 {
	uint32_t u32;
	struct cvmx_bbp_turbo_statistics3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_31_31               : 1;
	uint32_t out_so_buffer_lvl            : 7;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t out_hd_buffer_lvl            : 7;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t in_hac_buffer_lvl            : 7;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t shi_out_fsm_status           : 2;  /**< 0: IDLE;1==INPROCESS;2==WAIT_HD;3==WAIT_SO */
	uint32_t core_out_fsm_status          : 2;  /**< 0: INPROCESS;1==WAIT_HD;2==WAIT_SO */
	uint32_t core_drdy_status             : 2;  /**< 0: IDLe;1==WAIT_FOR_LAST;2==CHECK_DRDY */
	uint32_t input_fsm_status             : 2;  /**< 0: IDLe;1==HAC_RD;2==HARQ_RD */
	uint32_t turbo_inprocess              : 1;  /**< 1: HAB is non-idle */
	uint32_t turbo_busy                   : 1;  /**< 1: HAB is busy; cannot accept a new configuration set */
#else
	uint32_t turbo_busy                   : 1;
	uint32_t turbo_inprocess              : 1;
	uint32_t input_fsm_status             : 2;
	uint32_t core_drdy_status             : 2;
	uint32_t core_out_fsm_status          : 2;
	uint32_t shi_out_fsm_status           : 2;
	uint32_t in_hac_buffer_lvl            : 7;
	uint32_t out_hd_buffer_lvl            : 7;
	uint32_t out_so_buffer_lvl            : 7;
	uint32_t reserved_31_31               : 1;
#endif
	} s;
	struct cvmx_bbp_turbo_statistics3_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_statistics3 cvmx_bbp_turbo_statistics3_t;

/**
 * cvmx_bbp_turbo_statistics4
 */
union cvmx_bbp_turbo_statistics4 {
	uint32_t u32;
	struct cvmx_bbp_turbo_statistics4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t out_harq_buffer_lvl          : 8;  /**< [ALMOST FULL, BUFFER LEVEL] */
	uint32_t in_harq_buffer_lvl           : 8;  /**< [ALMOST FULL, BUFFER LEVEL] */
#else
	uint32_t in_harq_buffer_lvl           : 8;
	uint32_t out_harq_buffer_lvl          : 8;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_turbo_statistics4_s   cnf71xx;
};
typedef union cvmx_bbp_turbo_statistics4 cvmx_bbp_turbo_statistics4_t;

/**
 * cvmx_bbp_turbo_sys_cfg0
 */
union cvmx_bbp_turbo_sys_cfg0 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t n_size                       : 16; /**< number of input LLR samples */
	uint32_t k_size                       : 13; /**< payload block size in bits */
	uint32_t ctc_mode                     : 2;  /**< 1: LTE; 2: HSPA */
	uint32_t ctc_bypass                   : 1;  /**< 1: CTC core in bypass mode */
#else
	uint32_t ctc_bypass                   : 1;
	uint32_t ctc_mode                     : 2;
	uint32_t k_size                       : 13;
	uint32_t n_size                       : 16;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg0_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg0 cvmx_bbp_turbo_sys_cfg0_t;

/**
 * cvmx_bbp_turbo_sys_cfg1
 */
union cvmx_bbp_turbo_sys_cfg1 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t bypass_nbi                   : 1;  /**< 1: Null insertion is disabled (LTE MODE) */
	uint32_t generate_hd                  : 1;  /**< 1: Hard output bits are generated */
	uint32_t core_crc                     : 2;  /**< 0: No CRC;1: gCRC24A; 2: gCRC24B */
	uint32_t halfit                       : 6;  /**< Half Iteration */
	uint32_t threshold                    : 8;  /**< threshold */
	uint32_t ctc_dyn_stop                 : 1;  /**< 1: dynamic stop enabled */
	uint32_t reserved_11_12               : 2;
	uint32_t core_control                 : 5;  /**< 1: deactivates test on [output watchdog,decoder watchdog,input watchdog,dlast,N_size] */
	uint32_t nfiller                      : 6;  /**< number of filler bits in payload */
#else
	uint32_t nfiller                      : 6;
	uint32_t core_control                 : 5;
	uint32_t reserved_11_12               : 2;
	uint32_t ctc_dyn_stop                 : 1;
	uint32_t threshold                    : 8;
	uint32_t halfit                       : 6;
	uint32_t core_crc                     : 2;
	uint32_t generate_hd                  : 1;
	uint32_t bypass_nbi                   : 1;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg1_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg1 cvmx_bbp_turbo_sys_cfg1_t;

/**
 * cvmx_bbp_turbo_sys_cfg10
 */
union cvmx_bbp_turbo_sys_cfg10 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg10_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eminus_2                     : 32; /**< EMINUS_2 (HSPA Mode) */
#else
	uint32_t eminus_2                     : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg10_s     cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg10 cvmx_bbp_turbo_sys_cfg10_t;

/**
 * cvmx_bbp_turbo_sys_cfg11
 */
union cvmx_bbp_turbo_sys_cfg11 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg11_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eini_3                       : 32; /**< EINI_3 (HSPA Mode) */
#else
	uint32_t eini_3                       : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg11_s     cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg11 cvmx_bbp_turbo_sys_cfg11_t;

/**
 * cvmx_bbp_turbo_sys_cfg12
 */
union cvmx_bbp_turbo_sys_cfg12 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg12_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eplus_3                      : 32; /**< EPLUS_3 (HSPA Mode) */
#else
	uint32_t eplus_3                      : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg12_s     cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg12 cvmx_bbp_turbo_sys_cfg12_t;

/**
 * cvmx_bbp_turbo_sys_cfg13
 */
union cvmx_bbp_turbo_sys_cfg13 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg13_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eminus_3                     : 32; /**< EMINUS_3 (HSPA Mode) */
#else
	uint32_t eminus_3                     : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg13_s     cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg13 cvmx_bbp_turbo_sys_cfg13_t;

/**
 * cvmx_bbp_turbo_sys_cfg2
 */
union cvmx_bbp_turbo_sys_cfg2 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_31_31               : 1;
	uint32_t bypass_inv_bc                : 1;  /**< 1: EDCH inverse bit-collection is bypassed */
	uint32_t reserved_29_29               : 1;
	uint32_t bypass_harq                  : 1;  /**< 1: bypass HARQ functionality */
	uint32_t rv_dx                        : 2;  /**< redundancy version */
	uint32_t punct_mode                   : 2;  /**< 0: punct P1&P2;1: punct S&P1&P2; 2: unused; 3: rep. */
	uint32_t bypass_rm                    : 1;  /**< 1: rate matching is bypassed (HSPA mode) */
	uint32_t loop_back                    : 1;  /**< 1: send the input LLRs to soft output port */
	uint32_t negate_llr                   : 1;  /**< 1: input LLRs and soft output LLRs are negated */
	uint32_t output_endian                : 1;  /**< 0: big endian; 1: little endian */
	uint32_t output_bit_sel               : 2;  /**< bit sel range: 0: <5:0>;1: <6:1>; 2: <7:2> */
	uint32_t output_sat_bypass            : 1;  /**< 0: Saturation is performed on soft output LLRs */
	uint32_t input_bit_sel                : 2;  /**< bit sel range: 0: <5:0>;1: <6:1>; 2: <7:2> */
	uint32_t input_sat_bypass             : 1;  /**< 0: Saturation is performed on input LLRs */
	uint32_t tb_crc_seed_en               : 1;  /**< 0: default seed (0x0); 1: initial seed read from
                                                         from BBP_TURBO_SYS_CFG3[TB_CRC_SEED] */
	uint32_t last_flag                    : 1;  /**< 1: TB's last code block */
	uint32_t first_flag                   : 1;  /**< 1: TB's first code block */
	uint32_t tb_id                        : 2;  /**< Transport Block number.  Used for identifying
                                                         code blocks when multiple transport blocks are
                                                         interleaved. */
	uint32_t tb_crc                       : 2;  /**< 0: No CRC;1: gCRC24A; 2: gCRC24B */
	uint32_t log_ctrl                     : 1;  /**< 0: use BBP_TURBO_STATISTICS0
                                                         - 1: use BBP_TURBO_STATISTICS1 */
	uint32_t no_concats                   : 6;  /**< No bits to be concatenated with prev code blk */
#else
	uint32_t no_concats                   : 6;
	uint32_t log_ctrl                     : 1;
	uint32_t tb_crc                       : 2;
	uint32_t tb_id                        : 2;
	uint32_t first_flag                   : 1;
	uint32_t last_flag                    : 1;
	uint32_t tb_crc_seed_en               : 1;
	uint32_t input_sat_bypass             : 1;
	uint32_t input_bit_sel                : 2;
	uint32_t output_sat_bypass            : 1;
	uint32_t output_bit_sel               : 2;
	uint32_t output_endian                : 1;
	uint32_t negate_llr                   : 1;
	uint32_t loop_back                    : 1;
	uint32_t bypass_rm                    : 1;
	uint32_t punct_mode                   : 2;
	uint32_t rv_dx                        : 2;
	uint32_t bypass_harq                  : 1;
	uint32_t reserved_29_29               : 1;
	uint32_t bypass_inv_bc                : 1;
	uint32_t reserved_31_31               : 1;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg2_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg2 cvmx_bbp_turbo_sys_cfg2_t;

/**
 * cvmx_bbp_turbo_sys_cfg3
 */
union cvmx_bbp_turbo_sys_cfg3 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_30_31               : 2;
	uint32_t no_harq_last_vld             : 3;  /**< Number of valid LLRs in the last word of harq input */
	uint32_t no_hac_last_vld              : 3;  /**< Number of valid LLRs in the last word of hac input */
	uint32_t tb_crc_seed                  : 24; /**< TB CRC SEED */
#else
	uint32_t tb_crc_seed                  : 24;
	uint32_t no_hac_last_vld              : 3;
	uint32_t no_harq_last_vld             : 3;
	uint32_t reserved_30_31               : 2;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg3_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg3 cvmx_bbp_turbo_sys_cfg3_t;

/**
 * cvmx_bbp_turbo_sys_cfg4
 */
union cvmx_bbp_turbo_sys_cfg4 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dblk_id                      : 16; /**< Blk ID */
	uint32_t reserved_13_15               : 3;
	uint32_t dyn_stop_so                  : 3;  /**< 1: Dynamic iteration stopping is enabled */
	uint32_t bypass_rm_so                 : 1;  /**< 1: No rate matching on soft outputs */
	uint32_t bypass_snbs_so               : 1;  /**< 1: Null suppresssion and puncturing is disabled for SO */
	uint32_t halfit_so                    : 6;  /**< SO Half Iteration */
	uint32_t so__type                     : 1;  /**< 0: APP; 1: Extrinsic */
	uint32_t generate_so                  : 1;  /**< 1: Soft outputs are generated */
#else
	uint32_t generate_so                  : 1;
	uint32_t so__type                     : 1;
	uint32_t halfit_so                    : 6;
	uint32_t bypass_snbs_so               : 1;
	uint32_t bypass_rm_so                 : 1;
	uint32_t dyn_stop_so                  : 3;
	uint32_t reserved_13_15               : 3;
	uint32_t dblk_id                      : 16;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg4_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg4 cvmx_bbp_turbo_sys_cfg4_t;

/**
 * cvmx_bbp_turbo_sys_cfg5
 */
union cvmx_bbp_turbo_sys_cfg5 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eini_1                       : 32; /**< EINI_1 (HSPA Mode) */
#else
	uint32_t eini_1                       : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg5_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg5 cvmx_bbp_turbo_sys_cfg5_t;

/**
 * cvmx_bbp_turbo_sys_cfg6
 */
union cvmx_bbp_turbo_sys_cfg6 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg6_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eplus_1                      : 32; /**< EPLUS_1 (HSPA Mode) */
#else
	uint32_t eplus_1                      : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg6_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg6 cvmx_bbp_turbo_sys_cfg6_t;

/**
 * cvmx_bbp_turbo_sys_cfg7
 */
union cvmx_bbp_turbo_sys_cfg7 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg7_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eminus_1                     : 32; /**< EMINUS_1 (HSPA Mode) */
#else
	uint32_t eminus_1                     : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg7_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg7 cvmx_bbp_turbo_sys_cfg7_t;

/**
 * cvmx_bbp_turbo_sys_cfg8
 */
union cvmx_bbp_turbo_sys_cfg8 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg8_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eini_2                       : 32; /**< EINI_2 (HSPA Mode) */
#else
	uint32_t eini_2                       : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg8_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg8 cvmx_bbp_turbo_sys_cfg8_t;

/**
 * cvmx_bbp_turbo_sys_cfg9
 */
union cvmx_bbp_turbo_sys_cfg9 {
	uint32_t u32;
	struct cvmx_bbp_turbo_sys_cfg9_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t eplus_2                      : 32; /**< EPLUS_2 (HSPA Mode) */
#else
	uint32_t eplus_2                      : 32;
#endif
	} s;
	struct cvmx_bbp_turbo_sys_cfg9_s      cnf71xx;
};
typedef union cvmx_bbp_turbo_sys_cfg9 cvmx_bbp_turbo_sys_cfg9_t;

/**
 * cvmx_bbp_tx_bist_status0
 *
 * TX  Bist Status0  0x874400+0x60
 *
 */
union cvmx_bbp_tx_bist_status0 {
	uint32_t u32;
	struct cvmx_bbp_tx_bist_status0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t tx_trace0_bist               : 1;  /**< TX DSP0 Trace Ram Bist Result
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t tx_trace1_bist               : 1;  /**< TX DSP1 Trace Ram Bist Result
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t reserved_0_29                : 30;
#else
	uint32_t reserved_0_29                : 30;
	uint32_t tx_trace1_bist               : 1;
	uint32_t tx_trace0_bist               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_bist_status0_s     cnf71xx;
};
typedef union cvmx_bbp_tx_bist_status0 cvmx_bbp_tx_bist_status0_t;

/**
 * cvmx_bbp_tx_bist_status1
 *
 * TX  Bist Status1  0x874400+0x64
 *
 */
union cvmx_bbp_tx_bist_status1 {
	uint32_t u32;
	struct cvmx_bbp_tx_bist_status1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ipm_bist0                    : 32; /**< IPM Bist Result Set0
                                                         66 rams in IPM
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t ipm_bist0                    : 32;
#endif
	} s;
	struct cvmx_bbp_tx_bist_status1_s     cnf71xx;
};
typedef union cvmx_bbp_tx_bist_status1 cvmx_bbp_tx_bist_status1_t;

/**
 * cvmx_bbp_tx_bist_status2
 *
 * TX  Bist Status2  0x874400+0x68
 *
 */
union cvmx_bbp_tx_bist_status2 {
	uint32_t u32;
	struct cvmx_bbp_tx_bist_status2_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ipm_bist1                    : 32; /**< IPM Bist Result Set1
                                                         66 rams in IPM
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t ipm_bist1                    : 32;
#endif
	} s;
	struct cvmx_bbp_tx_bist_status2_s     cnf71xx;
};
typedef union cvmx_bbp_tx_bist_status2 cvmx_bbp_tx_bist_status2_t;

/**
 * cvmx_bbp_tx_bist_status3
 *
 * TX  Bist Status3  0x874400+0x6c
 *
 */
union cvmx_bbp_tx_bist_status3 {
	uint32_t u32;
	struct cvmx_bbp_tx_bist_status3_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t ipm_bist2                    : 2;  /**< IPM Bist Result Set2
                                                         66 rams in IPM
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t dle_bist0                    : 30; /**< DLE Bist Result Set0
                                                         76 rams in DLE
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t dle_bist0                    : 30;
	uint32_t ipm_bist2                    : 2;
#endif
	} s;
	struct cvmx_bbp_tx_bist_status3_s     cnf71xx;
};
typedef union cvmx_bbp_tx_bist_status3 cvmx_bbp_tx_bist_status3_t;

/**
 * cvmx_bbp_tx_bist_status4
 *
 * TX  Bist Status4  0x874400+0x70
 *
 */
union cvmx_bbp_tx_bist_status4 {
	uint32_t u32;
	struct cvmx_bbp_tx_bist_status4_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dle_bist1                    : 32; /**< DLE Bist Result Set1
                                                         76 rams in DLE
                                                         A value of 1 indicates BIST fail for that particular ram. */
#else
	uint32_t dle_bist1                    : 32;
#endif
	} s;
	struct cvmx_bbp_tx_bist_status4_s     cnf71xx;
};
typedef union cvmx_bbp_tx_bist_status4 cvmx_bbp_tx_bist_status4_t;

/**
 * cvmx_bbp_tx_bist_status5
 *
 * TX  Bist Status5  0x874400+0x74
 *
 */
union cvmx_bbp_tx_bist_status5 {
	uint32_t u32;
	struct cvmx_bbp_tx_bist_status5_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dle_bist2                    : 14; /**< DLE Bist Result Set2
                                                         76 rams in DLE
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t tx_psm_bist                  : 1;  /**< TX PSM Bist Result
                                                         1 ram in TX PSM
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t eng3g_bist                   : 6;  /**< 3G Encoder Bist
                                                         6 rams in 3G Encoder
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t rfif_bist                    : 7;  /**< RFIF Bist
                                                         7 rams in RFIF
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t spi_bist                     : 2;  /**< RFIF SPI Bist
                                                         2 rams in RFIF SPI
                                                         A value of 1 indicates BIST fail for that particular ram. */
	uint32_t reserved_0_1                 : 2;
#else
	uint32_t reserved_0_1                 : 2;
	uint32_t spi_bist                     : 2;
	uint32_t rfif_bist                    : 7;
	uint32_t eng3g_bist                   : 6;
	uint32_t tx_psm_bist                  : 1;
	uint32_t dle_bist2                    : 14;
#endif
	} s;
	struct cvmx_bbp_tx_bist_status5_s     cnf71xx;
};
typedef union cvmx_bbp_tx_bist_status5 cvmx_bbp_tx_bist_status5_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_tx_ext_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_cbuf_end_addr0 cvmx_bbp_tx_ext_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_tx_ext_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_cbuf_start_addr0 cvmx_bbp_tx_ext_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_debug_dat
 */
union cvmx_bbp_tx_ext_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_debug_dat cvmx_bbp_tx_ext_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_debug_sel
 */
union cvmx_bbp_tx_ext_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_debug_sel cvmx_bbp_tx_ext_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_intr_clear
 */
union cvmx_bbp_tx_ext_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_intr_clear cvmx_bbp_tx_ext_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_intr_enb
 */
union cvmx_bbp_tx_ext_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_intr_enb cvmx_bbp_tx_ext_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_intr_rstatus
 */
union cvmx_bbp_tx_ext_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_intr_rstatus cvmx_bbp_tx_ext_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_intr_status
 */
union cvmx_bbp_tx_ext_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_intr_status cvmx_bbp_tx_ext_dma_rd_intr_status_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_intr_test
 */
union cvmx_bbp_tx_ext_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_intr_test cvmx_bbp_tx_ext_dma_rd_intr_test_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_memclr_data
 */
union cvmx_bbp_tx_ext_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_memclr_data cvmx_bbp_tx_ext_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_mode
 */
union cvmx_bbp_tx_ext_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_mode_s  cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_mode cvmx_bbp_tx_ext_dma_rd_mode_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_pri_mode
 */
union cvmx_bbp_tx_ext_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_pri_mode cvmx_bbp_tx_ext_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_start_addr0
 */
union cvmx_bbp_tx_ext_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_start_addr0 cvmx_bbp_tx_ext_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_status
 */
union cvmx_bbp_tx_ext_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_status cvmx_bbp_tx_ext_dma_rd_status_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_xfer_mode_count
 */
union cvmx_bbp_tx_ext_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_xfer_mode_count cvmx_bbp_tx_ext_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_xfer_q_status
 */
union cvmx_bbp_tx_ext_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_xfer_q_status cvmx_bbp_tx_ext_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ext_dma_rd_xfer_start
 */
union cvmx_bbp_tx_ext_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_rd_xfer_start cvmx_bbp_tx_ext_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_tx_ext_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_cbuf_end_addr0 cvmx_bbp_tx_ext_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_tx_ext_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_cbuf_start_addr0 cvmx_bbp_tx_ext_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_debug_dat
 */
union cvmx_bbp_tx_ext_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_debug_dat cvmx_bbp_tx_ext_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_debug_sel
 */
union cvmx_bbp_tx_ext_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_debug_sel cvmx_bbp_tx_ext_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_intr_clear
 */
union cvmx_bbp_tx_ext_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_intr_clear cvmx_bbp_tx_ext_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_intr_enb
 */
union cvmx_bbp_tx_ext_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_intr_enb cvmx_bbp_tx_ext_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_intr_rstatus
 */
union cvmx_bbp_tx_ext_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_intr_rstatus cvmx_bbp_tx_ext_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_intr_status
 */
union cvmx_bbp_tx_ext_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_intr_status cvmx_bbp_tx_ext_dma_wr_intr_status_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_intr_test
 */
union cvmx_bbp_tx_ext_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_intr_test cvmx_bbp_tx_ext_dma_wr_intr_test_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_memclr_data
 */
union cvmx_bbp_tx_ext_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_memclr_data cvmx_bbp_tx_ext_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_mode
 */
union cvmx_bbp_tx_ext_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_mode_s  cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_mode cvmx_bbp_tx_ext_dma_wr_mode_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_pri_mode
 */
union cvmx_bbp_tx_ext_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_pri_mode cvmx_bbp_tx_ext_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_start_addr0
 */
union cvmx_bbp_tx_ext_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_start_addr0 cvmx_bbp_tx_ext_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_status
 */
union cvmx_bbp_tx_ext_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_status cvmx_bbp_tx_ext_dma_wr_status_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_xfer_mode_count
 */
union cvmx_bbp_tx_ext_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_xfer_mode_count cvmx_bbp_tx_ext_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_xfer_q_status
 */
union cvmx_bbp_tx_ext_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_xfer_q_status cvmx_bbp_tx_ext_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ext_dma_wr_xfer_start
 */
union cvmx_bbp_tx_ext_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ext_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ext_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ext_dma_wr_xfer_start cvmx_bbp_tx_ext_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_end_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_end_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_start_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_dat
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_dat cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_dat_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_sel
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_sel cvmx_bbp_tx_ifftpapr_dma_rd_0_debug_sel_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_clear
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_clear cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_clear_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_enb
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_enb cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_enb_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_rstatus
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_rstatus cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_status cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_test
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_test cvmx_bbp_tx_ifftpapr_dma_rd_0_intr_test_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_memclr_data
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_memclr_data cvmx_bbp_tx_ifftpapr_dma_rd_0_memclr_data_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_mode cvmx_bbp_tx_ifftpapr_dma_rd_0_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_pri_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_pri_mode cvmx_bbp_tx_ifftpapr_dma_rd_0_pri_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_start_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_0_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_status cvmx_bbp_tx_ifftpapr_dma_rd_0_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_mode_count
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_mode_count cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_q_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_q_status cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_start
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_start cvmx_bbp_tx_ifftpapr_dma_rd_0_xfer_start_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_end_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_end_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_start_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_dat
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_dat cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_dat_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_sel
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_sel cvmx_bbp_tx_ifftpapr_dma_rd_1_debug_sel_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_clear
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_clear cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_clear_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_enb
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_enb cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_enb_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_rstatus
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_rstatus cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_status cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_test
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_test cvmx_bbp_tx_ifftpapr_dma_rd_1_intr_test_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_memclr_data
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_memclr_data cvmx_bbp_tx_ifftpapr_dma_rd_1_memclr_data_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_mode cvmx_bbp_tx_ifftpapr_dma_rd_1_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_pri_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_pri_mode cvmx_bbp_tx_ifftpapr_dma_rd_1_pri_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_start_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_1_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_status cvmx_bbp_tx_ifftpapr_dma_rd_1_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_mode_count
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_mode_count cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_q_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_q_status cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_start
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_start cvmx_bbp_tx_ifftpapr_dma_rd_1_xfer_start_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_end_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_end_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_start_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_rm_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_dat
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_dat cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_dat_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_sel
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_sel cvmx_bbp_tx_ifftpapr_dma_rd_rm_debug_sel_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_clear
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_clear cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_clear_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_enb
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_enb cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_enb_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_rstatus
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_rstatus cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_status cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_test
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_test cvmx_bbp_tx_ifftpapr_dma_rd_rm_intr_test_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_memclr_data
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_memclr_data cvmx_bbp_tx_ifftpapr_dma_rd_rm_memclr_data_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_mode cvmx_bbp_tx_ifftpapr_dma_rd_rm_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_pri_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_pri_mode cvmx_bbp_tx_ifftpapr_dma_rd_rm_pri_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_start_addr0 cvmx_bbp_tx_ifftpapr_dma_rd_rm_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_status cvmx_bbp_tx_ifftpapr_dma_rd_rm_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_mode_count
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_mode_count cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_q_status
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_q_status cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_start
 */
union cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_start cvmx_bbp_tx_ifftpapr_dma_rd_rm_xfer_start_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_end_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_end_addr0 cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_start_addr0 cvmx_bbp_tx_ifftpapr_dma_wr_0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_dat
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_dat cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_dat_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_sel
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_sel cvmx_bbp_tx_ifftpapr_dma_wr_0_debug_sel_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_clear
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_clear cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_clear_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_enb
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_enb cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_enb_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_rstatus
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_rstatus cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_status
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_status cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_test
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_test cvmx_bbp_tx_ifftpapr_dma_wr_0_intr_test_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_memclr_data
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_memclr_data cvmx_bbp_tx_ifftpapr_dma_wr_0_memclr_data_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_mode cvmx_bbp_tx_ifftpapr_dma_wr_0_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_pri_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_pri_mode cvmx_bbp_tx_ifftpapr_dma_wr_0_pri_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_start_addr0 cvmx_bbp_tx_ifftpapr_dma_wr_0_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_status
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_status cvmx_bbp_tx_ifftpapr_dma_wr_0_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_mode_count
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_mode_count cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_q_status
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_q_status cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_start
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_start cvmx_bbp_tx_ifftpapr_dma_wr_0_xfer_start_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_end_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_end_addr0 cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_start_addr0 cvmx_bbp_tx_ifftpapr_dma_wr_1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_dat
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_dat cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_dat_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_sel
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_sel cvmx_bbp_tx_ifftpapr_dma_wr_1_debug_sel_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_clear
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_clear cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_clear_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_enb
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_enb cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_enb_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_rstatus
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_rstatus cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_rstatus_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_status
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_status cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_test
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_test cvmx_bbp_tx_ifftpapr_dma_wr_1_intr_test_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_memclr_data
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_memclr_data cvmx_bbp_tx_ifftpapr_dma_wr_1_memclr_data_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_mode cvmx_bbp_tx_ifftpapr_dma_wr_1_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_pri_mode
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_pri_mode cvmx_bbp_tx_ifftpapr_dma_wr_1_pri_mode_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_start_addr0
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_start_addr0 cvmx_bbp_tx_ifftpapr_dma_wr_1_start_addr0_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_status
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_status cvmx_bbp_tx_ifftpapr_dma_wr_1_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_mode_count
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_mode_count cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_q_status
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_q_status cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_q_status_t;

/**
 * cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_start
 */
union cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_start cvmx_bbp_tx_ifftpapr_dma_wr_1_xfer_start_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_tx_instr_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_cbuf_end_addr0 cvmx_bbp_tx_instr_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_tx_instr_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_cbuf_start_addr0 cvmx_bbp_tx_instr_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_debug_dat
 */
union cvmx_bbp_tx_instr_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_debug_dat cvmx_bbp_tx_instr_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_debug_sel
 */
union cvmx_bbp_tx_instr_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_debug_sel cvmx_bbp_tx_instr_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_intr_clear
 */
union cvmx_bbp_tx_instr_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_intr_clear cvmx_bbp_tx_instr_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_intr_enb
 */
union cvmx_bbp_tx_instr_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_intr_enb cvmx_bbp_tx_instr_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_intr_rstatus
 */
union cvmx_bbp_tx_instr_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_intr_rstatus cvmx_bbp_tx_instr_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_intr_status
 */
union cvmx_bbp_tx_instr_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_intr_status cvmx_bbp_tx_instr_dma_wr_intr_status_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_intr_test
 */
union cvmx_bbp_tx_instr_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_intr_test cvmx_bbp_tx_instr_dma_wr_intr_test_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_memclr_data
 */
union cvmx_bbp_tx_instr_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_memclr_data cvmx_bbp_tx_instr_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_mode
 */
union cvmx_bbp_tx_instr_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_mode cvmx_bbp_tx_instr_dma_wr_mode_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_pri_mode
 */
union cvmx_bbp_tx_instr_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_pri_mode cvmx_bbp_tx_instr_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_start_addr0
 */
union cvmx_bbp_tx_instr_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_start_addr0 cvmx_bbp_tx_instr_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_status
 */
union cvmx_bbp_tx_instr_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_status cvmx_bbp_tx_instr_dma_wr_status_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_xfer_mode_count
 */
union cvmx_bbp_tx_instr_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_xfer_mode_count cvmx_bbp_tx_instr_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_xfer_q_status
 */
union cvmx_bbp_tx_instr_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_xfer_q_status cvmx_bbp_tx_instr_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_tx_instr_dma_wr_xfer_start
 */
union cvmx_bbp_tx_instr_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_instr_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_instr_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_instr_dma_wr_xfer_start cvmx_bbp_tx_instr_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_tx_int_dma_rd_cbuf_end_addr0
 */
union cvmx_bbp_tx_int_dma_rd_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_cbuf_end_addr0 cvmx_bbp_tx_int_dma_rd_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_int_dma_rd_cbuf_start_addr0
 */
union cvmx_bbp_tx_int_dma_rd_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_cbuf_start_addr0 cvmx_bbp_tx_int_dma_rd_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_int_dma_rd_debug_dat
 */
union cvmx_bbp_tx_int_dma_rd_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_debug_dat cvmx_bbp_tx_int_dma_rd_debug_dat_t;

/**
 * cvmx_bbp_tx_int_dma_rd_debug_sel
 */
union cvmx_bbp_tx_int_dma_rd_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_debug_sel cvmx_bbp_tx_int_dma_rd_debug_sel_t;

/**
 * cvmx_bbp_tx_int_dma_rd_intr_clear
 */
union cvmx_bbp_tx_int_dma_rd_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_intr_clear cvmx_bbp_tx_int_dma_rd_intr_clear_t;

/**
 * cvmx_bbp_tx_int_dma_rd_intr_enb
 */
union cvmx_bbp_tx_int_dma_rd_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_intr_enb cvmx_bbp_tx_int_dma_rd_intr_enb_t;

/**
 * cvmx_bbp_tx_int_dma_rd_intr_rstatus
 */
union cvmx_bbp_tx_int_dma_rd_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_intr_rstatus cvmx_bbp_tx_int_dma_rd_intr_rstatus_t;

/**
 * cvmx_bbp_tx_int_dma_rd_intr_status
 */
union cvmx_bbp_tx_int_dma_rd_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_intr_status cvmx_bbp_tx_int_dma_rd_intr_status_t;

/**
 * cvmx_bbp_tx_int_dma_rd_intr_test
 */
union cvmx_bbp_tx_int_dma_rd_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_intr_test cvmx_bbp_tx_int_dma_rd_intr_test_t;

/**
 * cvmx_bbp_tx_int_dma_rd_memclr_data
 */
union cvmx_bbp_tx_int_dma_rd_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_memclr_data cvmx_bbp_tx_int_dma_rd_memclr_data_t;

/**
 * cvmx_bbp_tx_int_dma_rd_mode
 */
union cvmx_bbp_tx_int_dma_rd_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_mode_s  cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_mode cvmx_bbp_tx_int_dma_rd_mode_t;

/**
 * cvmx_bbp_tx_int_dma_rd_pri_mode
 */
union cvmx_bbp_tx_int_dma_rd_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_pri_mode cvmx_bbp_tx_int_dma_rd_pri_mode_t;

/**
 * cvmx_bbp_tx_int_dma_rd_start_addr0
 */
union cvmx_bbp_tx_int_dma_rd_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_start_addr0 cvmx_bbp_tx_int_dma_rd_start_addr0_t;

/**
 * cvmx_bbp_tx_int_dma_rd_status
 */
union cvmx_bbp_tx_int_dma_rd_status {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_status cvmx_bbp_tx_int_dma_rd_status_t;

/**
 * cvmx_bbp_tx_int_dma_rd_xfer_mode_count
 */
union cvmx_bbp_tx_int_dma_rd_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_xfer_mode_count cvmx_bbp_tx_int_dma_rd_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_int_dma_rd_xfer_q_status
 */
union cvmx_bbp_tx_int_dma_rd_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_xfer_q_status cvmx_bbp_tx_int_dma_rd_xfer_q_status_t;

/**
 * cvmx_bbp_tx_int_dma_rd_xfer_start
 */
union cvmx_bbp_tx_int_dma_rd_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_rd_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_rd_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_rd_xfer_start cvmx_bbp_tx_int_dma_rd_xfer_start_t;

/**
 * cvmx_bbp_tx_int_dma_wr_cbuf_end_addr0
 */
union cvmx_bbp_tx_int_dma_wr_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_cbuf_end_addr0 cvmx_bbp_tx_int_dma_wr_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_int_dma_wr_cbuf_start_addr0
 */
union cvmx_bbp_tx_int_dma_wr_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_cbuf_start_addr0 cvmx_bbp_tx_int_dma_wr_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_int_dma_wr_debug_dat
 */
union cvmx_bbp_tx_int_dma_wr_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_debug_dat cvmx_bbp_tx_int_dma_wr_debug_dat_t;

/**
 * cvmx_bbp_tx_int_dma_wr_debug_sel
 */
union cvmx_bbp_tx_int_dma_wr_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_debug_sel cvmx_bbp_tx_int_dma_wr_debug_sel_t;

/**
 * cvmx_bbp_tx_int_dma_wr_intr_clear
 */
union cvmx_bbp_tx_int_dma_wr_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_intr_clear cvmx_bbp_tx_int_dma_wr_intr_clear_t;

/**
 * cvmx_bbp_tx_int_dma_wr_intr_enb
 */
union cvmx_bbp_tx_int_dma_wr_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_intr_enb cvmx_bbp_tx_int_dma_wr_intr_enb_t;

/**
 * cvmx_bbp_tx_int_dma_wr_intr_rstatus
 */
union cvmx_bbp_tx_int_dma_wr_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_intr_rstatus cvmx_bbp_tx_int_dma_wr_intr_rstatus_t;

/**
 * cvmx_bbp_tx_int_dma_wr_intr_status
 */
union cvmx_bbp_tx_int_dma_wr_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_intr_status cvmx_bbp_tx_int_dma_wr_intr_status_t;

/**
 * cvmx_bbp_tx_int_dma_wr_intr_test
 */
union cvmx_bbp_tx_int_dma_wr_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_intr_test cvmx_bbp_tx_int_dma_wr_intr_test_t;

/**
 * cvmx_bbp_tx_int_dma_wr_memclr_data
 */
union cvmx_bbp_tx_int_dma_wr_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_memclr_data cvmx_bbp_tx_int_dma_wr_memclr_data_t;

/**
 * cvmx_bbp_tx_int_dma_wr_mode
 */
union cvmx_bbp_tx_int_dma_wr_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_mode_s  cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_mode cvmx_bbp_tx_int_dma_wr_mode_t;

/**
 * cvmx_bbp_tx_int_dma_wr_pri_mode
 */
union cvmx_bbp_tx_int_dma_wr_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_pri_mode cvmx_bbp_tx_int_dma_wr_pri_mode_t;

/**
 * cvmx_bbp_tx_int_dma_wr_start_addr0
 */
union cvmx_bbp_tx_int_dma_wr_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_start_addr0 cvmx_bbp_tx_int_dma_wr_start_addr0_t;

/**
 * cvmx_bbp_tx_int_dma_wr_status
 */
union cvmx_bbp_tx_int_dma_wr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_status cvmx_bbp_tx_int_dma_wr_status_t;

/**
 * cvmx_bbp_tx_int_dma_wr_xfer_mode_count
 */
union cvmx_bbp_tx_int_dma_wr_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_xfer_mode_count cvmx_bbp_tx_int_dma_wr_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_int_dma_wr_xfer_q_status
 */
union cvmx_bbp_tx_int_dma_wr_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_xfer_q_status cvmx_bbp_tx_int_dma_wr_xfer_q_status_t;

/**
 * cvmx_bbp_tx_int_dma_wr_xfer_start
 */
union cvmx_bbp_tx_int_dma_wr_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_int_dma_wr_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_int_dma_wr_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_int_dma_wr_xfer_start cvmx_bbp_tx_int_dma_wr_xfer_start_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_end_addr0
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_end_addr0 cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_start_addr0 cvmx_bbp_tx_lteenc_dma_rd_tb0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_dat
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_dat cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_dat_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_sel
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_sel cvmx_bbp_tx_lteenc_dma_rd_tb0_debug_sel_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_clear
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_clear cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_clear_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_enb
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_enb cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_enb_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_rstatus
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_rstatus cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_rstatus_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_status
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_status cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_test
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_test cvmx_bbp_tx_lteenc_dma_rd_tb0_intr_test_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_memclr_data
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_memclr_data cvmx_bbp_tx_lteenc_dma_rd_tb0_memclr_data_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_mode
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_mode cvmx_bbp_tx_lteenc_dma_rd_tb0_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_pri_mode
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_pri_mode cvmx_bbp_tx_lteenc_dma_rd_tb0_pri_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_start_addr0 cvmx_bbp_tx_lteenc_dma_rd_tb0_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_status
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_status cvmx_bbp_tx_lteenc_dma_rd_tb0_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_mode_count
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_mode_count cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_q_status
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_q_status cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_q_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_start
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_start cvmx_bbp_tx_lteenc_dma_rd_tb0_xfer_start_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_end_addr0
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_end_addr0 cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_start_addr0 cvmx_bbp_tx_lteenc_dma_rd_tb1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_dat
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_dat cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_dat_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_sel
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_sel cvmx_bbp_tx_lteenc_dma_rd_tb1_debug_sel_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_clear
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_clear cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_clear_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_enb
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_enb cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_enb_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_rstatus
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_rstatus cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_rstatus_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_status
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_status cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_test
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_test cvmx_bbp_tx_lteenc_dma_rd_tb1_intr_test_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_memclr_data
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_memclr_data cvmx_bbp_tx_lteenc_dma_rd_tb1_memclr_data_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_mode
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_mode cvmx_bbp_tx_lteenc_dma_rd_tb1_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_pri_mode
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_pri_mode cvmx_bbp_tx_lteenc_dma_rd_tb1_pri_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_start_addr0 cvmx_bbp_tx_lteenc_dma_rd_tb1_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_status
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_status cvmx_bbp_tx_lteenc_dma_rd_tb1_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_mode_count
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_mode_count cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_q_status
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_q_status cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_q_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_start
 */
union cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_start cvmx_bbp_tx_lteenc_dma_rd_tb1_xfer_start_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_end_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_end_addr0 cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_start_addr0 cvmx_bbp_tx_lteenc_dma_wr_cch_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_debug_dat
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_debug_dat cvmx_bbp_tx_lteenc_dma_wr_cch_debug_dat_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_debug_sel
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_debug_sel cvmx_bbp_tx_lteenc_dma_wr_cch_debug_sel_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_intr_clear
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_clear cvmx_bbp_tx_lteenc_dma_wr_cch_intr_clear_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_intr_enb
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_enb cvmx_bbp_tx_lteenc_dma_wr_cch_intr_enb_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_intr_rstatus
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_rstatus cvmx_bbp_tx_lteenc_dma_wr_cch_intr_rstatus_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_intr_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_status cvmx_bbp_tx_lteenc_dma_wr_cch_intr_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_intr_test
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_intr_test cvmx_bbp_tx_lteenc_dma_wr_cch_intr_test_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_memclr_data
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_memclr_data cvmx_bbp_tx_lteenc_dma_wr_cch_memclr_data_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_mode
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_mode cvmx_bbp_tx_lteenc_dma_wr_cch_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_pri_mode
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_pri_mode cvmx_bbp_tx_lteenc_dma_wr_cch_pri_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_start_addr0 cvmx_bbp_tx_lteenc_dma_wr_cch_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_status cvmx_bbp_tx_lteenc_dma_wr_cch_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_mode_count
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_mode_count cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_q_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_q_status cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_q_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_start
 */
union cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_start cvmx_bbp_tx_lteenc_dma_wr_cch_xfer_start_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_end_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_end_addr0 cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_start_addr0 cvmx_bbp_tx_lteenc_dma_wr_tb0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_dat
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_dat cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_dat_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_sel
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_sel cvmx_bbp_tx_lteenc_dma_wr_tb0_debug_sel_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_clear
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_clear cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_clear_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_enb
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_enb cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_enb_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_rstatus
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_rstatus cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_rstatus_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_status cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_test
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_test cvmx_bbp_tx_lteenc_dma_wr_tb0_intr_test_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_memclr_data
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_memclr_data cvmx_bbp_tx_lteenc_dma_wr_tb0_memclr_data_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_mode
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_mode cvmx_bbp_tx_lteenc_dma_wr_tb0_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_pri_mode
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_pri_mode cvmx_bbp_tx_lteenc_dma_wr_tb0_pri_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_start_addr0 cvmx_bbp_tx_lteenc_dma_wr_tb0_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_status cvmx_bbp_tx_lteenc_dma_wr_tb0_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_mode_count
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_mode_count cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_q_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_q_status cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_q_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_start
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_start cvmx_bbp_tx_lteenc_dma_wr_tb0_xfer_start_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_end_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_end_addr0 cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_start_addr0 cvmx_bbp_tx_lteenc_dma_wr_tb1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_dat
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_dat cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_dat_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_sel
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_sel cvmx_bbp_tx_lteenc_dma_wr_tb1_debug_sel_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_clear
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_clear cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_clear_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_enb
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_enb cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_enb_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_rstatus
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_rstatus cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_rstatus_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_status cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_test
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_test cvmx_bbp_tx_lteenc_dma_wr_tb1_intr_test_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_memclr_data
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_memclr_data cvmx_bbp_tx_lteenc_dma_wr_tb1_memclr_data_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_mode
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_mode cvmx_bbp_tx_lteenc_dma_wr_tb1_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_pri_mode
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_pri_mode cvmx_bbp_tx_lteenc_dma_wr_tb1_pri_mode_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_start_addr0
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_start_addr0 cvmx_bbp_tx_lteenc_dma_wr_tb1_start_addr0_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_status cvmx_bbp_tx_lteenc_dma_wr_tb1_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_mode_count
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_mode_count cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_q_status
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_q_status cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_q_status_t;

/**
 * cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_start
 */
union cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_start cvmx_bbp_tx_lteenc_dma_wr_tb1_xfer_start_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_cbuf_end_addr0
 */
union cvmx_bbp_tx_rfif_dma_rd_0_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_cbuf_end_addr0 cvmx_bbp_tx_rfif_dma_rd_0_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_cbuf_start_addr0
 */
union cvmx_bbp_tx_rfif_dma_rd_0_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_cbuf_start_addr0 cvmx_bbp_tx_rfif_dma_rd_0_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_debug_dat
 */
union cvmx_bbp_tx_rfif_dma_rd_0_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_debug_dat cvmx_bbp_tx_rfif_dma_rd_0_debug_dat_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_debug_sel
 */
union cvmx_bbp_tx_rfif_dma_rd_0_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_debug_sel cvmx_bbp_tx_rfif_dma_rd_0_debug_sel_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_intr_clear
 */
union cvmx_bbp_tx_rfif_dma_rd_0_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_intr_clear cvmx_bbp_tx_rfif_dma_rd_0_intr_clear_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_intr_enb
 */
union cvmx_bbp_tx_rfif_dma_rd_0_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_intr_enb cvmx_bbp_tx_rfif_dma_rd_0_intr_enb_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_intr_rstatus
 */
union cvmx_bbp_tx_rfif_dma_rd_0_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_intr_rstatus cvmx_bbp_tx_rfif_dma_rd_0_intr_rstatus_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_intr_status
 */
union cvmx_bbp_tx_rfif_dma_rd_0_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_intr_status cvmx_bbp_tx_rfif_dma_rd_0_intr_status_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_intr_test
 */
union cvmx_bbp_tx_rfif_dma_rd_0_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_intr_test cvmx_bbp_tx_rfif_dma_rd_0_intr_test_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_memclr_data
 */
union cvmx_bbp_tx_rfif_dma_rd_0_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_memclr_data cvmx_bbp_tx_rfif_dma_rd_0_memclr_data_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_mode
 */
union cvmx_bbp_tx_rfif_dma_rd_0_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_mode cvmx_bbp_tx_rfif_dma_rd_0_mode_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_pri_mode
 */
union cvmx_bbp_tx_rfif_dma_rd_0_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_pri_mode cvmx_bbp_tx_rfif_dma_rd_0_pri_mode_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_start_addr0
 */
union cvmx_bbp_tx_rfif_dma_rd_0_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_start_addr0 cvmx_bbp_tx_rfif_dma_rd_0_start_addr0_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_status
 */
union cvmx_bbp_tx_rfif_dma_rd_0_status {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_status cvmx_bbp_tx_rfif_dma_rd_0_status_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_xfer_mode_count
 */
union cvmx_bbp_tx_rfif_dma_rd_0_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_xfer_mode_count cvmx_bbp_tx_rfif_dma_rd_0_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_xfer_q_status
 */
union cvmx_bbp_tx_rfif_dma_rd_0_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_xfer_q_status cvmx_bbp_tx_rfif_dma_rd_0_xfer_q_status_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_0_xfer_start
 */
union cvmx_bbp_tx_rfif_dma_rd_0_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_0_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_0_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_0_xfer_start cvmx_bbp_tx_rfif_dma_rd_0_xfer_start_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_cbuf_end_addr0
 */
union cvmx_bbp_tx_rfif_dma_rd_1_cbuf_end_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_cbuf_end_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer End Address0
                                                         The Circular Buffer End Address register indicates the
                                                         end of the circular buffer.  If the circular buffer
                                                         feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_cbuf_end_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_cbuf_end_addr0 cvmx_bbp_tx_rfif_dma_rd_1_cbuf_end_addr0_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_cbuf_start_addr0
 */
union cvmx_bbp_tx_rfif_dma_rd_1_cbuf_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_cbuf_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Circular Buffer Start Address0
                                                         The Circular Buffer Start Address register indicates
                                                         the start of the circular buffer.   If the circular
                                                         buffer feature is enable, when the transfer exceeds the
                                                         Circular Buffer End Address, the HMM wraps the transfer
                                                         address to the Circular Buffer Start address.
                                                         This register is for the 1st data stream. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_cbuf_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_cbuf_start_addr0 cvmx_bbp_tx_rfif_dma_rd_1_cbuf_start_addr0_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_debug_dat
 */
union cvmx_bbp_tx_rfif_dma_rd_1_debug_dat {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_debug_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t dbg_data                     : 32; /**< Debug Data
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
#else
	uint32_t dbg_data                     : 32;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_debug_dat_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_debug_dat cvmx_bbp_tx_rfif_dma_rd_1_debug_dat_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_debug_sel
 */
union cvmx_bbp_tx_rfif_dma_rd_1_debug_sel {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_debug_sel_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_8_31                : 24;
	uint32_t dbg_sel                      : 4;  /**< Debug Select
                                                         This field select which sets of signals that can be
                                                         read from the HMM Debug Data register.
                                                         Please contact Cavium if you need access to this debug
                                                         register. */
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_en                       : 1;  /**< Debug Mode Enable
                                                         This bit enables or disables the Debug Data register.
                                                         When 1, the Debug Data register stores internal HMM
                                                         signal register.
                                                         When 0, the Debug Data register returns zeros. */
#else
	uint32_t dbg_en                       : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t dbg_sel                      : 4;
	uint32_t reserved_8_31                : 24;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_debug_sel_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_debug_sel cvmx_bbp_tx_rfif_dma_rd_1_debug_sel_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_intr_clear
 */
union cvmx_bbp_tx_rfif_dma_rd_1_intr_clear {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_clear_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_clr         : 1;  /**< Transfer Queue Interrupt Clear
                                                         Write 1 to clear the Transfer Queue interrupt. */
	uint32_t xfer_done_int_clr            : 1;  /**< Transfer Done Interrupt Clear
                                                         Write 1 to clear the Transfer Done interrupt. */
#else
	uint32_t xfer_done_int_clr            : 1;
	uint32_t xfer_q_empty_int_clr         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_clear_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_intr_clear cvmx_bbp_tx_rfif_dma_rd_1_intr_clear_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_intr_enb
 */
union cvmx_bbp_tx_rfif_dma_rd_1_intr_enb {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_enb_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_mask        : 1;  /**< Transfer Queue Interrupt Mask
                                                         Enables the Transfer Queue Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
	uint32_t xfer_done_int_mask           : 1;  /**< Transfer Done Interrupt Mask
                                                         Enables the Transfer Done Interrupt to the system.  This
                                                         when 0 masks the interrupt. */
#else
	uint32_t xfer_done_int_mask           : 1;
	uint32_t xfer_q_empty_int_mask        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_enb_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_intr_enb cvmx_bbp_tx_rfif_dma_rd_1_intr_enb_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_intr_rstatus
 */
union cvmx_bbp_tx_rfif_dma_rd_1_intr_rstatus {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_rstatus_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_raw_q_empty_int         : 1;  /**< Raw Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty
                                                         before the interrupt enable. */
	uint32_t xfer_raw_done_int            : 1;  /**< Raw Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete
                                                         before the interrupt enable. */
#else
	uint32_t xfer_raw_done_int            : 1;
	uint32_t xfer_raw_q_empty_int         : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_rstatus_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_intr_rstatus cvmx_bbp_tx_rfif_dma_rd_1_intr_rstatus_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_intr_status
 */
union cvmx_bbp_tx_rfif_dma_rd_1_intr_status {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int             : 1;  /**< Transfer Queue Empty Interrupt
                                                         Interrupt indicating that the transfer queue is empty.
                                                         This is the logcial AND of the interrupt and mask */
	uint32_t xfer_done_int                : 1;  /**< Transfer Done Interrupt
                                                         Interrupt indicating that a transfer is complete.
                                                         This is the logcial AND of the interrupt and mask */
#else
	uint32_t xfer_done_int                : 1;
	uint32_t xfer_q_empty_int             : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_intr_status cvmx_bbp_tx_rfif_dma_rd_1_intr_status_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_intr_test
 */
union cvmx_bbp_tx_rfif_dma_rd_1_intr_test {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_test_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t xfer_q_empty_int_test        : 1;  /**< Transfer Queue Interrupt Test
                                                         Write 1 to set the Transfer Queue Empty Interrupt.  This
                                                         can be used for software test. */
	uint32_t xfer_done_int_test           : 1;  /**< Transfer Done Interrupt Test
                                                         Write 1 to set the Transfer Done Interrupt.  This can be
                                                         used for software test. */
#else
	uint32_t xfer_done_int_test           : 1;
	uint32_t xfer_q_empty_int_test        : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_intr_test_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_intr_test cvmx_bbp_tx_rfif_dma_rd_1_intr_test_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_memclr_data
 */
union cvmx_bbp_tx_rfif_dma_rd_1_memclr_data {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_memclr_data_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t memclr_data                  : 32; /**< Memory Clear Data
                                                         For HMM Write Channels, when Memory Clear Mode is
                                                         enabled and Memory Clear Data Select is set to 1, this
                                                         register holds the 32-bit value that is written to
                                                         memory.  Programmers must set this register before the
                                                         memory transfer is started. */
#else
	uint32_t memclr_data                  : 32;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_memclr_data_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_memclr_data cvmx_bbp_tx_rfif_dma_rd_1_memclr_data_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_mode
 */
union cvmx_bbp_tx_rfif_dma_rd_1_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t itlv_bufmode                 : 2;  /**< Interleaver Mode
                                                         If the channel is an interleaver channel, this sets the
                                                         interleave mode : 0==1:1, 1==2:1, 2==4:1 */
	uint32_t reserved_3_3                 : 1;
	uint32_t mem_clr_data_sel             : 1;  /**< Memory Clear Data Select
                                                         This register setting is valid only when the Memory Clear
                                                         Mode is enabled.
                                                         When 0, 32'h0 is written to the selected memory locations
                                                         When 1, the value of the Memory Clear Data register is
                                                         written to the selected memory locations */
	uint32_t mem_clr_enb                  : 1;  /**< Memory Clear Enable
                                                         When 1, enables the memory clear mode.
                                                         This feature is for HMM Write channels and can be used to
                                                         store a fixed value to memory.The HMM write channel,
                                                         in this mode, ignores the control and data from
                                                         particular HAB it is connected to. The data is
                                                         either the value of 32'h0 or the value in the Memory Clear
                                                         Data register depending on the MEM_CLR_DATA_SEL bit .
                                                         The intent of this mode is to allow the programmer to
                                                         write a fixed value into memory without needing to enable
                                                         the HAB. The other parameters used to program the HMM
                                                         Write Channel (ie, start address, word count, etc) are
                                                         still valid. */
	uint32_t auto_clk_enb                 : 1;  /**< Auto clock enable
                                                         Enables auto clock gating when set to 1. */
#else
	uint32_t auto_clk_enb                 : 1;
	uint32_t mem_clr_enb                  : 1;
	uint32_t mem_clr_data_sel             : 1;
	uint32_t reserved_3_3                 : 1;
	uint32_t itlv_bufmode                 : 2;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_mode cvmx_bbp_tx_rfif_dma_rd_1_mode_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_pri_mode
 */
union cvmx_bbp_tx_rfif_dma_rd_1_pri_mode {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_pri_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t priority_en                  : 1;  /**< Priority Request Enable */
	uint32_t reserved_8_30                : 23;
	uint32_t priority_cnt                 : 8;  /**< Priority Request Count */
#else
	uint32_t priority_cnt                 : 8;
	uint32_t reserved_8_30                : 23;
	uint32_t priority_en                  : 1;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_pri_mode_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_pri_mode cvmx_bbp_tx_rfif_dma_rd_1_pri_mode_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_start_addr0
 */
union cvmx_bbp_tx_rfif_dma_rd_1_start_addr0 {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_start_addr0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t addr                         : 24; /**< Transfer Start Address0
                                                         Specifies the start address of the HMM transfer.  This
                                                         address is either the source address or target address
                                                         of the transfer depending on the HMM type. */
#else
	uint32_t addr                         : 24;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_start_addr0_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_start_addr0 cvmx_bbp_tx_rfif_dma_rd_1_start_addr0_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_status
 */
union cvmx_bbp_tx_rfif_dma_rd_1_status {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_24_31               : 8;
	uint32_t read0_or_write1              : 1;  /**< When 0 indicates a read channel or when 1 a write channel */
	uint32_t intl_channel                 : 1;  /**< When 1 indicates a interleaver channel */
	uint32_t ssm_statem                   : 2;  /**< Start Stop Statemachine
                                                         Internal statemachine indicating the state of the
                                                         interface between the hab and hmm.
                                                         00=idle, 01=started, 10=hab done */
	uint32_t reserved_19_19               : 1;
	uint32_t tss_statem                   : 3;  /**< Transfer Start State Machine
                                                         Internal statemachine indicating the status of the mclk
                                                         side of the transfer.
                                                         000-wait for transfer start.
                                                         001-assert start in mclk and waiting for start ack
                                                         011-wait for start ack deassertion
                                                         010-wait for mclk sm to assert done
                                                         110-wait for done deassertion */
	uint32_t reserved_9_15                : 7;
	uint32_t cqueue_valid                 : 1;  /**< Command Queue Valid
                                                         When 1, indicates there is at least 1 valid command. */
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_full                  : 1;  /**< Command Queue Full
                                                         When 1, indicates the command queue is full. */
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_empty                 : 1;  /**< Command Queue Empty
                                                         When 1, indicates the command queue is empty. */
#else
	uint32_t cqueue_empty                 : 1;
	uint32_t reserved_1_3                 : 3;
	uint32_t cqueue_full                  : 1;
	uint32_t reserved_5_7                 : 3;
	uint32_t cqueue_valid                 : 1;
	uint32_t reserved_9_15                : 7;
	uint32_t tss_statem                   : 3;
	uint32_t reserved_19_19               : 1;
	uint32_t ssm_statem                   : 2;
	uint32_t intl_channel                 : 1;
	uint32_t read0_or_write1              : 1;
	uint32_t reserved_24_31               : 8;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_status cvmx_bbp_tx_rfif_dma_rd_1_status_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_xfer_mode_count
 */
union cvmx_bbp_tx_rfif_dma_rd_1_xfer_mode_count {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_xfer_mode_count_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_done_intr               : 1;  /**< Transfer Done Interrupt
                                                         Enables Done Interrupt.  The Transfer Done interrupt is
                                                         set once the transfer is complete. */
	uint32_t slice_mode                   : 1;  /**< Slice Mode
                                                         Enables Slce Mode for the current transfer.  The HMM
                                                         does not assert the "DONE" or "LAST Data" signal to the
                                                         HAB at the end of the transfer. */
	uint32_t cbuf_mode                    : 1;  /**< Circular Buffer Mode
                                                         Enables the circular buffer feature for the current
                                                         transfer.  When the address hits the Circular Buffer
                                                         End Address, the HMM resets the address to the Circular
                                                         Buffer Start address. */
	uint32_t reserved_16_28               : 13;
	uint32_t xfer_count                   : 16; /**< Transfer Count
                                                         Specifies the number of data to be transfered to/from
                                                         the hab.  If the channel is a read channel, data is
                                                         to the hab.  If the channel is a write channel, data is
                                                         from the hab.
                                                         The data size is dependent on the channel size.  If it
                                                         a native 64-bit wide port, the data size is 64-bit.
                                                         Else the data is 32-bit wide. */
#else
	uint32_t xfer_count                   : 16;
	uint32_t reserved_16_28               : 13;
	uint32_t cbuf_mode                    : 1;
	uint32_t slice_mode                   : 1;
	uint32_t xfer_done_intr               : 1;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_xfer_mode_count_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_xfer_mode_count cvmx_bbp_tx_rfif_dma_rd_1_xfer_mode_count_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_xfer_q_status
 */
union cvmx_bbp_tx_rfif_dma_rd_1_xfer_q_status {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_xfer_q_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t xfer_q_status                : 32; /**< Transfer Queue Status
                                                         Number of free slots in the transfer queue. */
#else
	uint32_t xfer_q_status                : 32;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_xfer_q_status_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_xfer_q_status cvmx_bbp_tx_rfif_dma_rd_1_xfer_q_status_t;

/**
 * cvmx_bbp_tx_rfif_dma_rd_1_xfer_start
 */
union cvmx_bbp_tx_rfif_dma_rd_1_xfer_start {
	uint32_t u32;
	struct cvmx_bbp_tx_rfif_dma_rd_1_xfer_start_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t xfer_start                   : 1;  /**< Transfer Start
                                                         Write 1 to initiate the transfer.  The Transfer Start
                                                         Address and Count registers should be setup before the
                                                         transfer. */
#else
	uint32_t xfer_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_tx_rfif_dma_rd_1_xfer_start_s cnf71xx;
};
typedef union cvmx_bbp_tx_rfif_dma_rd_1_xfer_start cvmx_bbp_tx_rfif_dma_rd_1_xfer_start_t;

/**
 * cvmx_bbp_txint_cntl_hi#
 *
 * TXINT_CNTL_HI - Interrupt Enable HI
 *
 */
union cvmx_bbp_txint_cntl_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_cntl_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enab                         : 1;  /**< Interrupt Enable */
#else
	uint32_t enab                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_txint_cntl_hix_s      cnf71xx;
};
typedef union cvmx_bbp_txint_cntl_hix cvmx_bbp_txint_cntl_hix_t;

/**
 * cvmx_bbp_txint_cntl_lo#
 *
 * TXINT_CNTL_LO - Interrupt Enable LO
 *
 */
union cvmx_bbp_txint_cntl_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_cntl_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t enab                         : 1;  /**< Interrupt Enable */
#else
	uint32_t enab                         : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_txint_cntl_lox_s      cnf71xx;
};
typedef union cvmx_bbp_txint_cntl_lox cvmx_bbp_txint_cntl_lox_t;

/**
 * cvmx_bbp_txint_index_hi#
 *
 * TXINT_INDEX_HI - Overall Index HI
 *
 */
union cvmx_bbp_txint_index_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_index_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t index                        : 9;  /**< Overall Interrup Index */
#else
	uint32_t index                        : 9;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_txint_index_hix_s     cnf71xx;
};
typedef union cvmx_bbp_txint_index_hix cvmx_bbp_txint_index_hix_t;

/**
 * cvmx_bbp_txint_index_lo#
 *
 * TXINT_INDEX_LO - Overall Index LO
 *
 */
union cvmx_bbp_txint_index_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_index_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_9_31                : 23;
	uint32_t index                        : 9;  /**< Overall Interrup Index */
#else
	uint32_t index                        : 9;
	uint32_t reserved_9_31                : 23;
#endif
	} s;
	struct cvmx_bbp_txint_index_lox_s     cnf71xx;
};
typedef union cvmx_bbp_txint_index_lox cvmx_bbp_txint_index_lox_t;

/**
 * cvmx_bbp_txint_misc_idx_hi#
 *
 * TXINT_MISC_IDX_HI - Misc Group Index HI
 *
 */
union cvmx_bbp_txint_misc_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Misc Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_misc_idx_hix_s  cnf71xx;
};
typedef union cvmx_bbp_txint_misc_idx_hix cvmx_bbp_txint_misc_idx_hix_t;

/**
 * cvmx_bbp_txint_misc_idx_lo#
 *
 * TXINT_MISC_IDX_LO - Misc Group Index LO
 *
 */
union cvmx_bbp_txint_misc_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Misc Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_misc_idx_lox_s  cnf71xx;
};
typedef union cvmx_bbp_txint_misc_idx_lox cvmx_bbp_txint_misc_idx_lox_t;

/**
 * cvmx_bbp_txint_misc_mask_hi#
 *
 * TXINT_MISC_MASK_HI = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_txint_misc_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_tx_ppssync                : 1;  /**< TX PPS Sync Done */
	uint32_t rf_tx_spiskip                : 1;  /**< TX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_tx_sttx                   : 1;  /**< TX Start TX */
	uint32_t rf_tx_stframe                : 1;  /**< TX Start Frame */
	uint32_t rf_txd_ffflag                : 1;  /**< TX DIV FIFO flags asserted */
	uint32_t rf_txd_ffthresh              : 1;  /**< TX DIV FIFO Threshhold reached */
	uint32_t rf_tx_ffflag                 : 1;  /**< TX FIFO flags asserted */
	uint32_t rf_tx_ffthresh               : 1;  /**< TX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_tx_ffthresh               : 1;
	uint32_t rf_tx_ffflag                 : 1;
	uint32_t rf_txd_ffthresh              : 1;
	uint32_t rf_txd_ffflag                : 1;
	uint32_t rf_tx_stframe                : 1;
	uint32_t rf_tx_sttx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_tx_spiskip                : 1;
	uint32_t rf_tx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_txint_misc_mask_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_misc_mask_hix cvmx_bbp_txint_misc_mask_hix_t;

/**
 * cvmx_bbp_txint_misc_mask_lo#
 *
 * TXINT_MISC_MASK_LO = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_txint_misc_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_tx_ppssync                : 1;  /**< TX PPS Sync Done */
	uint32_t rf_tx_spiskip                : 1;  /**< TX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_tx_sttx                   : 1;  /**< TX Start TX */
	uint32_t rf_tx_stframe                : 1;  /**< TX Start Frame */
	uint32_t rf_txd_ffflag                : 1;  /**< TX DIV FIFO flags asserted */
	uint32_t rf_txd_ffthresh              : 1;  /**< TX DIV FIFO Threshhold reached */
	uint32_t rf_tx_ffflag                 : 1;  /**< TX FIFO flags asserted */
	uint32_t rf_tx_ffthresh               : 1;  /**< TX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_tx_ffthresh               : 1;
	uint32_t rf_tx_ffflag                 : 1;
	uint32_t rf_txd_ffthresh              : 1;
	uint32_t rf_txd_ffflag                : 1;
	uint32_t rf_tx_stframe                : 1;
	uint32_t rf_tx_sttx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_tx_spiskip                : 1;
	uint32_t rf_tx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_txint_misc_mask_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_misc_mask_lox cvmx_bbp_txint_misc_mask_lox_t;

/**
 * cvmx_bbp_txint_misc_rint
 *
 * TXINT_MISC_RINT - MISC Raw Interrupt Status
 *
 */
union cvmx_bbp_txint_misc_rint {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_tx_ppssync                : 1;  /**< TX PPS Sync Done */
	uint32_t rf_tx_spiskip                : 1;  /**< TX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_tx_sttx                   : 1;  /**< TX Start TX */
	uint32_t rf_tx_stframe                : 1;  /**< TX Start Frame */
	uint32_t rf_txd_ffflag                : 1;  /**< TX DIV FIFO flags asserted */
	uint32_t rf_txd_ffthresh              : 1;  /**< TX DIV FIFO Threshhold reached */
	uint32_t rf_tx_ffflag                 : 1;  /**< TX FIFO flags asserted */
	uint32_t rf_tx_ffthresh               : 1;  /**< TX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_tx_ffthresh               : 1;
	uint32_t rf_tx_ffflag                 : 1;
	uint32_t rf_txd_ffthresh              : 1;
	uint32_t rf_txd_ffflag                : 1;
	uint32_t rf_tx_stframe                : 1;
	uint32_t rf_tx_sttx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_tx_spiskip                : 1;
	uint32_t rf_tx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_txint_misc_rint_s     cnf71xx;
};
typedef union cvmx_bbp_txint_misc_rint cvmx_bbp_txint_misc_rint_t;

/**
 * cvmx_bbp_txint_misc_status_hi#
 *
 * TXINT_MISC_STATUS_HI = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_txint_misc_status_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_tx_ppssync                : 1;  /**< TX PPS Sync Done */
	uint32_t rf_tx_spiskip                : 1;  /**< TX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_tx_sttx                   : 1;  /**< TX Start TX */
	uint32_t rf_tx_stframe                : 1;  /**< TX Start Frame */
	uint32_t rf_txd_ffflag                : 1;  /**< TX DIV FIFO flags asserted */
	uint32_t rf_txd_ffthresh              : 1;  /**< TX DIV FIFO Threshhold reached */
	uint32_t rf_tx_ffflag                 : 1;  /**< TX FIFO flags asserted */
	uint32_t rf_tx_ffthresh               : 1;  /**< TX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_tx_ffthresh               : 1;
	uint32_t rf_tx_ffflag                 : 1;
	uint32_t rf_txd_ffthresh              : 1;
	uint32_t rf_txd_ffflag                : 1;
	uint32_t rf_tx_stframe                : 1;
	uint32_t rf_tx_sttx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_tx_spiskip                : 1;
	uint32_t rf_tx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_txint_misc_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_misc_status_hix cvmx_bbp_txint_misc_status_hix_t;

/**
 * cvmx_bbp_txint_misc_status_lo#
 *
 * TXINT_MISC_STATUS_LO = Interrupt MISC Group Mask
 *
 */
union cvmx_bbp_txint_misc_status_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_misc_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rf_tx_ppssync                : 1;  /**< TX PPS Sync Done */
	uint32_t rf_tx_spiskip                : 1;  /**< TX SPI Event Skipped */
	uint32_t rf_spi3                      : 1;  /**< SPI Transfer Done Event 3 */
	uint32_t rf_spi2                      : 1;  /**< SPI Transfer Done Event 2 */
	uint32_t rf_spi1                      : 1;  /**< SPI Transfer Done Event 1 */
	uint32_t rf_spi0                      : 1;  /**< SPI Transfer Done Event 0 */
	uint32_t rf_tx_sttx                   : 1;  /**< TX Start TX */
	uint32_t rf_tx_stframe                : 1;  /**< TX Start Frame */
	uint32_t rf_txd_ffflag                : 1;  /**< TX DIV FIFO flags asserted */
	uint32_t rf_txd_ffthresh              : 1;  /**< TX DIV FIFO Threshhold reached */
	uint32_t rf_tx_ffflag                 : 1;  /**< TX FIFO flags asserted */
	uint32_t rf_tx_ffthresh               : 1;  /**< TX FIFO Threshhold reached */
	uint32_t tti_timer                    : 8;  /**< TTI Timer Interrupt */
	uint32_t axi_berr                     : 1;  /**< AXI Bus Error */
	uint32_t rfspi                        : 1;  /**< RFSPI Interrupt */
	uint32_t ifftpapr                     : 1;  /**< IFFTPAPR HAB Interrupt */
	uint32_t h3genc                       : 1;  /**< 3G Encoder HAB Interrupt */
	uint32_t lteenc                       : 1;  /**< LTE Encoder HAB Interrupt */
	uint32_t vdec                         : 1;  /**< Viterbi Decoder HAB Interrupt */
	uint32_t turbo_rddone                 : 1;  /**< TURBO Decoder HAB Read Done */
	uint32_t turbo_done                   : 1;  /**< TURBO Decoder HAB Done */
	uint32_t turbo                        : 1;  /**< TURBO Decoder HAB Interrupt */
	uint32_t dftdmp                       : 1;  /**< DFTDMP HAB Interrupt */
	uint32_t rach                         : 1;  /**< RACH HAB Interrupt */
	uint32_t ulfe                         : 1;  /**< ULFE HAB Interrupt */
#else
	uint32_t ulfe                         : 1;
	uint32_t rach                         : 1;
	uint32_t dftdmp                       : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_done                   : 1;
	uint32_t turbo_rddone                 : 1;
	uint32_t vdec                         : 1;
	uint32_t lteenc                       : 1;
	uint32_t h3genc                       : 1;
	uint32_t ifftpapr                     : 1;
	uint32_t rfspi                        : 1;
	uint32_t axi_berr                     : 1;
	uint32_t tti_timer                    : 8;
	uint32_t rf_tx_ffthresh               : 1;
	uint32_t rf_tx_ffflag                 : 1;
	uint32_t rf_txd_ffthresh              : 1;
	uint32_t rf_txd_ffflag                : 1;
	uint32_t rf_tx_stframe                : 1;
	uint32_t rf_tx_sttx                   : 1;
	uint32_t rf_spi0                      : 1;
	uint32_t rf_spi1                      : 1;
	uint32_t rf_spi2                      : 1;
	uint32_t rf_spi3                      : 1;
	uint32_t rf_tx_spiskip                : 1;
	uint32_t rf_tx_ppssync                : 1;
#endif
	} s;
	struct cvmx_bbp_txint_misc_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_misc_status_lox cvmx_bbp_txint_misc_status_lox_t;

/**
 * cvmx_bbp_txint_rd_idx_hi#
 *
 * TXINT_RD_IDX_HI - Read Done Group Index HI
 *
 */
union cvmx_bbp_txint_rd_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_rd_idx_hix_s    cnf71xx;
};
typedef union cvmx_bbp_txint_rd_idx_hix cvmx_bbp_txint_rd_idx_hix_t;

/**
 * cvmx_bbp_txint_rd_idx_lo#
 *
 * TXINT_RD_IDX_LO - Read Done Group Index LO
 *
 */
union cvmx_bbp_txint_rd_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_rd_idx_lox_s    cnf71xx;
};
typedef union cvmx_bbp_txint_rd_idx_lox cvmx_bbp_txint_rd_idx_lox_t;

/**
 * cvmx_bbp_txint_rd_mask_hi#
 *
 * TXINT_RD_MASK_HI = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_txint_rd_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t3seq_intr                   : 8;  /**< TX Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t3seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_txint_rd_mask_hix_s   cnf71xx;
};
typedef union cvmx_bbp_txint_rd_mask_hix cvmx_bbp_txint_rd_mask_hix_t;

/**
 * cvmx_bbp_txint_rd_mask_lo#
 *
 * TXINT_RD_MASK_LO = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_txint_rd_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t3seq_intr                   : 8;  /**< TX Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t3seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_txint_rd_mask_lox_s   cnf71xx;
};
typedef union cvmx_bbp_txint_rd_mask_lox cvmx_bbp_txint_rd_mask_lox_t;

/**
 * cvmx_bbp_txint_rd_rint
 *
 * TXINT_RD_RINT - Read Done Group Raw Interrupt Status
 *
 */
union cvmx_bbp_txint_rd_rint {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t3seq_intr                   : 8;  /**< TX Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t3seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_txint_rd_rint_s       cnf71xx;
};
typedef union cvmx_bbp_txint_rd_rint cvmx_bbp_txint_rd_rint_t;

/**
 * cvmx_bbp_txint_rd_status_hi#
 *
 * TXINT_RD_STATUS_HI = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_txint_rd_status_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t3seq_intr                   : 8;  /**< TX Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t3seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_txint_rd_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_rd_status_hix cvmx_bbp_txint_rd_status_hix_t;

/**
 * cvmx_bbp_txint_rd_status_lo#
 *
 * TXINT_RD_STATUS_LO = Interrupt Read Done Group Mask
 *
 */
union cvmx_bbp_txint_rd_status_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_rd_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t t3seq_intr                   : 8;  /**< TX Sequencer Interupts */
	uint32_t t3_rfif_1                    : 1;  /**< RFIF_1 Read Done */
	uint32_t t3_rfif_0                    : 1;  /**< RFIF_0 Read Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Read Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Read Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Read Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Read Done */
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Done */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Done */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Done */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Done */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Done */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Done */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Done */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Done */
	uint32_t rachsnif                     : 1;  /**< RACH Read Done */
	uint32_t ulfe                         : 1;  /**< ULFE Read Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t3_rfif_0                    : 1;
	uint32_t t3_rfif_1                    : 1;
	uint32_t t3seq_intr                   : 8;
#endif
	} s;
	struct cvmx_bbp_txint_rd_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_rd_status_lox cvmx_bbp_txint_rd_status_lox_t;

/**
 * cvmx_bbp_txint_rdq_idx_hi#
 *
 * TXINT_RDQ_IDX_HI - Read Queue Empty Group Index HI
 *
 */
union cvmx_bbp_txint_rdq_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_idx_hix cvmx_bbp_txint_rdq_idx_hix_t;

/**
 * cvmx_bbp_txint_rdq_idx_lo#
 *
 * TXINT_RDQ_IDX_LO - Read Queue Empty Group Index LO
 *
 */
union cvmx_bbp_txint_rdq_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Read Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_idx_lox cvmx_bbp_txint_rdq_idx_lox_t;

/**
 * cvmx_bbp_txint_rdq_mask_hi#
 *
 * TXINT_RDQ_MASK_HI = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_rdq_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_mask_hix cvmx_bbp_txint_rdq_mask_hix_t;

/**
 * cvmx_bbp_txint_rdq_mask_lo#
 *
 * TXINT_RDQ_MASK_LO = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_rdq_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_mask_lox cvmx_bbp_txint_rdq_mask_lox_t;

/**
 * cvmx_bbp_txint_rdq_rint
 *
 * TXINT_RDQ_RINT - Read Queue Empty Group Raw Interrupt Status
 *
 */
union cvmx_bbp_txint_rdq_rint {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_rint_s      cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_rint cvmx_bbp_txint_rdq_rint_t;

/**
 * cvmx_bbp_txint_rdq_status_hi#
 *
 * TXINT_RDQ_STATUS_HI = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_rdq_status_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_status_hix cvmx_bbp_txint_rdq_status_hix_t;

/**
 * cvmx_bbp_txint_rdq_status_lo#
 *
 * TXINT_RDQ_STATUS_LO = Interrupt Read Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_rdq_status_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_rdq_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_18_31               : 14;
	uint32_t t3_int                       : 1;  /**< TX to PHY Read Queue Empty */
	uint32_t t3_ext                       : 1;  /**< TX to Host Read Queue Empty */
	uint32_t t2_int                       : 1;  /**< RX1 to PHY Read Queue Empty */
	uint32_t t2_harq                      : 1;  /**< HARQ to Host Read Queue Empty */
	uint32_t t2_ext                       : 1;  /**< RX1 to Host Read Queue Empty */
	uint32_t t1_int                       : 1;  /**< RX0 to PHY Read Queue Empty */
	uint32_t t1_ext                       : 1;  /**< RX0 to Host Read Queue Empty */
	uint32_t ifftpapr_rm                  : 1;  /**< IFFTPAPR_RM Read Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Read Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Read Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Read Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Read Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Read Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Read Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Read Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Read Queue Empty */
	uint32_t rachsnif                     : 1;  /**< RACH Read Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Read Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif                     : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t ifftpapr_rm                  : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_int                       : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t reserved_18_31               : 14;
#endif
	} s;
	struct cvmx_bbp_txint_rdq_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_rdq_status_lox cvmx_bbp_txint_rdq_status_lox_t;

/**
 * cvmx_bbp_txint_stat_hi#
 *
 * TXINT_STAT_HI - Grouped Interrupt Status HI
 *
 */
union cvmx_bbp_txint_stat_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_stat_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t misc                         : 1;  /**< Misc Group Interrupt */
	uint32_t sw                           : 1;  /**< SW Group Interrupt */
	uint32_t wrqdone                      : 1;  /**< Write  Queue Empty Group Interrupt */
	uint32_t rdqdone                      : 1;  /**< Read  Queue Empty Group Interrupt */
	uint32_t rddone                       : 1;  /**< Read  Done Group Interrupt */
	uint32_t wrdone                       : 1;  /**< Write Done Group Interrupt */
#else
	uint32_t wrdone                       : 1;
	uint32_t rddone                       : 1;
	uint32_t rdqdone                      : 1;
	uint32_t wrqdone                      : 1;
	uint32_t sw                           : 1;
	uint32_t misc                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_stat_hix_s      cnf71xx;
};
typedef union cvmx_bbp_txint_stat_hix cvmx_bbp_txint_stat_hix_t;

/**
 * cvmx_bbp_txint_stat_lo#
 *
 * TXINT_STAT_LO - Grouped Interrupt Status LO
 *
 */
union cvmx_bbp_txint_stat_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_stat_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t misc                         : 1;  /**< Misc Group Interrupt */
	uint32_t sw                           : 1;  /**< SW Group Interrupt */
	uint32_t wrqdone                      : 1;  /**< Write  Queue Empty Group Interrupt */
	uint32_t rdqdone                      : 1;  /**< Read  Queue Empty Group Interrupt */
	uint32_t rddone                       : 1;  /**< Read  Done Group Interrupt */
	uint32_t wrdone                       : 1;  /**< Write Done Group Interrupt */
#else
	uint32_t wrdone                       : 1;
	uint32_t rddone                       : 1;
	uint32_t rdqdone                      : 1;
	uint32_t wrqdone                      : 1;
	uint32_t sw                           : 1;
	uint32_t misc                         : 1;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_stat_lox_s      cnf71xx;
};
typedef union cvmx_bbp_txint_stat_lox cvmx_bbp_txint_stat_lox_t;

/**
 * cvmx_bbp_txint_sw_idx_hi#
 *
 * TXINT_SW_IDX_HI - SW Group Index HI
 *
 */
union cvmx_bbp_txint_sw_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< SW Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_sw_idx_hix_s    cnf71xx;
};
typedef union cvmx_bbp_txint_sw_idx_hix cvmx_bbp_txint_sw_idx_hix_t;

/**
 * cvmx_bbp_txint_sw_idx_lo#
 *
 * TXINT_SW_IDX_LO - SW Group Index LO
 *
 */
union cvmx_bbp_txint_sw_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< SW Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_sw_idx_lox_s    cnf71xx;
};
typedef union cvmx_bbp_txint_sw_idx_lox cvmx_bbp_txint_sw_idx_lox_t;

/**
 * cvmx_bbp_txint_sw_mask_hi#
 *
 * TXINT_SW_MASK_HI = Interrupt SW Mask
 *
 */
union cvmx_bbp_txint_sw_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_txint_sw_mask_hix_s   cnf71xx;
};
typedef union cvmx_bbp_txint_sw_mask_hix cvmx_bbp_txint_sw_mask_hix_t;

/**
 * cvmx_bbp_txint_sw_mask_lo#
 *
 * TXINT_SW_MASK_LO = Interrupt SW Mask
 *
 */
union cvmx_bbp_txint_sw_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_txint_sw_mask_lox_s   cnf71xx;
};
typedef union cvmx_bbp_txint_sw_mask_lox cvmx_bbp_txint_sw_mask_lox_t;

/**
 * cvmx_bbp_txint_sw_rint
 *
 * TXINT_SW_RINT - SW Raw Interrupt Status
 *
 */
union cvmx_bbp_txint_sw_rint {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_txint_sw_rint_s       cnf71xx;
};
typedef union cvmx_bbp_txint_sw_rint cvmx_bbp_txint_sw_rint_t;

/**
 * cvmx_bbp_txint_sw_status_hi#
 *
 * TXINT_SW_STATUS_HI = Interrupt SW Mask
 *
 */
union cvmx_bbp_txint_sw_status_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_txint_sw_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_sw_status_hix cvmx_bbp_txint_sw_status_hix_t;

/**
 * cvmx_bbp_txint_sw_status_lo#
 *
 * TXINT_SW_STATUS_LO = Interrupt SW Mask
 *
 */
union cvmx_bbp_txint_sw_status_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_sw_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t swint                        : 32; /**< ULFE Read Done */
#else
	uint32_t swint                        : 32;
#endif
	} s;
	struct cvmx_bbp_txint_sw_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_sw_status_lox cvmx_bbp_txint_sw_status_lox_t;

/**
 * cvmx_bbp_txint_swclr
 *
 * TXINT_SWCLR- SW Interrupt Clear
 *
 */
union cvmx_bbp_txint_swclr {
	uint32_t u32;
	struct cvmx_bbp_txint_swclr_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t clr                          : 32; /**< Clear SW Interrupt bit */
#else
	uint32_t clr                          : 32;
#endif
	} s;
	struct cvmx_bbp_txint_swclr_s         cnf71xx;
};
typedef union cvmx_bbp_txint_swclr cvmx_bbp_txint_swclr_t;

/**
 * cvmx_bbp_txint_swset
 *
 * TXINT_SWSET - SW Interrupt Set
 *
 */
union cvmx_bbp_txint_swset {
	uint32_t u32;
	struct cvmx_bbp_txint_swset_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t set                          : 32; /**< Set SW Interrupt bit */
#else
	uint32_t set                          : 32;
#endif
	} s;
	struct cvmx_bbp_txint_swset_s         cnf71xx;
};
typedef union cvmx_bbp_txint_swset cvmx_bbp_txint_swset_t;

/**
 * cvmx_bbp_txint_wr_idx_hi#
 *
 * TXINT_WR_IDX_HI - Write Done Group Index HI
 *
 */
union cvmx_bbp_txint_wr_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_wr_idx_hix_s    cnf71xx;
};
typedef union cvmx_bbp_txint_wr_idx_hix cvmx_bbp_txint_wr_idx_hix_t;

/**
 * cvmx_bbp_txint_wr_idx_lo#
 *
 * TXINT_WR_IDX_LO - Write Done Group Index LO
 *
 */
union cvmx_bbp_txint_wr_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Done Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_wr_idx_lox_s    cnf71xx;
};
typedef union cvmx_bbp_txint_wr_idx_lox cvmx_bbp_txint_wr_idx_lox_t;

/**
 * cvmx_bbp_txint_wr_mask_hi#
 *
 * TXINT_WR_MASK_HI = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_txint_wr_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_txint_wr_mask_hix_s   cnf71xx;
};
typedef union cvmx_bbp_txint_wr_mask_hix cvmx_bbp_txint_wr_mask_hix_t;

/**
 * cvmx_bbp_txint_wr_mask_lo#
 *
 * &BBP_TXINT_DID_ID         = 0x6F007F860000
 *
 * TXINT_WR_MASK_LO = Interrupt Write Done Group Mask
 */
union cvmx_bbp_txint_wr_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_txint_wr_mask_lox_s   cnf71xx;
};
typedef union cvmx_bbp_txint_wr_mask_lox cvmx_bbp_txint_wr_mask_lox_t;

/**
 * cvmx_bbp_txint_wr_rint
 *
 * TXINT_WR_RINT - Write Done Group Raw Interrupt Status
 *
 */
union cvmx_bbp_txint_wr_rint {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_txint_wr_rint_s       cnf71xx;
};
typedef union cvmx_bbp_txint_wr_rint cvmx_bbp_txint_wr_rint_t;

/**
 * cvmx_bbp_txint_wr_status_hi#
 *
 * TXINT_WR_STATUS_HI = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_txint_wr_status_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_txint_wr_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_wr_status_hix cvmx_bbp_txint_wr_status_hix_t;

/**
 * cvmx_bbp_txint_wr_status_lo#
 *
 * TXINT_WR_STATUS_LO = Interrupt Write Done Group Mask
 *
 */
union cvmx_bbp_txint_wr_status_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_wr_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_29_31               : 3;
	uint32_t t1_rfif_1                    : 1;  /**< RFIF_1 Write Done */
	uint32_t t1_rfif_0                    : 1;  /**< RFIF_0 Write Done */
	uint32_t axi_rx1_harq                 : 1;  /**< HARQ to Host Write Done */
	uint32_t axi_rx1                      : 1;  /**< RX1 to Host Write Done */
	uint32_t axi_rx0                      : 1;  /**< RX0 to Host Write Done */
	uint32_t axi_tx                       : 1;  /**< TX to Host Write Done */
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Done */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Done */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Done */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Done */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Done */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Done */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Done */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Done */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Done */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Done */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Done */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Done */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Done */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Done */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Done */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Done */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Done */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Done */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Done */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Done */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Done */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Done */
	uint32_t ulfe                         : 1;  /**< ULFE Write Done */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t axi_tx                       : 1;
	uint32_t axi_rx0                      : 1;
	uint32_t axi_rx1                      : 1;
	uint32_t axi_rx1_harq                 : 1;
	uint32_t t1_rfif_0                    : 1;
	uint32_t t1_rfif_1                    : 1;
	uint32_t reserved_29_31               : 3;
#endif
	} s;
	struct cvmx_bbp_txint_wr_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_wr_status_lox cvmx_bbp_txint_wr_status_lox_t;

/**
 * cvmx_bbp_txint_wrq_idx_hi#
 *
 * TXINT_WRQ_IDX_HI - Write Queue Empty Group Index HI
 *
 */
union cvmx_bbp_txint_wrq_idx_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_idx_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_idx_hix_s   cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_idx_hix cvmx_bbp_txint_wrq_idx_hix_t;

/**
 * cvmx_bbp_txint_wrq_idx_lo#
 *
 * TXINT_WRQ_IDX_LO - Write Queue Empty Group Index LO
 *
 */
union cvmx_bbp_txint_wrq_idx_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_idx_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_6_31                : 26;
	uint32_t grpidx                       : 6;  /**< Write Queue Empty Group Interrupt Index */
#else
	uint32_t grpidx                       : 6;
	uint32_t reserved_6_31                : 26;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_idx_lox_s   cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_idx_lox cvmx_bbp_txint_wrq_idx_lox_t;

/**
 * cvmx_bbp_txint_wrq_mask_hi#
 *
 * TXINT_WRQ_MASK_HI = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_wrq_mask_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_mask_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_mask_hix_s  cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_mask_hix cvmx_bbp_txint_wrq_mask_hix_t;

/**
 * cvmx_bbp_txint_wrq_mask_lo#
 *
 * TXINT_WRQ_MASK_LO = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_wrq_mask_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_mask_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_mask_lox_s  cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_mask_lox cvmx_bbp_txint_wrq_mask_lox_t;

/**
 * cvmx_bbp_txint_wrq_rint
 *
 * TXINT_WRQ_RINT - Write Queue Empty Group Raw Interrupt Status
 *
 */
union cvmx_bbp_txint_wrq_rint {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_rint_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_rint_s      cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_rint cvmx_bbp_txint_wrq_rint_t;

/**
 * cvmx_bbp_txint_wrq_status_hi#
 *
 * TXINT_WRQ_STATUS_HI = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_wrq_status_hix {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_status_hix_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_status_hix_s cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_status_hix cvmx_bbp_txint_wrq_status_hix_t;

/**
 * cvmx_bbp_txint_wrq_status_lo#
 *
 * TXINT_WRQ_STATUS_LO = Interrupt Write Queue Empty Group Mask
 *
 */
union cvmx_bbp_txint_wrq_status_lox {
	uint32_t u32;
	struct cvmx_bbp_txint_wrq_status_lox_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_23_31               : 9;
	uint32_t t3_instr                     : 1;  /**< TX Instr Write Queue Empty */
	uint32_t t3_int                       : 1;  /**< PHY to TX Write Queue Empty */
	uint32_t t3_ext                       : 1;  /**< Host to TX Write Queue Empty */
	uint32_t t2_instr                     : 1;  /**< RX1 Instr Write Queue Empty */
	uint32_t t2_harq                      : 1;  /**< Host to HARQ Write Queue Empty */
	uint32_t t2_int                       : 1;  /**< PHY to RX1 Write Queue Empty */
	uint32_t t2_ext                       : 1;  /**< Host to RX1 Write Queue Empty */
	uint32_t t1_instr                     : 1;  /**< RX0 Instr Write Queue Empty */
	uint32_t t1_int                       : 1;  /**< PHY to RX0 Write Queue Empty */
	uint32_t t1_ext                       : 1;  /**< Host to RX0 Write Queue Empty */
	uint32_t ifftpapr_1                   : 1;  /**< IFFTPAPR_1 Write Queue Empty */
	uint32_t ifftpapr_0                   : 1;  /**< IFFTPAPR_0 Write Queue Empty */
	uint32_t lteenc_cch                   : 1;  /**< LTE Encoder CCH Write Queue Empty */
	uint32_t lteenc_tb1                   : 1;  /**< LTE Encoder TB1 Write Queue Empty */
	uint32_t lteenc_tb0                   : 1;  /**< LTE Encoder TB0 Write Queue Empty */
	uint32_t vitbdec                      : 1;  /**< Viterbi Decoder Write Queue Empty */
	uint32_t turbo_hq                     : 1;  /**< Turbo Decoder HARQ Write Queue Empty */
	uint32_t turbo_sb                     : 1;  /**< Turbo Decoder Soft Bits Write Queue Empty */
	uint32_t turbo                        : 1;  /**< Turbo Decoder Write Queue Empty */
	uint32_t dftdm                        : 1;  /**< DFT/Demapper Write Queue Empty */
	uint32_t rachsnif_1                   : 1;  /**< RACH_1 Write Queue Empty */
	uint32_t rachsnif_0                   : 1;  /**< RACH_0 Write Queue Empty */
	uint32_t ulfe                         : 1;  /**< ULFE Write Queue Empty */
#else
	uint32_t ulfe                         : 1;
	uint32_t rachsnif_0                   : 1;
	uint32_t rachsnif_1                   : 1;
	uint32_t dftdm                        : 1;
	uint32_t turbo                        : 1;
	uint32_t turbo_sb                     : 1;
	uint32_t turbo_hq                     : 1;
	uint32_t vitbdec                      : 1;
	uint32_t lteenc_tb0                   : 1;
	uint32_t lteenc_tb1                   : 1;
	uint32_t lteenc_cch                   : 1;
	uint32_t ifftpapr_0                   : 1;
	uint32_t ifftpapr_1                   : 1;
	uint32_t t1_ext                       : 1;
	uint32_t t1_int                       : 1;
	uint32_t t1_instr                     : 1;
	uint32_t t2_ext                       : 1;
	uint32_t t2_int                       : 1;
	uint32_t t2_harq                      : 1;
	uint32_t t2_instr                     : 1;
	uint32_t t3_ext                       : 1;
	uint32_t t3_int                       : 1;
	uint32_t t3_instr                     : 1;
	uint32_t reserved_23_31               : 9;
#endif
	} s;
	struct cvmx_bbp_txint_wrq_status_lox_s cnf71xx;
};
typedef union cvmx_bbp_txint_wrq_status_lox cvmx_bbp_txint_wrq_status_lox_t;

/**
 * cvmx_bbp_txseq_autogate
 */
union cvmx_bbp_txseq_autogate {
	uint32_t u32;
	struct cvmx_bbp_txseq_autogate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t auto_gate                    : 1;  /**< 1==enable auto-clock-gating */
#else
	uint32_t auto_gate                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_txseq_autogate_s      cnf71xx;
};
typedef union cvmx_bbp_txseq_autogate cvmx_bbp_txseq_autogate_t;

/**
 * cvmx_bbp_txseq_gpi_rd00
 */
union cvmx_bbp_txseq_gpi_rd00 {
	uint32_t u32;
	struct cvmx_bbp_txseq_gpi_rd00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t rfif_1_rd_done               : 1;  /**< RFIF_1 RD done int */
	uint32_t rfif_0_rd_done               : 1;  /**< RFIF_0 RD done int */
	uint32_t edma_wr4_done                : 1;  /**< EDMA WR4 done int */
	uint32_t intdma_rd_done               : 1;  /**< INTDMA RD done int */
	uint32_t extdma_rd_done               : 1;  /**< EXTDMA RD done int */
	uint32_t ipm_rm_rd_done               : 1;  /**< IPM RM RD done int */
	uint32_t ipm1_rd_done                 : 1;  /**< IPM 1 RD done int */
	uint32_t ipm0_rd_done                 : 1;  /**< IPM 0 RD done int */
	uint32_t dle1_rd_done                 : 1;  /**< DLE TB1 RD done int */
	uint32_t dle0_rd_done                 : 1;  /**< DLE TB0 RD done int */
	uint32_t vitb_rd_done                 : 1;  /**< Viterbi RD done int */
	uint32_t rfif_spi_int                 : 1;  /**< RFIF SPI int */
	uint32_t rfif_tx_ints                 : 12; /**< RFIF TX ints */
	uint32_t tti_timer                    : 8;  /**< TTI Timer ints from RFIF */
#else
	uint32_t tti_timer                    : 8;
	uint32_t rfif_tx_ints                 : 12;
	uint32_t rfif_spi_int                 : 1;
	uint32_t vitb_rd_done                 : 1;
	uint32_t dle0_rd_done                 : 1;
	uint32_t dle1_rd_done                 : 1;
	uint32_t ipm0_rd_done                 : 1;
	uint32_t ipm1_rd_done                 : 1;
	uint32_t ipm_rm_rd_done               : 1;
	uint32_t extdma_rd_done               : 1;
	uint32_t intdma_rd_done               : 1;
	uint32_t edma_wr4_done                : 1;
	uint32_t rfif_0_rd_done               : 1;
	uint32_t rfif_1_rd_done               : 1;
#endif
	} s;
	struct cvmx_bbp_txseq_gpi_rd00_s      cnf71xx;
};
typedef union cvmx_bbp_txseq_gpi_rd00 cvmx_bbp_txseq_gpi_rd00_t;

/**
 * cvmx_bbp_txseq_gpi_rd01
 */
union cvmx_bbp_txseq_gpi_rd01 {
	uint32_t u32;
	struct cvmx_bbp_txseq_gpi_rd01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 20; /**< SEQ loopbacks from GPO. */
	uint32_t enc3g_done                   : 1;  /**< ENC3G done int, from HAB */
	uint32_t ipm_done                     : 1;  /**< IPM done int, from HAB */
	uint32_t dle_done                     : 1;  /**< DLE done int, from HAB */
	uint32_t reserved_8_8                 : 1;
	uint32_t intdma_wr_done               : 1;  /**< INTDMA WR done int */
	uint32_t extdma_wr_done               : 1;  /**< EXTDMA WR done int */
	uint32_t ipm1_wr_done                 : 1;  /**< IPM 1 RD done int */
	uint32_t ipm0_wr_done                 : 1;  /**< IPM 0 RD done int */
	uint32_t dle_cch_wr_done              : 1;  /**< DLE CCH WR done int */
	uint32_t dle1_wr_done                 : 1;  /**< DLE TB1 WR done int */
	uint32_t dle0_wr_done                 : 1;  /**< DLE TB0 WR done int */
	uint32_t vitb_wr_done                 : 1;  /**< Viterbi WR done int */
#else
	uint32_t vitb_wr_done                 : 1;
	uint32_t dle0_wr_done                 : 1;
	uint32_t dle1_wr_done                 : 1;
	uint32_t dle_cch_wr_done              : 1;
	uint32_t ipm0_wr_done                 : 1;
	uint32_t ipm1_wr_done                 : 1;
	uint32_t extdma_wr_done               : 1;
	uint32_t intdma_wr_done               : 1;
	uint32_t reserved_8_8                 : 1;
	uint32_t dle_done                     : 1;
	uint32_t ipm_done                     : 1;
	uint32_t enc3g_done                   : 1;
	uint32_t gpi_loopback                 : 20;
#endif
	} s;
	struct cvmx_bbp_txseq_gpi_rd01_s      cnf71xx;
};
typedef union cvmx_bbp_txseq_gpi_rd01 cvmx_bbp_txseq_gpi_rd01_t;

/**
 * cvmx_bbp_txseq_gpo_clr00
 */
union cvmx_bbp_txseq_gpo_clr00 {
	uint32_t u32;
	struct cvmx_bbp_txseq_gpo_clr00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t enc3g_sel                    : 1;  /**< Selects encoder.  0=LTE ENC, 1=3G.  Write 1 to clear, 0 to leave alone */
	uint32_t rfif_tx_insel                : 1;  /**< RFIF input select.  0=IPM, 1=HMM.   Write 1 to clear, 0 to leave alone */
	uint32_t t3seq_intr                   : 8;  /**< SEQ interrupt outputs.  Write 1 to clear, 0 to leave alone */
#else
	uint32_t t3seq_intr                   : 8;
	uint32_t rfif_tx_insel                : 1;
	uint32_t enc3g_sel                    : 1;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_txseq_gpo_clr00_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_gpo_clr00 cvmx_bbp_txseq_gpo_clr00_t;

/**
 * cvmx_bbp_txseq_gpo_clr01
 */
union cvmx_bbp_txseq_gpo_clr01 {
	uint32_t u32;
	struct cvmx_bbp_txseq_gpo_clr01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 20; /**< SEQ loopbacks to GPI.   Write 1 to clear, 0 to leave alone */
	uint32_t reserved_0_11                : 12;
#else
	uint32_t reserved_0_11                : 12;
	uint32_t gpi_loopback                 : 20;
#endif
	} s;
	struct cvmx_bbp_txseq_gpo_clr01_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_gpo_clr01 cvmx_bbp_txseq_gpo_clr01_t;

/**
 * cvmx_bbp_txseq_gpo_set00
 */
union cvmx_bbp_txseq_gpo_set00 {
	uint32_t u32;
	struct cvmx_bbp_txseq_gpo_set00_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_10_31               : 22;
	uint32_t enc3g_sel                    : 1;  /**< Selects encoder.  0=LTE ENC, 1=3G.  Write 1 to set, 0 to leave alone */
	uint32_t rfif_tx_insel                : 1;  /**< RFIF input select.  0=IPM, 1=HMM.   Write 1 to set, 0 to leave alone */
	uint32_t t3seq_intr                   : 8;  /**< SEQ interrupt outputs.  Write 1 to set, 0 to leave alone */
#else
	uint32_t t3seq_intr                   : 8;
	uint32_t rfif_tx_insel                : 1;
	uint32_t enc3g_sel                    : 1;
	uint32_t reserved_10_31               : 22;
#endif
	} s;
	struct cvmx_bbp_txseq_gpo_set00_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_gpo_set00 cvmx_bbp_txseq_gpo_set00_t;

/**
 * cvmx_bbp_txseq_gpo_set01
 */
union cvmx_bbp_txseq_gpo_set01 {
	uint32_t u32;
	struct cvmx_bbp_txseq_gpo_set01_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t gpi_loopback                 : 20; /**< SEQ loopbacks to GPI.   Write 1 to set, 0 to leave alone */
	uint32_t reserved_0_11                : 12;
#else
	uint32_t reserved_0_11                : 12;
	uint32_t gpi_loopback                 : 20;
#endif
	} s;
	struct cvmx_bbp_txseq_gpo_set01_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_gpo_set01 cvmx_bbp_txseq_gpo_set01_t;

/**
 * cvmx_bbp_txseq_param0
 */
union cvmx_bbp_txseq_param0 {
	uint32_t u32;
	struct cvmx_bbp_txseq_param0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_25_31               : 7;
	uint32_t autorun                      : 1;  /**< Autorun parameter value */
	uint32_t reserved_17_23               : 7;
	uint32_t seq_base_addr                : 17; /**< Base address parameter value */
#else
	uint32_t seq_base_addr                : 17;
	uint32_t reserved_17_23               : 7;
	uint32_t autorun                      : 1;
	uint32_t reserved_25_31               : 7;
#endif
	} s;
	struct cvmx_bbp_txseq_param0_s        cnf71xx;
};
typedef union cvmx_bbp_txseq_param0 cvmx_bbp_txseq_param0_t;

/**
 * cvmx_bbp_txseq_param1
 */
union cvmx_bbp_txseq_param1 {
	uint32_t u32;
	struct cvmx_bbp_txseq_param1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_21_31               : 11;
	uint32_t thrd_max                     : 5;  /**< Thread max parameter value */
	uint32_t gpio_out_max                 : 8;  /**< GPIO out max parameter value */
	uint32_t gpio_in_max                  : 8;  /**< GPIO in max parameter value */
#else
	uint32_t gpio_in_max                  : 8;
	uint32_t gpio_out_max                 : 8;
	uint32_t thrd_max                     : 5;
	uint32_t reserved_21_31               : 11;
#endif
	} s;
	struct cvmx_bbp_txseq_param1_s        cnf71xx;
};
typedef union cvmx_bbp_txseq_param1 cvmx_bbp_txseq_param1_t;

/**
 * cvmx_bbp_txseq_ramacc
 */
union cvmx_bbp_txseq_ramacc {
	uint32_t u32;
	struct cvmx_bbp_txseq_ramacc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t ram_read_addr                : 14; /**< Command RAM read address -- when reading from Command
                                                         RAM, write this register with the Command Address and
                                                         read back this register until the read value returns
                                                         the requested address.  Then the read data is ready in
                                                         the RAMRD_LSW and RAMRD_MSW registers (following). */
	uint32_t reserved_0_2                 : 3;
#else
	uint32_t reserved_0_2                 : 3;
	uint32_t ram_read_addr                : 14;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_txseq_ramacc_s        cnf71xx;
};
typedef union cvmx_bbp_txseq_ramacc cvmx_bbp_txseq_ramacc_t;

/**
 * cvmx_bbp_txseq_ramrd_lsw
 */
union cvmx_bbp_txseq_ramrd_lsw {
	uint32_t u32;
	struct cvmx_bbp_txseq_ramrd_lsw_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t cmd_ram_lsw                  : 12; /**< LSW of data read from command RAM */
#else
	uint32_t cmd_ram_lsw                  : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_txseq_ramrd_lsw_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_ramrd_lsw cvmx_bbp_txseq_ramrd_lsw_t;

/**
 * cvmx_bbp_txseq_ramrd_msw
 */
union cvmx_bbp_txseq_ramrd_msw {
	uint32_t u32;
	struct cvmx_bbp_txseq_ramrd_msw_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t cmd_ram_msw                  : 32; /**< MSW of data read from command RAM */
#else
	uint32_t cmd_ram_msw                  : 32;
#endif
	} s;
	struct cvmx_bbp_txseq_ramrd_msw_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_ramrd_msw cvmx_bbp_txseq_ramrd_msw_t;

/**
 * cvmx_bbp_txseq_status
 */
union cvmx_bbp_txseq_status {
	uint32_t u32;
	struct cvmx_bbp_txseq_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_21_31               : 11;
	uint32_t curthrd                      : 5;  /**< Currently active thread */
	uint32_t reserved_1_15                : 15;
	uint32_t seq_status                   : 1;  /**< 1==SEQ is not idle */
#else
	uint32_t seq_status                   : 1;
	uint32_t reserved_1_15                : 15;
	uint32_t curthrd                      : 5;
	uint32_t reserved_21_31               : 11;
#endif
	} s;
	struct cvmx_bbp_txseq_status_s        cnf71xx;
};
typedef union cvmx_bbp_txseq_status cvmx_bbp_txseq_status_t;

/**
 * cvmx_bbp_txseq_thrd#_cfg
 */
union cvmx_bbp_txseq_thrdx_cfg {
	uint32_t u32;
	struct cvmx_bbp_txseq_thrdx_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_26_31               : 6;
	uint32_t thrd_wait_sts                : 2;  /**< Thread X wait status
                                                         0==not waiting
                                                         1==waiting for timer
                                                         2==waiting for GPIO low
                                                         3==waiting for GPIO high */
	uint32_t thrd_gpiowait                : 8;  /**< Thread X GPIO used as trigger */
	uint32_t reserved_2_15                : 14;
	uint32_t thrd_stat                    : 2;  /**< Thread X status
                                                         0==done
                                                         1==ready
                                                         2==active
                                                         3==wait */
#else
	uint32_t thrd_stat                    : 2;
	uint32_t reserved_2_15                : 14;
	uint32_t thrd_gpiowait                : 8;
	uint32_t thrd_wait_sts                : 2;
	uint32_t reserved_26_31               : 6;
#endif
	} s;
	struct cvmx_bbp_txseq_thrdx_cfg_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_thrdx_cfg cvmx_bbp_txseq_thrdx_cfg_t;

/**
 * cvmx_bbp_txseq_thrd#_pc
 */
union cvmx_bbp_txseq_thrdx_pc {
	uint32_t u32;
	struct cvmx_bbp_txseq_thrdx_pc_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_16_31               : 16;
	uint32_t thrd_pc                      : 13; /**< Thread X PC (Program Counter) */
	uint32_t reserved_0_2                 : 3;
#else
	uint32_t reserved_0_2                 : 3;
	uint32_t thrd_pc                      : 13;
	uint32_t reserved_16_31               : 16;
#endif
	} s;
	struct cvmx_bbp_txseq_thrdx_pc_s      cnf71xx;
};
typedef union cvmx_bbp_txseq_thrdx_pc cvmx_bbp_txseq_thrdx_pc_t;

/**
 * cvmx_bbp_txseq_thrdstat0
 */
union cvmx_bbp_txseq_thrdstat0 {
	uint32_t u32;
	struct cvmx_bbp_txseq_thrdstat0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t thrd15_stat                  : 2;  /**< Thread 15 status */
	uint32_t thrd14_stat                  : 2;  /**< Thread 14 status */
	uint32_t thrd13_stat                  : 2;  /**< Thread 13 status */
	uint32_t thrd12_stat                  : 2;  /**< Thread 12 status */
	uint32_t thrd11_stat                  : 2;  /**< Thread 11 status */
	uint32_t thrd10_stat                  : 2;  /**< Thread 10 status */
	uint32_t thrd09_stat                  : 2;  /**< Thread 9 status */
	uint32_t thrd08_stat                  : 2;  /**< Thread 8 status */
	uint32_t thrd07_stat                  : 2;  /**< Thread 7 status */
	uint32_t thrd06_stat                  : 2;  /**< Thread 6 status */
	uint32_t thrd05_stat                  : 2;  /**< Thread 5 status */
	uint32_t thrd04_stat                  : 2;  /**< Thread 4 status */
	uint32_t thrd03_stat                  : 2;  /**< Thread 3 status */
	uint32_t thrd02_stat                  : 2;  /**< Thread 2 status */
	uint32_t thrd01_stat                  : 2;  /**< Thread 1 status */
	uint32_t thrd00_stat                  : 2;  /**< Thread 0 status
                                                         0==done
                                                         1==ready
                                                         2==active
                                                         3==wait */
#else
	uint32_t thrd00_stat                  : 2;
	uint32_t thrd01_stat                  : 2;
	uint32_t thrd02_stat                  : 2;
	uint32_t thrd03_stat                  : 2;
	uint32_t thrd04_stat                  : 2;
	uint32_t thrd05_stat                  : 2;
	uint32_t thrd06_stat                  : 2;
	uint32_t thrd07_stat                  : 2;
	uint32_t thrd08_stat                  : 2;
	uint32_t thrd09_stat                  : 2;
	uint32_t thrd10_stat                  : 2;
	uint32_t thrd11_stat                  : 2;
	uint32_t thrd12_stat                  : 2;
	uint32_t thrd13_stat                  : 2;
	uint32_t thrd14_stat                  : 2;
	uint32_t thrd15_stat                  : 2;
#endif
	} s;
	struct cvmx_bbp_txseq_thrdstat0_s     cnf71xx;
};
typedef union cvmx_bbp_txseq_thrdstat0 cvmx_bbp_txseq_thrdstat0_t;

/**
 * cvmx_bbp_txseq_timer
 */
union cvmx_bbp_txseq_timer {
	uint32_t u32;
	struct cvmx_bbp_txseq_timer_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t seq_timer                    : 32; /**< SEQ timer value - Normally set to a value specified by
                                                         the Wait for Timer command.  Will start counting down
                                                         until it hits 0 or until another Wait for Timer cmd is
                                                         issued.  Can be read to read current value or written to
                                                         overwrite count down value - but not a normal usage. */
#else
	uint32_t seq_timer                    : 32;
#endif
	} s;
	struct cvmx_bbp_txseq_timer_s         cnf71xx;
};
typedef union cvmx_bbp_txseq_timer cvmx_bbp_txseq_timer_t;

/**
 * cvmx_bbp_ulfe_bypass_conf
 */
union cvmx_bbp_ulfe_bypass_conf {
	uint32_t u32;
	struct cvmx_bbp_ulfe_bypass_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t bypass_mode                  : 1;  /**< HAB Bypass mode setting
                                                         0 - Normal Mode
                                                         1 - Bypass Mode */
	uint32_t reserved_4_15                : 12;
	uint32_t bypass_node                  : 4;  /**< HAB Bypass node setting
                                                         0000 - Input Data
                                                         0001 - CP remove out
                                                         0010 - Half tone shift out
                                                         0011 - ibuf out0
                                                         0100 - ibuf out1
                                                         0101 - FFT out (lower word)
                                                         0110 - FFT out (upper word)
                                                         0111 - dbuf out (lower word)
                                                         1000 - dbuf out (upper word)
                                                         1001 - scaled out
                                                         1010 ~ 1111 - dsel out */
#else
	uint32_t bypass_node                  : 4;
	uint32_t reserved_4_15                : 12;
	uint32_t bypass_mode                  : 1;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_ulfe_bypass_conf_s    cnf71xx;
};
typedef union cvmx_bbp_ulfe_bypass_conf cvmx_bbp_ulfe_bypass_conf_t;

/**
 * cvmx_bbp_ulfe_clk_ctrl
 */
union cvmx_bbp_ulfe_clk_ctrl {
	uint32_t u32;
	struct cvmx_bbp_ulfe_clk_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t clock_gating                 : 1;  /**< '0' = auto-clock-gating off (default)
                                                         '1' = auto-clock-gating on */
#else
	uint32_t clock_gating                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ulfe_clk_ctrl_s       cnf71xx;
};
typedef union cvmx_bbp_ulfe_clk_ctrl cvmx_bbp_ulfe_clk_ctrl_t;

/**
 * cvmx_bbp_ulfe_common_ctrl0
 */
union cvmx_bbp_ulfe_common_ctrl0 {
	uint32_t u32;
	struct cvmx_bbp_ulfe_common_ctrl0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t common_ctrl0                 : 1;  /**< HAB Done Mode
                                                         0 - Two done interrupt (default)
                                                         1 - One done interrupt */
#else
	uint32_t common_ctrl0                 : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ulfe_common_ctrl0_s   cnf71xx;
};
typedef union cvmx_bbp_ulfe_common_ctrl0 cvmx_bbp_ulfe_common_ctrl0_t;

/**
 * cvmx_bbp_ulfe_common_ctrl1
 */
union cvmx_bbp_ulfe_common_ctrl1 {
	uint32_t u32;
	struct cvmx_bbp_ulfe_common_ctrl1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_20_31               : 12;
	uint32_t common_ctrl1                 : 20; /**< DMA read time out value */
#else
	uint32_t common_ctrl1                 : 20;
	uint32_t reserved_20_31               : 12;
#endif
	} s;
	struct cvmx_bbp_ulfe_common_ctrl1_s   cnf71xx;
};
typedef union cvmx_bbp_ulfe_common_ctrl1 cvmx_bbp_ulfe_common_ctrl1_t;

/**
 * cvmx_bbp_ulfe_control
 */
union cvmx_bbp_ulfe_control {
	uint32_t u32;
	struct cvmx_bbp_ulfe_control_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t hab_start                    : 1;  /**< '1'= start the HAB per configeration registers
                                                         (auto-clear) */
#else
	uint32_t hab_start                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ulfe_control_s        cnf71xx;
};
typedef union cvmx_bbp_ulfe_control cvmx_bbp_ulfe_control_t;

/**
 * cvmx_bbp_ulfe_hab_version
 */
union cvmx_bbp_ulfe_hab_version {
	uint32_t u32;
	struct cvmx_bbp_ulfe_hab_version_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t drop_ver                     : 16; /**< 16bit Drop Version */
	uint32_t release_ver                  : 16; /**< 16bit Release Version */
#else
	uint32_t release_ver                  : 16;
	uint32_t drop_ver                     : 16;
#endif
	} s;
	struct cvmx_bbp_ulfe_hab_version_s    cnf71xx;
};
typedef union cvmx_bbp_ulfe_hab_version cvmx_bbp_ulfe_hab_version_t;

/**
 * cvmx_bbp_ulfe_hw_core_status
 */
union cvmx_bbp_ulfe_hw_core_status {
	uint32_t u32;
	struct cvmx_bbp_ulfe_hw_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_2_31                : 30;
	uint32_t engine_busy                  : 1;  /**< Indicates if the Internal Engine is busy
                                                         '0' = ready
                                                         '1' = busy */
	uint32_t hab_busy                     : 1;  /**< Busy (linked register 0x0 bit0) */
#else
	uint32_t hab_busy                     : 1;
	uint32_t engine_busy                  : 1;
	uint32_t reserved_2_31                : 30;
#endif
	} s;
	struct cvmx_bbp_ulfe_hw_core_status_s cnf71xx;
};
typedef union cvmx_bbp_ulfe_hw_core_status cvmx_bbp_ulfe_hw_core_status_t;

/**
 * cvmx_bbp_ulfe_int_mask
 */
union cvmx_bbp_ulfe_int_mask {
	uint32_t u32;
	struct cvmx_bbp_ulfe_int_mask_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t int_msk                      : 32; /**< Interrupt Mask */
#else
	uint32_t int_msk                      : 32;
#endif
	} s;
	struct cvmx_bbp_ulfe_int_mask_s       cnf71xx;
};
typedef union cvmx_bbp_ulfe_int_mask cvmx_bbp_ulfe_int_mask_t;

/**
 * cvmx_bbp_ulfe_int_src
 */
union cvmx_bbp_ulfe_int_src {
	uint32_t u32;
	struct cvmx_bbp_ulfe_int_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_7_31                : 25;
	uint32_t wr_fifo_full                 : 1;  /**< DMA Write FIFO Full
                                                         '0' = FIFO is not full
                                                         '1' = FIFO is full */
	uint32_t wr_overflow                  : 1;  /**< DMA Write Data Overflow
                                                         '1' = Less data(number of words) was transferred than configured. */
	uint32_t rd_overflow                  : 1;  /**< DMA Read Data Overflow
                                                         '1' = HAB recieved more data(number of words) than is programmed for */
	uint32_t rd_underflow                 : 1;  /**< DMA Read Data Underflow
                                                         '1' = HAB recieved less data(number of words) than is programmed for */
	uint32_t rd_timeout                   : 1;  /**< DMA Read Data Time Out
                                                         '1' = Last subframe data is not recieved in the expected time stamp */
	uint32_t ab_start                     : 1;  /**< Abnormal Start
                                                         '0' = "start" is inserted on the hab ready state
                                                         '1' = "start" is inserted on the hab busy state */
	uint32_t hab_done                     : 1;  /**< '0' = task not completed
                                                         '1' = task completed */
#else
	uint32_t hab_done                     : 1;
	uint32_t ab_start                     : 1;
	uint32_t rd_timeout                   : 1;
	uint32_t rd_underflow                 : 1;
	uint32_t rd_overflow                  : 1;
	uint32_t wr_overflow                  : 1;
	uint32_t wr_fifo_full                 : 1;
	uint32_t reserved_7_31                : 25;
#endif
	} s;
	struct cvmx_bbp_ulfe_int_src_s        cnf71xx;
};
typedef union cvmx_bbp_ulfe_int_src cvmx_bbp_ulfe_int_src_t;

/**
 * cvmx_bbp_ulfe_noise_conf
 */
union cvmx_bbp_ulfe_noise_conf {
	uint32_t u32;
	struct cvmx_bbp_ulfe_noise_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_17_31               : 15;
	uint32_t noise_en                     : 1;  /**< Noise measurement enable
                                                         0 - Diable
                                                         1 - Enable (RSSI and Noise) */
	uint32_t reserved_4_15                : 12;
	uint32_t noise_sym_index              : 4;  /**< Symbol index for noise measurement (0~13) */
#else
	uint32_t noise_sym_index              : 4;
	uint32_t reserved_4_15                : 12;
	uint32_t noise_en                     : 1;
	uint32_t reserved_17_31               : 15;
#endif
	} s;
	struct cvmx_bbp_ulfe_noise_conf_s     cnf71xx;
};
typedef union cvmx_bbp_ulfe_noise_conf cvmx_bbp_ulfe_noise_conf_t;

/**
 * cvmx_bbp_ulfe_status
 *
 * &BBP_DID_ID = 0x6F007F844000
 * ULFE_CSR_VERSION = v1.0       // hab_source_version
 */
union cvmx_bbp_ulfe_status {
	uint32_t u32;
	struct cvmx_bbp_ulfe_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t hab_busy                     : 1;  /**< Indicates if the Hardware accelerator is busy
                                                         '0' = ready
                                                         '1' = busy */
#else
	uint32_t hab_busy                     : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_ulfe_status_s         cnf71xx;
};
typedef union cvmx_bbp_ulfe_status cvmx_bbp_ulfe_status_t;

/**
 * cvmx_bbp_ulfe_sys_conf
 */
union cvmx_bbp_ulfe_sys_conf {
	uint32_t u32;
	struct cvmx_bbp_ulfe_sys_conf_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_25_31               : 7;
	uint32_t fram_type                    : 1;  /**< Frame Structure Type
                                                         0 - FDD or TDD Normal Sub-frame
                                                         1 - TDD Special sub-frame */
	uint32_t reserved_17_23               : 7;
	uint32_t cp_type                      : 1;  /**< CP Type
                                                         0 - Normal
                                                         1 - Extended (not supported) */
	uint32_t reserved_2_15                : 14;
	uint32_t system_bw                    : 2;  /**< System Bandwidth
                                                         00 - 20MHz
                                                         01 - 10MHz
                                                         10 - 5MHz
                                                         11 - Reserved */
#else
	uint32_t system_bw                    : 2;
	uint32_t reserved_2_15                : 14;
	uint32_t cp_type                      : 1;
	uint32_t reserved_17_23               : 7;
	uint32_t fram_type                    : 1;
	uint32_t reserved_25_31               : 7;
#endif
	} s;
	struct cvmx_bbp_ulfe_sys_conf_s       cnf71xx;
};
typedef union cvmx_bbp_ulfe_sys_conf cvmx_bbp_ulfe_sys_conf_t;

/**
 * cvmx_bbp_vitb_auto_clk_gate
 */
union cvmx_bbp_vitb_auto_clk_gate {
	uint32_t u32;
	struct cvmx_bbp_vitb_auto_clk_gate_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t auto_gate                    : 1;  /**< 1: enable auto-clock-gating */
#else
	uint32_t auto_gate                    : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_vitb_auto_clk_gate_s  cnf71xx;
};
typedef union cvmx_bbp_vitb_auto_clk_gate cvmx_bbp_vitb_auto_clk_gate_t;

/**
 * cvmx_bbp_vitb_core_status
 */
union cvmx_bbp_vitb_core_status {
	uint32_t u32;
	struct cvmx_bbp_vitb_core_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_0_31                : 32;
#else
	uint32_t reserved_0_31                : 32;
#endif
	} s;
	struct cvmx_bbp_vitb_core_status_s    cnf71xx;
};
typedef union cvmx_bbp_vitb_core_status cvmx_bbp_vitb_core_status_t;

/**
 * cvmx_bbp_vitb_intr_msk
 */
union cvmx_bbp_vitb_intr_msk {
	uint32_t u32;
	struct cvmx_bbp_vitb_intr_msk_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t vitb_intr_msk                : 1;  /**< Viterbi interrupt mask */
#else
	uint32_t vitb_intr_msk                : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_vitb_intr_msk_s       cnf71xx;
};
typedef union cvmx_bbp_vitb_intr_msk cvmx_bbp_vitb_intr_msk_t;

/**
 * cvmx_bbp_vitb_intr_src
 */
union cvmx_bbp_vitb_intr_src {
	uint32_t u32;
	struct cvmx_bbp_vitb_intr_src_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t vitb_hab_done                : 1;  /**< 1: Viterbi decoder is done */
#else
	uint32_t vitb_hab_done                : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_vitb_intr_src_s       cnf71xx;
};
typedef union cvmx_bbp_vitb_intr_src cvmx_bbp_vitb_intr_src_t;

/**
 * cvmx_bbp_vitb_module_ctrl
 */
union cvmx_bbp_vitb_module_ctrl {
	uint32_t u32;
	struct cvmx_bbp_vitb_module_ctrl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t vitb_start                   : 1;  /**< 1: start  (auto clear) */
#else
	uint32_t vitb_start                   : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_vitb_module_ctrl_s    cnf71xx;
};
typedef union cvmx_bbp_vitb_module_ctrl cvmx_bbp_vitb_module_ctrl_t;

/**
 * cvmx_bbp_vitb_module_status
 *
 * &BBP_VITB_DID_ID = 0x6F007F84A400
 * VITB_CSR_VERSION = v1.0  // hab_source_version
 */
union cvmx_bbp_vitb_module_status {
	uint32_t u32;
	struct cvmx_bbp_vitb_module_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_1_31                : 31;
	uint32_t status                       : 1;  /**< viterbi status (1: busy) */
#else
	uint32_t status                       : 1;
	uint32_t reserved_1_31                : 31;
#endif
	} s;
	struct cvmx_bbp_vitb_module_status_s  cnf71xx;
};
typedef union cvmx_bbp_vitb_module_status cvmx_bbp_vitb_module_status_t;

/**
 * cvmx_bbp_vitb_statistics0
 */
union cvmx_bbp_vitb_statistics0 {
	uint32_t u32;
	struct cvmx_bbp_vitb_statistics0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t reserved_12_31               : 20;
	uint32_t ber                          : 12; /**< BER - decoder input BER estimation.  The value reported
                                                         is the number of bitwise differences between the input
                                                         sign and decoded value for all coded bits: r*K */
#else
	uint32_t ber                          : 12;
	uint32_t reserved_12_31               : 20;
#endif
	} s;
	struct cvmx_bbp_vitb_statistics0_s    cnf71xx;
};
typedef union cvmx_bbp_vitb_statistics0 cvmx_bbp_vitb_statistics0_t;

/**
 * cvmx_bbp_vitb_sys_cfg0
 */
union cvmx_bbp_vitb_sys_cfg0 {
	uint32_t u32;
	struct cvmx_bbp_vitb_sys_cfg0_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t k_size                       : 16; /**< payload size of input block */
	uint32_t tb_length                    : 8;  /**< track back length (between 32 and 96) */
	uint32_t reserved_2_7                 : 6;
	uint32_t mode                         : 1;  /**< 0: WCDMA; 1: LTE */
	uint32_t rate                         : 1;  /**< 0: rate: 1/2; 1: rate: 1/3 */
#else
	uint32_t rate                         : 1;
	uint32_t mode                         : 1;
	uint32_t reserved_2_7                 : 6;
	uint32_t tb_length                    : 8;
	uint32_t k_size                       : 16;
#endif
	} s;
	struct cvmx_bbp_vitb_sys_cfg0_s       cnf71xx;
};
typedef union cvmx_bbp_vitb_sys_cfg0 cvmx_bbp_vitb_sys_cfg0_t;

/**
 * cvmx_bbp_vitb_sys_cfg1
 */
union cvmx_bbp_vitb_sys_cfg1 {
	uint32_t u32;
	struct cvmx_bbp_vitb_sys_cfg1_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint32_t data_bypass                  : 1;  /**< 1: bypass the decoder core; pass input LLRs to output */
	uint32_t reserved_17_30               : 14;
	uint32_t bit_endian                   : 1;  /**< 0: big endian (BIT32); 1: little endian (BIT32_LE) */
	uint32_t reserved_10_15               : 6;
	uint32_t bit_sel                      : 2;  /**< bit sel range in sat mode: 0: <5:0>;1: <6:1>; 2: <7:2> */
	uint32_t reserved_2_7                 : 6;
	uint32_t sat_mode                     : 1;  /**< 1: saturation is performed on input LLRs (recommanded) */
	uint32_t negate_llr                   : 1;  /**< 0: most reliable 1 is 0x7F; 1: most reliable 0 is 0x7F */
#else
	uint32_t negate_llr                   : 1;
	uint32_t sat_mode                     : 1;
	uint32_t reserved_2_7                 : 6;
	uint32_t bit_sel                      : 2;
	uint32_t reserved_10_15               : 6;
	uint32_t bit_endian                   : 1;
	uint32_t reserved_17_30               : 14;
	uint32_t data_bypass                  : 1;
#endif
	} s;
	struct cvmx_bbp_vitb_sys_cfg1_s       cnf71xx;
};
typedef union cvmx_bbp_vitb_sys_cfg1 cvmx_bbp_vitb_sys_cfg1_t;

#endif
